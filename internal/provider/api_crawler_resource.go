// Code generated by generate-all-schemas.go. DO NOT EDIT.
// Source: F5 XC OpenAPI specification

package provider

import (
	"context"
	"fmt"
	"strings"

	"github.com/hashicorp/terraform-plugin-framework-timeouts/resource/timeouts"
	"github.com/hashicorp/terraform-plugin-framework/attr"
	"github.com/hashicorp/terraform-plugin-framework/path"
	"github.com/hashicorp/terraform-plugin-framework/resource"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/planmodifier"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/stringplanmodifier"
	"github.com/hashicorp/terraform-plugin-framework/schema/validator"
	"github.com/hashicorp/terraform-plugin-framework/types"
	"github.com/hashicorp/terraform-plugin-log/tflog"

	"github.com/f5xc/terraform-provider-f5xc/internal/client"
	"github.com/f5xc/terraform-provider-f5xc/internal/privatestate"
	inttimeouts "github.com/f5xc/terraform-provider-f5xc/internal/timeouts"
	"github.com/f5xc/terraform-provider-f5xc/internal/validators"
)

// Ensure provider defined types fully satisfy framework interfaces.
var (
	_ resource.Resource                   = &APICrawlerResource{}
	_ resource.ResourceWithConfigure      = &APICrawlerResource{}
	_ resource.ResourceWithImportState    = &APICrawlerResource{}
	_ resource.ResourceWithModifyPlan     = &APICrawlerResource{}
	_ resource.ResourceWithUpgradeState   = &APICrawlerResource{}
	_ resource.ResourceWithValidateConfig = &APICrawlerResource{}
)

// api_crawlerSchemaVersion is the schema version for state upgrades
const api_crawlerSchemaVersion int64 = 1

func NewAPICrawlerResource() resource.Resource {
	return &APICrawlerResource{}
}

type APICrawlerResource struct {
	client *client.Client
}

// APICrawlerEmptyModel represents empty nested blocks
type APICrawlerEmptyModel struct {
}

// APICrawlerDomainsModel represents domains block
type APICrawlerDomainsModel struct {
	Domain      types.String                       `tfsdk:"domain"`
	SimpleLogin *APICrawlerDomainsSimpleLoginModel `tfsdk:"simple_login"`
}

// APICrawlerDomainsModelAttrTypes defines the attribute types for APICrawlerDomainsModel
var APICrawlerDomainsModelAttrTypes = map[string]attr.Type{
	"domain":       types.StringType,
	"simple_login": types.ObjectType{AttrTypes: APICrawlerDomainsSimpleLoginModelAttrTypes},
}

// APICrawlerDomainsSimpleLoginModel represents simple_login block
type APICrawlerDomainsSimpleLoginModel struct {
	User     types.String                               `tfsdk:"user"`
	Password *APICrawlerDomainsSimpleLoginPasswordModel `tfsdk:"password"`
}

// APICrawlerDomainsSimpleLoginModelAttrTypes defines the attribute types for APICrawlerDomainsSimpleLoginModel
var APICrawlerDomainsSimpleLoginModelAttrTypes = map[string]attr.Type{
	"user":     types.StringType,
	"password": types.ObjectType{AttrTypes: map[string]attr.Type{}},
}

// APICrawlerDomainsSimpleLoginPasswordModel represents password block
type APICrawlerDomainsSimpleLoginPasswordModel struct {
	BlindfoldSecretInfo *APICrawlerDomainsSimpleLoginPasswordBlindfoldSecretInfoModel `tfsdk:"blindfold_secret_info"`
	ClearSecretInfo     *APICrawlerDomainsSimpleLoginPasswordClearSecretInfoModel     `tfsdk:"clear_secret_info"`
}

// APICrawlerDomainsSimpleLoginPasswordModelAttrTypes defines the attribute types for APICrawlerDomainsSimpleLoginPasswordModel
var APICrawlerDomainsSimpleLoginPasswordModelAttrTypes = map[string]attr.Type{
	"blindfold_secret_info": types.ObjectType{AttrTypes: APICrawlerDomainsSimpleLoginPasswordBlindfoldSecretInfoModelAttrTypes},
	"clear_secret_info":     types.ObjectType{AttrTypes: APICrawlerDomainsSimpleLoginPasswordClearSecretInfoModelAttrTypes},
}

// APICrawlerDomainsSimpleLoginPasswordBlindfoldSecretInfoModel represents blindfold_secret_info block
type APICrawlerDomainsSimpleLoginPasswordBlindfoldSecretInfoModel struct {
	DecryptionProvider types.String `tfsdk:"decryption_provider"`
	Location           types.String `tfsdk:"location"`
	StoreProvider      types.String `tfsdk:"store_provider"`
}

// APICrawlerDomainsSimpleLoginPasswordBlindfoldSecretInfoModelAttrTypes defines the attribute types for APICrawlerDomainsSimpleLoginPasswordBlindfoldSecretInfoModel
var APICrawlerDomainsSimpleLoginPasswordBlindfoldSecretInfoModelAttrTypes = map[string]attr.Type{
	"decryption_provider": types.StringType,
	"location":            types.StringType,
	"store_provider":      types.StringType,
}

// APICrawlerDomainsSimpleLoginPasswordClearSecretInfoModel represents clear_secret_info block
type APICrawlerDomainsSimpleLoginPasswordClearSecretInfoModel struct {
	Provider types.String `tfsdk:"provider_ref"`
	URL      types.String `tfsdk:"url"`
}

// APICrawlerDomainsSimpleLoginPasswordClearSecretInfoModelAttrTypes defines the attribute types for APICrawlerDomainsSimpleLoginPasswordClearSecretInfoModel
var APICrawlerDomainsSimpleLoginPasswordClearSecretInfoModelAttrTypes = map[string]attr.Type{
	"provider_ref": types.StringType,
	"url":          types.StringType,
}

type APICrawlerResourceModel struct {
	Name        types.String   `tfsdk:"name"`
	Namespace   types.String   `tfsdk:"namespace"`
	Annotations types.Map      `tfsdk:"annotations"`
	Description types.String   `tfsdk:"description"`
	Disable     types.Bool     `tfsdk:"disable"`
	Labels      types.Map      `tfsdk:"labels"`
	ID          types.String   `tfsdk:"id"`
	Timeouts    timeouts.Value `tfsdk:"timeouts"`
	Domains     types.List     `tfsdk:"domains"`
}

func (r *APICrawlerResource) Metadata(ctx context.Context, req resource.MetadataRequest, resp *resource.MetadataResponse) {
	resp.TypeName = req.ProviderTypeName + "_api_crawler"
}

func (r *APICrawlerResource) Schema(ctx context.Context, req resource.SchemaRequest, resp *resource.SchemaResponse) {
	resp.Schema = schema.Schema{
		Version:             api_crawlerSchemaVersion,
		MarkdownDescription: "[Category: API Security] [Namespace: required] Manages a API Crawler resource in F5 Distributed Cloud.",
		Attributes: map[string]schema.Attribute{
			"name": schema.StringAttribute{
				MarkdownDescription: "Name of the API Crawler. Must be unique within the namespace.",
				Required:            true,
				PlanModifiers: []planmodifier.String{
					stringplanmodifier.RequiresReplace(),
				},
				Validators: []validator.String{
					validators.NameValidator(),
				},
			},
			"namespace": schema.StringAttribute{
				MarkdownDescription: "Namespace where the API Crawler will be created.",
				Required:            true,
				PlanModifiers: []planmodifier.String{
					stringplanmodifier.RequiresReplace(),
				},
				Validators: []validator.String{
					validators.NamespaceValidator(),
				},
			},
			"annotations": schema.MapAttribute{
				MarkdownDescription: "Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata.",
				Optional:            true,
				ElementType:         types.StringType,
			},
			"description": schema.StringAttribute{
				MarkdownDescription: "Human readable description for the object.",
				Optional:            true,
			},
			"disable": schema.BoolAttribute{
				MarkdownDescription: "A value of true will administratively disable the object.",
				Optional:            true,
			},
			"labels": schema.MapAttribute{
				MarkdownDescription: "Labels is a user defined key value map that can be attached to resources for organization and filtering.",
				Optional:            true,
				ElementType:         types.StringType,
			},
			"id": schema.StringAttribute{
				MarkdownDescription: "Unique identifier for the resource.",
				Computed:            true,
				PlanModifiers: []planmodifier.String{
					stringplanmodifier.UseStateForUnknown(),
				},
			},
		},
		Blocks: map[string]schema.Block{
			"timeouts": timeouts.Block(ctx, timeouts.Opts{
				Create: true,
				Read:   true,
				Update: true,
				Delete: true,
			}),
			"domains": schema.ListNestedBlock{
				MarkdownDescription: "API Crawler. API Crawler Configuration",
				NestedObject: schema.NestedBlockObject{
					Attributes: map[string]schema.Attribute{
						"domain": schema.StringAttribute{
							MarkdownDescription: "Domains to Crawl. Select the domain to execute API Crawling with given credentials.",
							Optional:            true,
						},
					},
					Blocks: map[string]schema.Block{
						"simple_login": schema.SingleNestedBlock{
							MarkdownDescription: "Simple Login.",
							Attributes: map[string]schema.Attribute{
								"user": schema.StringAttribute{
									MarkdownDescription: "User. Enter the username to assign credentials for the selected domain to crawl",
									Optional:            true,
								},
							},
							Blocks: map[string]schema.Block{
								"password": schema.SingleNestedBlock{
									MarkdownDescription: "Secret. SecretType is used in an object to indicate a sensitive/confidential field",
									Attributes:          map[string]schema.Attribute{},
									Blocks: map[string]schema.Block{
										"blindfold_secret_info": schema.SingleNestedBlock{
											MarkdownDescription: "Blindfold Secret. BlindfoldSecretInfoType specifies information about the Secret managed by F5XC Secret Management",
											Attributes: map[string]schema.Attribute{
												"decryption_provider": schema.StringAttribute{
													MarkdownDescription: "Decryption Provider. Name of the Secret Management Access object that contains information about the backend Secret Management service.",
													Optional:            true,
												},
												"location": schema.StringAttribute{
													MarkdownDescription: "Location. Location is the uri_ref. It could be in url format for string:/// Or it could be a path if the store provider is an http/https location",
													Optional:            true,
												},
												"store_provider": schema.StringAttribute{
													MarkdownDescription: "Store Provider. Name of the Secret Management Access object that contains information about the store to get encrypted bytes This field needs to be provided only if the url scheme is not string:///",
													Optional:            true,
												},
											},
										},
										"clear_secret_info": schema.SingleNestedBlock{
											MarkdownDescription: "In-Clear Secret. ClearSecretInfoType specifies information about the Secret that is not encrypted.",
											Attributes: map[string]schema.Attribute{
												"provider_ref": schema.StringAttribute{
													MarkdownDescription: "Provider. Name of the Secret Management Access object that contains information about the store to get encrypted bytes This field needs to be provided only if the url scheme is not string:///",
													Optional:            true,
												},
												"url": schema.StringAttribute{
													MarkdownDescription: "URL. URL of the secret. Currently supported URL schemes is string:///. For string:/// scheme, Secret needs to be encoded Base64 format. When asked for this secret, caller will get Secret bytes after Base64 decoding.",
													Optional:            true,
												},
											},
										},
									},
								},
							},
						},
					},
				},
			},
		},
	}
}

func (r *APICrawlerResource) Configure(ctx context.Context, req resource.ConfigureRequest, resp *resource.ConfigureResponse) {
	if req.ProviderData == nil {
		return
	}
	client, ok := req.ProviderData.(*client.Client)
	if !ok {
		resp.Diagnostics.AddError(
			"Unexpected Resource Configure Type",
			fmt.Sprintf("Expected *client.Client, got: %T. Please report this issue to the provider developers.", req.ProviderData),
		)
		return
	}
	r.client = client
}

// ValidateConfig implements resource.ResourceWithValidateConfig
func (r *APICrawlerResource) ValidateConfig(ctx context.Context, req resource.ValidateConfigRequest, resp *resource.ValidateConfigResponse) {
	var data APICrawlerResourceModel
	resp.Diagnostics.Append(req.Config.Get(ctx, &data)...)
	if resp.Diagnostics.HasError() {
		return
	}
}

// ModifyPlan implements resource.ResourceWithModifyPlan
func (r *APICrawlerResource) ModifyPlan(ctx context.Context, req resource.ModifyPlanRequest, resp *resource.ModifyPlanResponse) {
	if req.Plan.Raw.IsNull() {
		resp.Diagnostics.AddWarning(
			"Resource Destruction",
			"This will permanently delete the api_crawler from F5 Distributed Cloud.",
		)
		return
	}

	if req.State.Raw.IsNull() {
		var plan APICrawlerResourceModel
		resp.Diagnostics.Append(req.Plan.Get(ctx, &plan)...)
		if resp.Diagnostics.HasError() {
			return
		}

		if plan.Name.IsUnknown() {
			resp.Diagnostics.AddWarning(
				"Unknown Resource Name",
				"The resource name is not yet known. This may affect planning for dependent resources.",
			)
		}
	}
}

// UpgradeState implements resource.ResourceWithUpgradeState
func (r *APICrawlerResource) UpgradeState(ctx context.Context) map[int64]resource.StateUpgrader {
	return map[int64]resource.StateUpgrader{
		0: {
			PriorSchema: &schema.Schema{
				Attributes: map[string]schema.Attribute{
					"name":        schema.StringAttribute{Required: true},
					"namespace":   schema.StringAttribute{Required: true},
					"annotations": schema.MapAttribute{Optional: true, ElementType: types.StringType},
					"labels":      schema.MapAttribute{Optional: true, ElementType: types.StringType},
					"id":          schema.StringAttribute{Computed: true},
				},
			},
			StateUpgrader: func(ctx context.Context, req resource.UpgradeStateRequest, resp *resource.UpgradeStateResponse) {
				var priorState struct {
					Name        types.String `tfsdk:"name"`
					Namespace   types.String `tfsdk:"namespace"`
					Annotations types.Map    `tfsdk:"annotations"`
					Labels      types.Map    `tfsdk:"labels"`
					ID          types.String `tfsdk:"id"`
				}

				resp.Diagnostics.Append(req.State.Get(ctx, &priorState)...)
				if resp.Diagnostics.HasError() {
					return
				}

				upgradedState := APICrawlerResourceModel{
					Name:        priorState.Name,
					Namespace:   priorState.Namespace,
					Annotations: priorState.Annotations,
					Labels:      priorState.Labels,
					ID:          priorState.ID,
					Timeouts:    timeouts.Value{},
				}

				resp.Diagnostics.Append(resp.State.Set(ctx, upgradedState)...)
			},
		},
	}
}

func (r *APICrawlerResource) Create(ctx context.Context, req resource.CreateRequest, resp *resource.CreateResponse) {
	var data APICrawlerResourceModel
	resp.Diagnostics.Append(req.Plan.Get(ctx, &data)...)
	if resp.Diagnostics.HasError() {
		return
	}

	createTimeout, diags := data.Timeouts.Create(ctx, inttimeouts.DefaultCreate)
	resp.Diagnostics.Append(diags...)
	if resp.Diagnostics.HasError() {
		return
	}

	ctx, cancel := context.WithTimeout(ctx, createTimeout)
	defer cancel()

	tflog.Debug(ctx, "Creating api_crawler", map[string]interface{}{
		"name":      data.Name.ValueString(),
		"namespace": data.Namespace.ValueString(),
	})

	createReq := &client.APICrawler{
		Metadata: client.Metadata{
			Name:      data.Name.ValueString(),
			Namespace: data.Namespace.ValueString(),
		},
		Spec: make(map[string]interface{}),
	}

	if !data.Description.IsNull() {
		createReq.Metadata.Description = data.Description.ValueString()
	}

	if !data.Labels.IsNull() {
		labels := make(map[string]string)
		resp.Diagnostics.Append(data.Labels.ElementsAs(ctx, &labels, false)...)
		if resp.Diagnostics.HasError() {
			return
		}
		createReq.Metadata.Labels = labels
	}

	if !data.Annotations.IsNull() {
		annotations := make(map[string]string)
		resp.Diagnostics.Append(data.Annotations.ElementsAs(ctx, &annotations, false)...)
		if resp.Diagnostics.HasError() {
			return
		}
		createReq.Metadata.Annotations = annotations
	}

	// Marshal spec fields from Terraform state to API struct
	if !data.Domains.IsNull() && !data.Domains.IsUnknown() {
		var domainsItems []APICrawlerDomainsModel
		diags := data.Domains.ElementsAs(ctx, &domainsItems, false)
		resp.Diagnostics.Append(diags...)
		if !resp.Diagnostics.HasError() && len(domainsItems) > 0 {
			var domainsList []map[string]interface{}
			for _, item := range domainsItems {
				itemMap := make(map[string]interface{})
				if !item.Domain.IsNull() && !item.Domain.IsUnknown() {
					itemMap["domain"] = item.Domain.ValueString()
				}
				if item.SimpleLogin != nil {
					simple_loginNestedMap := make(map[string]interface{})
					if item.SimpleLogin.Password != nil {
						passwordDeepMap := make(map[string]interface{})
						simple_loginNestedMap["password"] = passwordDeepMap
					}
					if !item.SimpleLogin.User.IsNull() && !item.SimpleLogin.User.IsUnknown() {
						simple_loginNestedMap["user"] = item.SimpleLogin.User.ValueString()
					}
					itemMap["simple_login"] = simple_loginNestedMap
				}
				domainsList = append(domainsList, itemMap)
			}
			createReq.Spec["domains"] = domainsList
		}
	}

	apiResource, err := r.client.CreateAPICrawler(ctx, createReq)
	if err != nil {
		resp.Diagnostics.AddError("Client Error", fmt.Sprintf("Unable to create APICrawler: %s", err))
		return
	}

	data.ID = types.StringValue(apiResource.Metadata.Name)

	// Unmarshal spec fields from API response to Terraform state
	// This ensures computed nested fields (like tenant in Object Reference blocks) have known values
	isImport := false // Create is never an import
	_ = isImport      // May be unused if resource has no blocks needing import detection
	if listData, ok := apiResource.Spec["domains"].([]interface{}); ok && len(listData) > 0 {
		var domainsList []APICrawlerDomainsModel
		var existingDomainsItems []APICrawlerDomainsModel
		if !data.Domains.IsNull() && !data.Domains.IsUnknown() {
			data.Domains.ElementsAs(ctx, &existingDomainsItems, false)
		}
		for listIdx, item := range listData {
			_ = listIdx // May be unused if no empty marker blocks in list item
			if itemMap, ok := item.(map[string]interface{}); ok {
				domainsList = append(domainsList, APICrawlerDomainsModel{
					Domain: func() types.String {
						if v, ok := itemMap["domain"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
					SimpleLogin: func() *APICrawlerDomainsSimpleLoginModel {
						if nestedMap, ok := itemMap["simple_login"].(map[string]interface{}); ok {
							return &APICrawlerDomainsSimpleLoginModel{
								User: func() types.String {
									if v, ok := nestedMap["user"].(string); ok && v != "" {
										return types.StringValue(v)
									}
									return types.StringNull()
								}(),
							}
						}
						return nil
					}(),
				})
			}
		}
		listVal, diags := types.ListValueFrom(ctx, types.ObjectType{AttrTypes: APICrawlerDomainsModelAttrTypes}, domainsList)
		resp.Diagnostics.Append(diags...)
		if !resp.Diagnostics.HasError() {
			data.Domains = listVal
		}
	} else {
		// No data from API - set to null list
		data.Domains = types.ListNull(types.ObjectType{AttrTypes: APICrawlerDomainsModelAttrTypes})
	}

	psd := privatestate.NewPrivateStateData()
	psd.SetCustom("managed", "true")
	tflog.Debug(ctx, "Create: saving private state with managed marker", map[string]interface{}{
		"name": apiResource.Metadata.Name,
	})
	resp.Diagnostics.Append(psd.SaveToPrivateState(ctx, resp)...)

	tflog.Trace(ctx, "created APICrawler resource")
	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}

func (r *APICrawlerResource) Read(ctx context.Context, req resource.ReadRequest, resp *resource.ReadResponse) {
	var data APICrawlerResourceModel
	resp.Diagnostics.Append(req.State.Get(ctx, &data)...)
	if resp.Diagnostics.HasError() {
		return
	}

	readTimeout, diags := data.Timeouts.Read(ctx, inttimeouts.DefaultRead)
	resp.Diagnostics.Append(diags...)
	if resp.Diagnostics.HasError() {
		return
	}

	ctx, cancel := context.WithTimeout(ctx, readTimeout)
	defer cancel()

	psd, psDiags := privatestate.LoadFromPrivateState(ctx, &req)
	resp.Diagnostics.Append(psDiags...)

	apiResource, err := r.client.GetAPICrawler(ctx, data.Namespace.ValueString(), data.Name.ValueString())
	if err != nil {
		// Check if the resource was deleted outside Terraform
		if strings.Contains(err.Error(), "NOT_FOUND") || strings.Contains(err.Error(), "404") {
			tflog.Warn(ctx, "APICrawler not found, removing from state", map[string]interface{}{
				"name":      data.Name.ValueString(),
				"namespace": data.Namespace.ValueString(),
			})
			resp.State.RemoveResource(ctx)
			return
		}
		resp.Diagnostics.AddError("Client Error", fmt.Sprintf("Unable to read APICrawler: %s", err))
		return
	}

	if psd != nil && psd.Metadata.UID != "" && apiResource.Metadata.UID != psd.Metadata.UID {
		resp.Diagnostics.AddWarning(
			"Resource Drift Detected",
			"The api_crawler may have been recreated outside of Terraform.",
		)
	}

	data.ID = types.StringValue(apiResource.Metadata.Name)
	data.Name = types.StringValue(apiResource.Metadata.Name)
	data.Namespace = types.StringValue(apiResource.Metadata.Namespace)

	// Read description from metadata
	if apiResource.Metadata.Description != "" {
		data.Description = types.StringValue(apiResource.Metadata.Description)
	} else {
		data.Description = types.StringNull()
	}

	// Filter out system-managed labels (ves.io/*) that are injected by the platform
	if len(apiResource.Metadata.Labels) > 0 {
		filteredLabels := filterSystemLabels(apiResource.Metadata.Labels)
		if len(filteredLabels) > 0 {
			labels, diags := types.MapValueFrom(ctx, types.StringType, filteredLabels)
			resp.Diagnostics.Append(diags...)
			if !resp.Diagnostics.HasError() {
				data.Labels = labels
			}
		} else {
			data.Labels = types.MapNull(types.StringType)
		}
	} else {
		data.Labels = types.MapNull(types.StringType)
	}

	if len(apiResource.Metadata.Annotations) > 0 {
		annotations, diags := types.MapValueFrom(ctx, types.StringType, apiResource.Metadata.Annotations)
		resp.Diagnostics.Append(diags...)
		if !resp.Diagnostics.HasError() {
			data.Annotations = annotations
		}
	} else {
		data.Annotations = types.MapNull(types.StringType)
	}

	// Unmarshal spec fields from API response to Terraform state
	// isImport is true when private state has no "managed" marker (Import case - never went through Create)
	isImport := psd == nil || psd.Metadata.Custom == nil || psd.Metadata.Custom["managed"] != "true"
	_ = isImport // May be unused if resource has no blocks needing import detection
	tflog.Debug(ctx, "Read: checking isImport status", map[string]interface{}{
		"isImport":   isImport,
		"psd_is_nil": psd == nil,
		"managed":    psd.Metadata.Custom["managed"],
	})
	if listData, ok := apiResource.Spec["domains"].([]interface{}); ok && len(listData) > 0 {
		var domainsList []APICrawlerDomainsModel
		var existingDomainsItems []APICrawlerDomainsModel
		if !data.Domains.IsNull() && !data.Domains.IsUnknown() {
			data.Domains.ElementsAs(ctx, &existingDomainsItems, false)
		}
		for listIdx, item := range listData {
			_ = listIdx // May be unused if no empty marker blocks in list item
			if itemMap, ok := item.(map[string]interface{}); ok {
				domainsList = append(domainsList, APICrawlerDomainsModel{
					Domain: func() types.String {
						if v, ok := itemMap["domain"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
					SimpleLogin: func() *APICrawlerDomainsSimpleLoginModel {
						if nestedMap, ok := itemMap["simple_login"].(map[string]interface{}); ok {
							return &APICrawlerDomainsSimpleLoginModel{
								User: func() types.String {
									if v, ok := nestedMap["user"].(string); ok && v != "" {
										return types.StringValue(v)
									}
									return types.StringNull()
								}(),
							}
						}
						return nil
					}(),
				})
			}
		}
		listVal, diags := types.ListValueFrom(ctx, types.ObjectType{AttrTypes: APICrawlerDomainsModelAttrTypes}, domainsList)
		resp.Diagnostics.Append(diags...)
		if !resp.Diagnostics.HasError() {
			data.Domains = listVal
		}
	} else {
		// No data from API - set to null list
		data.Domains = types.ListNull(types.ObjectType{AttrTypes: APICrawlerDomainsModelAttrTypes})
	}

	// Preserve or set the managed marker for future Read operations
	newPsd := privatestate.NewPrivateStateData()
	newPsd.SetUID(apiResource.Metadata.UID)
	if !isImport {
		// Preserve the managed marker if we already had it
		newPsd.SetCustom("managed", "true")
	}
	resp.Diagnostics.Append(newPsd.SaveToPrivateState(ctx, resp)...)

	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}

func (r *APICrawlerResource) Update(ctx context.Context, req resource.UpdateRequest, resp *resource.UpdateResponse) {
	var data APICrawlerResourceModel
	resp.Diagnostics.Append(req.Plan.Get(ctx, &data)...)
	if resp.Diagnostics.HasError() {
		return
	}

	updateTimeout, diags := data.Timeouts.Update(ctx, inttimeouts.DefaultUpdate)
	resp.Diagnostics.Append(diags...)
	if resp.Diagnostics.HasError() {
		return
	}

	ctx, cancel := context.WithTimeout(ctx, updateTimeout)
	defer cancel()

	apiResource := &client.APICrawler{
		Metadata: client.Metadata{
			Name:      data.Name.ValueString(),
			Namespace: data.Namespace.ValueString(),
		},
		Spec: make(map[string]interface{}),
	}

	if !data.Description.IsNull() {
		apiResource.Metadata.Description = data.Description.ValueString()
	}

	if !data.Labels.IsNull() {
		labels := make(map[string]string)
		resp.Diagnostics.Append(data.Labels.ElementsAs(ctx, &labels, false)...)
		if resp.Diagnostics.HasError() {
			return
		}
		apiResource.Metadata.Labels = labels
	}

	if !data.Annotations.IsNull() {
		annotations := make(map[string]string)
		resp.Diagnostics.Append(data.Annotations.ElementsAs(ctx, &annotations, false)...)
		if resp.Diagnostics.HasError() {
			return
		}
		apiResource.Metadata.Annotations = annotations
	}

	// Marshal spec fields from Terraform state to API struct
	if !data.Domains.IsNull() && !data.Domains.IsUnknown() {
		var domainsItems []APICrawlerDomainsModel
		diags := data.Domains.ElementsAs(ctx, &domainsItems, false)
		resp.Diagnostics.Append(diags...)
		if !resp.Diagnostics.HasError() && len(domainsItems) > 0 {
			var domainsList []map[string]interface{}
			for _, item := range domainsItems {
				itemMap := make(map[string]interface{})
				if !item.Domain.IsNull() && !item.Domain.IsUnknown() {
					itemMap["domain"] = item.Domain.ValueString()
				}
				if item.SimpleLogin != nil {
					simple_loginNestedMap := make(map[string]interface{})
					if item.SimpleLogin.Password != nil {
						passwordDeepMap := make(map[string]interface{})
						simple_loginNestedMap["password"] = passwordDeepMap
					}
					if !item.SimpleLogin.User.IsNull() && !item.SimpleLogin.User.IsUnknown() {
						simple_loginNestedMap["user"] = item.SimpleLogin.User.ValueString()
					}
					itemMap["simple_login"] = simple_loginNestedMap
				}
				domainsList = append(domainsList, itemMap)
			}
			apiResource.Spec["domains"] = domainsList
		}
	}

	_, err := r.client.UpdateAPICrawler(ctx, apiResource)
	if err != nil {
		resp.Diagnostics.AddError("Client Error", fmt.Sprintf("Unable to update APICrawler: %s", err))
		return
	}

	// Use plan data for ID since API response may not include metadata.name
	data.ID = types.StringValue(data.Name.ValueString())

	// Fetch the resource to get complete state including computed fields
	// PUT responses may not include all computed nested fields (like tenant in Object Reference blocks)
	fetched, fetchErr := r.client.GetAPICrawler(ctx, data.Namespace.ValueString(), data.Name.ValueString())
	if fetchErr != nil {
		resp.Diagnostics.AddError("Client Error", fmt.Sprintf("Unable to read APICrawler after update: %s", fetchErr))
		return
	}

	// Set computed fields from API response

	// Unmarshal spec fields from fetched resource to Terraform state
	apiResource = fetched // Use GET response which includes all computed fields
	isImport := false     // Update is never an import
	_ = isImport          // May be unused if resource has no blocks needing import detection
	if listData, ok := apiResource.Spec["domains"].([]interface{}); ok && len(listData) > 0 {
		var domainsList []APICrawlerDomainsModel
		var existingDomainsItems []APICrawlerDomainsModel
		if !data.Domains.IsNull() && !data.Domains.IsUnknown() {
			data.Domains.ElementsAs(ctx, &existingDomainsItems, false)
		}
		for listIdx, item := range listData {
			_ = listIdx // May be unused if no empty marker blocks in list item
			if itemMap, ok := item.(map[string]interface{}); ok {
				domainsList = append(domainsList, APICrawlerDomainsModel{
					Domain: func() types.String {
						if v, ok := itemMap["domain"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
					SimpleLogin: func() *APICrawlerDomainsSimpleLoginModel {
						if nestedMap, ok := itemMap["simple_login"].(map[string]interface{}); ok {
							return &APICrawlerDomainsSimpleLoginModel{
								User: func() types.String {
									if v, ok := nestedMap["user"].(string); ok && v != "" {
										return types.StringValue(v)
									}
									return types.StringNull()
								}(),
							}
						}
						return nil
					}(),
				})
			}
		}
		listVal, diags := types.ListValueFrom(ctx, types.ObjectType{AttrTypes: APICrawlerDomainsModelAttrTypes}, domainsList)
		resp.Diagnostics.Append(diags...)
		if !resp.Diagnostics.HasError() {
			data.Domains = listVal
		}
	} else {
		// No data from API - set to null list
		data.Domains = types.ListNull(types.ObjectType{AttrTypes: APICrawlerDomainsModelAttrTypes})
	}

	psd := privatestate.NewPrivateStateData()
	// Use UID from fetched resource
	uid := fetched.Metadata.UID
	psd.SetUID(uid)
	psd.SetCustom("managed", "true") // Preserve managed marker after Update
	resp.Diagnostics.Append(psd.SaveToPrivateState(ctx, resp)...)

	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}

func (r *APICrawlerResource) Delete(ctx context.Context, req resource.DeleteRequest, resp *resource.DeleteResponse) {
	var data APICrawlerResourceModel
	resp.Diagnostics.Append(req.State.Get(ctx, &data)...)
	if resp.Diagnostics.HasError() {
		return
	}

	deleteTimeout, diags := data.Timeouts.Delete(ctx, inttimeouts.DefaultDelete)
	resp.Diagnostics.Append(diags...)
	if resp.Diagnostics.HasError() {
		return
	}

	ctx, cancel := context.WithTimeout(ctx, deleteTimeout)
	defer cancel()
	err := r.client.DeleteAPICrawler(ctx, data.Namespace.ValueString(), data.Name.ValueString())
	if err != nil {
		// If the resource is already gone, consider deletion successful (idempotent delete)
		if strings.Contains(err.Error(), "NOT_FOUND") || strings.Contains(err.Error(), "404") {
			tflog.Warn(ctx, "APICrawler already deleted, removing from state", map[string]interface{}{
				"name":      data.Name.ValueString(),
				"namespace": data.Namespace.ValueString(),
			})
			return
		}
		// If delete is not implemented (501), warn and remove from state
		// Some F5 XC resources don't support deletion via API
		if strings.Contains(err.Error(), "501") {
			tflog.Warn(ctx, "APICrawler delete not supported by API (501), removing from state only", map[string]interface{}{
				"name":      data.Name.ValueString(),
				"namespace": data.Namespace.ValueString(),
			})
			return
		}
		resp.Diagnostics.AddError("Client Error", fmt.Sprintf("Unable to delete APICrawler: %s", err))
		return
	}
}

func (r *APICrawlerResource) ImportState(ctx context.Context, req resource.ImportStateRequest, resp *resource.ImportStateResponse) {
	// Import ID format: namespace/name
	parts := strings.Split(req.ID, "/")
	if len(parts) != 2 || parts[0] == "" || parts[1] == "" {
		resp.Diagnostics.AddError(
			"Invalid Import ID",
			fmt.Sprintf("Expected import ID format: namespace/name, got: %s", req.ID),
		)
		return
	}
	namespace := parts[0]
	name := parts[1]

	resp.Diagnostics.Append(resp.State.SetAttribute(ctx, path.Root("namespace"), namespace)...)
	resp.Diagnostics.Append(resp.State.SetAttribute(ctx, path.Root("name"), name)...)
	resp.Diagnostics.Append(resp.State.SetAttribute(ctx, path.Root("id"), name)...)
}
