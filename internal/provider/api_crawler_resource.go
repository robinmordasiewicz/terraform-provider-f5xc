// Code generated by generate-all-schemas.go. DO NOT EDIT.
// Source: F5 XC OpenAPI specification

package provider

import (
	"context"
	"fmt"
	"strings"

	"github.com/hashicorp/terraform-plugin-framework-timeouts/resource/timeouts"
	"github.com/hashicorp/terraform-plugin-framework/path"
	"github.com/hashicorp/terraform-plugin-framework/resource"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/planmodifier"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/stringplanmodifier"
	"github.com/hashicorp/terraform-plugin-framework/schema/validator"
	"github.com/hashicorp/terraform-plugin-framework/types"
	"github.com/hashicorp/terraform-plugin-log/tflog"

	"github.com/f5xc/terraform-provider-f5xc/internal/client"
	"github.com/f5xc/terraform-provider-f5xc/internal/privatestate"
	inttimeouts "github.com/f5xc/terraform-provider-f5xc/internal/timeouts"
	"github.com/f5xc/terraform-provider-f5xc/internal/validators"
)

// Ensure provider defined types fully satisfy framework interfaces.
var (
	_ resource.Resource                   = &APICrawlerResource{}
	_ resource.ResourceWithConfigure      = &APICrawlerResource{}
	_ resource.ResourceWithImportState    = &APICrawlerResource{}
	_ resource.ResourceWithModifyPlan     = &APICrawlerResource{}
	_ resource.ResourceWithUpgradeState   = &APICrawlerResource{}
	_ resource.ResourceWithValidateConfig = &APICrawlerResource{}
)

// api_crawlerSchemaVersion is the schema version for state upgrades
const api_crawlerSchemaVersion int64 = 1

func NewAPICrawlerResource() resource.Resource {
	return &APICrawlerResource{}
}

type APICrawlerResource struct {
	client *client.Client
}

// APICrawlerEmptyModel represents empty nested blocks
type APICrawlerEmptyModel struct {
}

// APICrawlerDomainsModel represents domains block
type APICrawlerDomainsModel struct {
	Domain types.String `tfsdk:"domain"`
	SimpleLogin *APICrawlerDomainsSimpleLoginModel `tfsdk:"simple_login"`
}

// APICrawlerDomainsSimpleLoginModel represents simple_login block
type APICrawlerDomainsSimpleLoginModel struct {
	User types.String `tfsdk:"user"`
	Password *APICrawlerDomainsSimpleLoginPasswordModel `tfsdk:"password"`
}

// APICrawlerDomainsSimpleLoginPasswordModel represents password block
type APICrawlerDomainsSimpleLoginPasswordModel struct {
	BlindfoldSecretInfo *APICrawlerDomainsSimpleLoginPasswordBlindfoldSecretInfoModel `tfsdk:"blindfold_secret_info"`
	ClearSecretInfo *APICrawlerDomainsSimpleLoginPasswordClearSecretInfoModel `tfsdk:"clear_secret_info"`
}

// APICrawlerDomainsSimpleLoginPasswordBlindfoldSecretInfoModel represents blindfold_secret_info block
type APICrawlerDomainsSimpleLoginPasswordBlindfoldSecretInfoModel struct {
	DecryptionProvider types.String `tfsdk:"decryption_provider"`
	Location types.String `tfsdk:"location"`
	StoreProvider types.String `tfsdk:"store_provider"`
}

// APICrawlerDomainsSimpleLoginPasswordClearSecretInfoModel represents clear_secret_info block
type APICrawlerDomainsSimpleLoginPasswordClearSecretInfoModel struct {
	Provider types.String `tfsdk:"provider_ref"`
	URL types.String `tfsdk:"url"`
}

type APICrawlerResourceModel struct {
	Name types.String `tfsdk:"name"`
	Namespace types.String `tfsdk:"namespace"`
	Annotations types.Map `tfsdk:"annotations"`
	Description types.String `tfsdk:"description"`
	Disable types.Bool `tfsdk:"disable"`
	Labels types.Map `tfsdk:"labels"`
	ID types.String `tfsdk:"id"`
	Timeouts timeouts.Value `tfsdk:"timeouts"`
	Domains []APICrawlerDomainsModel `tfsdk:"domains"`
}

func (r *APICrawlerResource) Metadata(ctx context.Context, req resource.MetadataRequest, resp *resource.MetadataResponse) {
	resp.TypeName = req.ProviderTypeName + "_api_crawler"
}

func (r *APICrawlerResource) Schema(ctx context.Context, req resource.SchemaRequest, resp *resource.SchemaResponse) {
	resp.Schema = schema.Schema{
		Version:             api_crawlerSchemaVersion,
		MarkdownDescription: "Manages a APICrawler resource in F5 Distributed Cloud.",
		Attributes: map[string]schema.Attribute{
			"name": schema.StringAttribute{
				MarkdownDescription: "Name of the APICrawler. Must be unique within the namespace.",
				Required: true,
				PlanModifiers: []planmodifier.String{
					stringplanmodifier.RequiresReplace(),
				},
				Validators: []validator.String{
					validators.NameValidator(),
				},
			},
			"namespace": schema.StringAttribute{
				MarkdownDescription: "Namespace where the APICrawler will be created.",
				Required: true,
				PlanModifiers: []planmodifier.String{
					stringplanmodifier.RequiresReplace(),
				},
				Validators: []validator.String{
					validators.NamespaceValidator(),
				},
			},
			"annotations": schema.MapAttribute{
				MarkdownDescription: "Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata.",
				Optional: true,
				ElementType: types.StringType,
			},
			"description": schema.StringAttribute{
				MarkdownDescription: "Human readable description for the object.",
				Optional: true,
			},
			"disable": schema.BoolAttribute{
				MarkdownDescription: "A value of true will administratively disable the object.",
				Optional: true,
			},
			"labels": schema.MapAttribute{
				MarkdownDescription: "Labels is a user defined key value map that can be attached to resources for organization and filtering.",
				Optional: true,
				ElementType: types.StringType,
			},
			"id": schema.StringAttribute{
				MarkdownDescription: "Unique identifier for the resource.",
				Computed: true,
				PlanModifiers: []planmodifier.String{
					stringplanmodifier.UseStateForUnknown(),
				},
			},
		},
		Blocks: map[string]schema.Block{
			"timeouts": timeouts.Block(ctx, timeouts.Opts{
				Create: true,
				Read:   true,
				Update: true,
				Delete: true,
			}),
			"domains": schema.ListNestedBlock{
				MarkdownDescription: "API Crawler. API Crawler Configuration",
				NestedObject: schema.NestedBlockObject{
					Attributes: map[string]schema.Attribute{
						"domain": schema.StringAttribute{
							MarkdownDescription: "Domains to Crawl. Select the domain to execute API Crawling with given credentials.",
							Optional: true,
						},
					},
					Blocks: map[string]schema.Block{
						"simple_login": schema.SingleNestedBlock{
							MarkdownDescription: "Simple Login.",
							Attributes: map[string]schema.Attribute{
								"user": schema.StringAttribute{
									MarkdownDescription: "User. Enter the username to assign credentials for the selected domain to crawl",
									Optional: true,
								},
							},
							Blocks: map[string]schema.Block{
								"password": schema.SingleNestedBlock{
									MarkdownDescription: "Secret. SecretType is used in an object to indicate a sensitive/confidential field",
									Attributes: map[string]schema.Attribute{
									},
									Blocks: map[string]schema.Block{
										"blindfold_secret_info": schema.SingleNestedBlock{
											MarkdownDescription: "Blindfold Secret. BlindfoldSecretInfoType specifies information about the Secret managed by F5XC Secret Management",
											Attributes: map[string]schema.Attribute{
												"decryption_provider": schema.StringAttribute{
													MarkdownDescription: "Decryption Provider. Name of the Secret Management Access object that contains information about the backend Secret Management service.",
													Optional: true,
												},
												"location": schema.StringAttribute{
													MarkdownDescription: "Location. Location is the uri_ref. It could be in url format for string:/// Or it could be a path if the store provider is an http/https location",
													Optional: true,
												},
												"store_provider": schema.StringAttribute{
													MarkdownDescription: "Store Provider. Name of the Secret Management Access object that contains information about the store to get encrypted bytes This field needs to be provided only if the url scheme is not string:///",
													Optional: true,
												},
											},
										},
										"clear_secret_info": schema.SingleNestedBlock{
											MarkdownDescription: "In-Clear Secret. ClearSecretInfoType specifies information about the Secret that is not encrypted.",
											Attributes: map[string]schema.Attribute{
												"provider_ref": schema.StringAttribute{
													MarkdownDescription: "Provider. Name of the Secret Management Access object that contains information about the store to get encrypted bytes This field needs to be provided only if the url scheme is not string:///",
													Optional: true,
												},
												"url": schema.StringAttribute{
													MarkdownDescription: "URL. URL of the secret. Currently supported URL schemes is string:///. For string:/// scheme, Secret needs to be encoded Base64 format. When asked for this secret, caller will get Secret bytes after Base64 decoding.",
													Optional: true,
												},
											},
										},
									},
								},
							},
						},
					},

				},
			},
		},
	}
}

func (r *APICrawlerResource) Configure(ctx context.Context, req resource.ConfigureRequest, resp *resource.ConfigureResponse) {
	if req.ProviderData == nil {
		return
	}
	client, ok := req.ProviderData.(*client.Client)
	if !ok {
		resp.Diagnostics.AddError(
			"Unexpected Resource Configure Type",
			fmt.Sprintf("Expected *client.Client, got: %T. Please report this issue to the provider developers.", req.ProviderData),
		)
		return
	}
	r.client = client
}

// ValidateConfig implements resource.ResourceWithValidateConfig
func (r *APICrawlerResource) ValidateConfig(ctx context.Context, req resource.ValidateConfigRequest, resp *resource.ValidateConfigResponse) {
	var data APICrawlerResourceModel
	resp.Diagnostics.Append(req.Config.Get(ctx, &data)...)
	if resp.Diagnostics.HasError() {
		return
	}
}

// ModifyPlan implements resource.ResourceWithModifyPlan
func (r *APICrawlerResource) ModifyPlan(ctx context.Context, req resource.ModifyPlanRequest, resp *resource.ModifyPlanResponse) {
	if req.Plan.Raw.IsNull() {
		resp.Diagnostics.AddWarning(
			"Resource Destruction",
			"This will permanently delete the api_crawler from F5 Distributed Cloud.",
		)
		return
	}

	if req.State.Raw.IsNull() {
		var plan APICrawlerResourceModel
		resp.Diagnostics.Append(req.Plan.Get(ctx, &plan)...)
		if resp.Diagnostics.HasError() {
			return
		}

		if plan.Name.IsUnknown() {
			resp.Diagnostics.AddWarning(
				"Unknown Resource Name",
				"The resource name is not yet known. This may affect planning for dependent resources.",
			)
		}
	}
}

// UpgradeState implements resource.ResourceWithUpgradeState
func (r *APICrawlerResource) UpgradeState(ctx context.Context) map[int64]resource.StateUpgrader {
	return map[int64]resource.StateUpgrader{
		0: {
			PriorSchema: &schema.Schema{
				Attributes: map[string]schema.Attribute{
					"name":        schema.StringAttribute{Required: true},
					"namespace":   schema.StringAttribute{Required: true},
					"annotations": schema.MapAttribute{Optional: true, ElementType: types.StringType},
					"labels":      schema.MapAttribute{Optional: true, ElementType: types.StringType},
					"id":          schema.StringAttribute{Computed: true},
				},
			},
			StateUpgrader: func(ctx context.Context, req resource.UpgradeStateRequest, resp *resource.UpgradeStateResponse) {
				var priorState struct {
					Name        types.String `tfsdk:"name"`
					Namespace   types.String `tfsdk:"namespace"`
					Annotations types.Map    `tfsdk:"annotations"`
					Labels      types.Map    `tfsdk:"labels"`
					ID          types.String `tfsdk:"id"`
				}

				resp.Diagnostics.Append(req.State.Get(ctx, &priorState)...)
				if resp.Diagnostics.HasError() {
					return
				}

				upgradedState := APICrawlerResourceModel{
					Name:        priorState.Name,
					Namespace:   priorState.Namespace,
					Annotations: priorState.Annotations,
					Labels:      priorState.Labels,
					ID:          priorState.ID,
					Timeouts:    timeouts.Value{},
				}

				resp.Diagnostics.Append(resp.State.Set(ctx, upgradedState)...)
			},
		},
	}
}

func (r *APICrawlerResource) Create(ctx context.Context, req resource.CreateRequest, resp *resource.CreateResponse) {
	var data APICrawlerResourceModel
	resp.Diagnostics.Append(req.Plan.Get(ctx, &data)...)
	if resp.Diagnostics.HasError() {
		return
	}

	createTimeout, diags := data.Timeouts.Create(ctx, inttimeouts.DefaultCreate)
	resp.Diagnostics.Append(diags...)
	if resp.Diagnostics.HasError() {
		return
	}

	ctx, cancel := context.WithTimeout(ctx, createTimeout)
	defer cancel()

	tflog.Debug(ctx, "Creating api_crawler", map[string]interface{}{
		"name":      data.Name.ValueString(),
		"namespace": data.Namespace.ValueString(),
	})

	apiResource := &client.APICrawler{
		Metadata: client.Metadata{
			Name:      data.Name.ValueString(),
			Namespace: data.Namespace.ValueString(),
		},
		Spec: make(map[string]interface{}),
	}

	if !data.Description.IsNull() {
		apiResource.Metadata.Description = data.Description.ValueString()
	}

	if !data.Labels.IsNull() {
		labels := make(map[string]string)
		resp.Diagnostics.Append(data.Labels.ElementsAs(ctx, &labels, false)...)
		if resp.Diagnostics.HasError() {
			return
		}
		apiResource.Metadata.Labels = labels
	}

	if !data.Annotations.IsNull() {
		annotations := make(map[string]string)
		resp.Diagnostics.Append(data.Annotations.ElementsAs(ctx, &annotations, false)...)
		if resp.Diagnostics.HasError() {
			return
		}
		apiResource.Metadata.Annotations = annotations
	}

	// Marshal spec fields from Terraform state to API struct
	if len(data.Domains) > 0 {
		var domainsList []map[string]interface{}
		for _, item := range data.Domains {
			itemMap := make(map[string]interface{})
			if !item.Domain.IsNull() && !item.Domain.IsUnknown() {
				itemMap["domain"] = item.Domain.ValueString()
			}
			if item.SimpleLogin != nil {
				simple_loginNestedMap := make(map[string]interface{})
				if !item.SimpleLogin.User.IsNull() && !item.SimpleLogin.User.IsUnknown() {
					simple_loginNestedMap["user"] = item.SimpleLogin.User.ValueString()
				}
				itemMap["simple_login"] = simple_loginNestedMap
			}
			domainsList = append(domainsList, itemMap)
		}
		apiResource.Spec["domains"] = domainsList
	}


	created, err := r.client.CreateAPICrawler(ctx, apiResource)
	if err != nil {
		resp.Diagnostics.AddError("Client Error", fmt.Sprintf("Unable to create APICrawler: %s", err))
		return
	}

	data.ID = types.StringValue(created.Metadata.Name)

	// Set computed fields from API response

	psd := privatestate.NewPrivateStateData()
	psd.SetCustom("managed", "true")
	tflog.Debug(ctx, "Create: saving private state with managed marker", map[string]interface{}{
		"name": created.Metadata.Name,
	})
	resp.Diagnostics.Append(psd.SaveToPrivateState(ctx, resp)...)

	tflog.Trace(ctx, "created APICrawler resource")
	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}

func (r *APICrawlerResource) Read(ctx context.Context, req resource.ReadRequest, resp *resource.ReadResponse) {
	var data APICrawlerResourceModel
	resp.Diagnostics.Append(req.State.Get(ctx, &data)...)
	if resp.Diagnostics.HasError() {
		return
	}

	readTimeout, diags := data.Timeouts.Read(ctx, inttimeouts.DefaultRead)
	resp.Diagnostics.Append(diags...)
	if resp.Diagnostics.HasError() {
		return
	}

	ctx, cancel := context.WithTimeout(ctx, readTimeout)
	defer cancel()

	psd, psDiags := privatestate.LoadFromPrivateState(ctx, &req)
	resp.Diagnostics.Append(psDiags...)

	apiResource, err := r.client.GetAPICrawler(ctx, data.Namespace.ValueString(), data.Name.ValueString())
	if err != nil {
		// Check if the resource was deleted outside Terraform
		if strings.Contains(err.Error(), "NOT_FOUND") || strings.Contains(err.Error(), "404") {
			tflog.Warn(ctx, "APICrawler not found, removing from state", map[string]interface{}{
				"name":      data.Name.ValueString(),
				"namespace": data.Namespace.ValueString(),
			})
			resp.State.RemoveResource(ctx)
			return
		}
		resp.Diagnostics.AddError("Client Error", fmt.Sprintf("Unable to read APICrawler: %s", err))
		return
	}

	if psd != nil && psd.Metadata.UID != "" && apiResource.Metadata.UID != psd.Metadata.UID {
		resp.Diagnostics.AddWarning(
			"Resource Drift Detected",
			"The api_crawler may have been recreated outside of Terraform.",
		)
	}

	data.ID = types.StringValue(apiResource.Metadata.Name)
	data.Name = types.StringValue(apiResource.Metadata.Name)
	data.Namespace = types.StringValue(apiResource.Metadata.Namespace)

	// Read description from metadata
	if apiResource.Metadata.Description != "" {
		data.Description = types.StringValue(apiResource.Metadata.Description)
	} else {
		data.Description = types.StringNull()
	}

	if len(apiResource.Metadata.Labels) > 0 {
		labels, diags := types.MapValueFrom(ctx, types.StringType, apiResource.Metadata.Labels)
		resp.Diagnostics.Append(diags...)
		if !resp.Diagnostics.HasError() {
			data.Labels = labels
		}
	} else {
		data.Labels = types.MapNull(types.StringType)
	}

	if len(apiResource.Metadata.Annotations) > 0 {
		annotations, diags := types.MapValueFrom(ctx, types.StringType, apiResource.Metadata.Annotations)
		resp.Diagnostics.Append(diags...)
		if !resp.Diagnostics.HasError() {
			data.Annotations = annotations
		}
	} else {
		data.Annotations = types.MapNull(types.StringType)
	}

	// Unmarshal spec fields from API response to Terraform state
	// isImport is true when private state has no "managed" marker (Import case - never went through Create)
	isImport := psd == nil || psd.Metadata.Custom == nil || psd.Metadata.Custom["managed"] != "true"
	_ = isImport // May be unused if resource has no blocks needing import detection
	tflog.Debug(ctx, "Read: checking isImport status", map[string]interface{}{
		"isImport":     isImport,
		"psd_is_nil":   psd == nil,
		"managed":      psd.Metadata.Custom["managed"],
	})
	if listData, ok := apiResource.Spec["domains"].([]interface{}); ok && len(listData) > 0 {
		var domainsList []APICrawlerDomainsModel
		for _, item := range listData {
			if itemMap, ok := item.(map[string]interface{}); ok {
				domainsList = append(domainsList, APICrawlerDomainsModel{
					Domain: func() types.String {
						if v, ok := itemMap["domain"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
					SimpleLogin: func() *APICrawlerDomainsSimpleLoginModel {
						if nestedMap, ok := itemMap["simple_login"].(map[string]interface{}); ok {
							return &APICrawlerDomainsSimpleLoginModel{
								User: func() types.String {
									if v, ok := nestedMap["user"].(string); ok && v != "" {
										return types.StringValue(v)
									}
									return types.StringNull()
								}(),
							}
						}
						return nil
					}(),
				})
			}
		}
		data.Domains = domainsList
	}


	// Preserve or set the managed marker for future Read operations
	newPsd := privatestate.NewPrivateStateData()
	newPsd.SetUID(apiResource.Metadata.UID)
	if !isImport {
		// Preserve the managed marker if we already had it
		newPsd.SetCustom("managed", "true")
	}
	resp.Diagnostics.Append(newPsd.SaveToPrivateState(ctx, resp)...)

	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}

func (r *APICrawlerResource) Update(ctx context.Context, req resource.UpdateRequest, resp *resource.UpdateResponse) {
	var data APICrawlerResourceModel
	resp.Diagnostics.Append(req.Plan.Get(ctx, &data)...)
	if resp.Diagnostics.HasError() {
		return
	}

	updateTimeout, diags := data.Timeouts.Update(ctx, inttimeouts.DefaultUpdate)
	resp.Diagnostics.Append(diags...)
	if resp.Diagnostics.HasError() {
		return
	}

	ctx, cancel := context.WithTimeout(ctx, updateTimeout)
	defer cancel()

	apiResource := &client.APICrawler{
		Metadata: client.Metadata{
			Name:      data.Name.ValueString(),
			Namespace: data.Namespace.ValueString(),
		},
		Spec: make(map[string]interface{}),
	}

	if !data.Description.IsNull() {
		apiResource.Metadata.Description = data.Description.ValueString()
	}

	if !data.Labels.IsNull() {
		labels := make(map[string]string)
		resp.Diagnostics.Append(data.Labels.ElementsAs(ctx, &labels, false)...)
		if resp.Diagnostics.HasError() {
			return
		}
		apiResource.Metadata.Labels = labels
	}

	if !data.Annotations.IsNull() {
		annotations := make(map[string]string)
		resp.Diagnostics.Append(data.Annotations.ElementsAs(ctx, &annotations, false)...)
		if resp.Diagnostics.HasError() {
			return
		}
		apiResource.Metadata.Annotations = annotations
	}

	// Marshal spec fields from Terraform state to API struct
	if len(data.Domains) > 0 {
		var domainsList []map[string]interface{}
		for _, item := range data.Domains {
			itemMap := make(map[string]interface{})
			if !item.Domain.IsNull() && !item.Domain.IsUnknown() {
				itemMap["domain"] = item.Domain.ValueString()
			}
			if item.SimpleLogin != nil {
				simple_loginNestedMap := make(map[string]interface{})
				if !item.SimpleLogin.User.IsNull() && !item.SimpleLogin.User.IsUnknown() {
					simple_loginNestedMap["user"] = item.SimpleLogin.User.ValueString()
				}
				itemMap["simple_login"] = simple_loginNestedMap
			}
			domainsList = append(domainsList, itemMap)
		}
		apiResource.Spec["domains"] = domainsList
	}


	updated, err := r.client.UpdateAPICrawler(ctx, apiResource)
	if err != nil {
		resp.Diagnostics.AddError("Client Error", fmt.Sprintf("Unable to update APICrawler: %s", err))
		return
	}

	// Use plan data for ID since API response may not include metadata.name
	data.ID = types.StringValue(data.Name.ValueString())

	// Set computed fields from API response

	psd := privatestate.NewPrivateStateData()
	// Use UID from response if available, otherwise preserve from plan
	uid := updated.Metadata.UID
	if uid == "" {
		// If API doesn't return UID, we need to fetch it
		fetched, fetchErr := r.client.GetAPICrawler(ctx, data.Namespace.ValueString(), data.Name.ValueString())
		if fetchErr == nil {
			uid = fetched.Metadata.UID
		}
	}
	psd.SetUID(uid)
	psd.SetCustom("managed", "true") // Preserve managed marker after Update
	resp.Diagnostics.Append(psd.SaveToPrivateState(ctx, resp)...)

	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}

func (r *APICrawlerResource) Delete(ctx context.Context, req resource.DeleteRequest, resp *resource.DeleteResponse) {
	var data APICrawlerResourceModel
	resp.Diagnostics.Append(req.State.Get(ctx, &data)...)
	if resp.Diagnostics.HasError() {
		return
	}

	deleteTimeout, diags := data.Timeouts.Delete(ctx, inttimeouts.DefaultDelete)
	resp.Diagnostics.Append(diags...)
	if resp.Diagnostics.HasError() {
		return
	}

	ctx, cancel := context.WithTimeout(ctx, deleteTimeout)
	defer cancel()
	err := r.client.DeleteAPICrawler(ctx, data.Namespace.ValueString(), data.Name.ValueString())
	if err != nil {
		// If the resource is already gone, consider deletion successful (idempotent delete)
		if strings.Contains(err.Error(), "NOT_FOUND") || strings.Contains(err.Error(), "404") {
			tflog.Warn(ctx, "APICrawler already deleted, removing from state", map[string]interface{}{
				"name":      data.Name.ValueString(),
				"namespace": data.Namespace.ValueString(),
			})
			return
		}
		// If delete is not implemented (501), warn and remove from state
		// Some F5 XC resources don't support deletion via API
		if strings.Contains(err.Error(), "501") {
			tflog.Warn(ctx, "APICrawler delete not supported by API (501), removing from state only", map[string]interface{}{
				"name":      data.Name.ValueString(),
				"namespace": data.Namespace.ValueString(),
			})
			return
		}
		resp.Diagnostics.AddError("Client Error", fmt.Sprintf("Unable to delete APICrawler: %s", err))
		return
	}
}

func (r *APICrawlerResource) ImportState(ctx context.Context, req resource.ImportStateRequest, resp *resource.ImportStateResponse) {
	// Import ID format: namespace/name
	parts := strings.Split(req.ID, "/")
	if len(parts) != 2 || parts[0] == "" || parts[1] == "" {
		resp.Diagnostics.AddError(
			"Invalid Import ID",
			fmt.Sprintf("Expected import ID format: namespace/name, got: %s", req.ID),
		)
		return
	}
	namespace := parts[0]
	name := parts[1]

	resp.Diagnostics.Append(resp.State.SetAttribute(ctx, path.Root("namespace"), namespace)...)
	resp.Diagnostics.Append(resp.State.SetAttribute(ctx, path.Root("name"), name)...)
	resp.Diagnostics.Append(resp.State.SetAttribute(ctx, path.Root("id"), name)...)
}
