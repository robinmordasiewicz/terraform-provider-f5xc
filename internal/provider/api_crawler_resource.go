// Code generated by generate-all-schemas.go. DO NOT EDIT.
// Source: F5 XC OpenAPI specification

package provider

import (
	"context"
	"fmt"

	"github.com/hashicorp/terraform-plugin-framework/path"
	"github.com/hashicorp/terraform-plugin-framework/resource"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/planmodifier"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/stringplanmodifier"
	"github.com/hashicorp/terraform-plugin-framework/schema/validator"
	"github.com/hashicorp/terraform-plugin-framework/types"
	"github.com/hashicorp/terraform-plugin-log/tflog"

	"github.com/f5xc/terraform-provider-f5xc/internal/client"
	"github.com/f5xc/terraform-provider-f5xc/internal/validators"
)

var (
	_ resource.Resource                = &APICrawlerResource{}
	_ resource.ResourceWithConfigure   = &APICrawlerResource{}
	_ resource.ResourceWithImportState = &APICrawlerResource{}
)

func NewAPICrawlerResource() resource.Resource {
	return &APICrawlerResource{}
}

type APICrawlerResource struct {
	client *client.Client
}

type APICrawlerResourceModel struct {
	Name types.String `tfsdk:"name"`
	Namespace types.String `tfsdk:"namespace"`
	Annotations types.Map `tfsdk:"annotations"`
	Labels types.Map `tfsdk:"labels"`
	ID types.String `tfsdk:"id"`
}

func (r *APICrawlerResource) Metadata(ctx context.Context, req resource.MetadataRequest, resp *resource.MetadataResponse) {
	resp.TypeName = req.ProviderTypeName + "_api_crawler"
}

func (r *APICrawlerResource) Schema(ctx context.Context, req resource.SchemaRequest, resp *resource.SchemaResponse) {
	resp.Schema = schema.Schema{
		MarkdownDescription: "Manages a APICrawler resource in F5 Distributed Cloud.",
		Attributes: map[string]schema.Attribute{
			"name": schema.StringAttribute{
				MarkdownDescription: "Name of the APICrawler. Must be unique within the namespace.",
				Required: true,
				PlanModifiers: []planmodifier.String{
					stringplanmodifier.RequiresReplace(),
				},
				Validators: []validator.String{
					validators.NameValidator(),
				},
			},
			"namespace": schema.StringAttribute{
				MarkdownDescription: "Namespace where the APICrawler will be created.",
				Required: true,
				PlanModifiers: []planmodifier.String{
					stringplanmodifier.RequiresReplace(),
				},
				Validators: []validator.String{
					validators.NamespaceValidator(),
				},
			},
			"annotations": schema.MapAttribute{
				MarkdownDescription: "Annotations to apply to this resource.",
				Optional: true,
				ElementType: types.StringType,
			},
			"labels": schema.MapAttribute{
				MarkdownDescription: "Labels to apply to this resource.",
				Optional: true,
				ElementType: types.StringType,
			},
			"id": schema.StringAttribute{
				MarkdownDescription: "Unique identifier for the resource.",
				Computed: true,
				PlanModifiers: []planmodifier.String{
					stringplanmodifier.UseStateForUnknown(),
				},
			},
		},
		Blocks: map[string]schema.Block{
			"domains": schema.ListNestedBlock{
				MarkdownDescription: "API Crawler. API Crawler Configuration",
				NestedObject: schema.NestedBlockObject{
					Attributes: map[string]schema.Attribute{
						"domain": schema.StringAttribute{
							MarkdownDescription: "Domains to Crawl. Select the domain to execute API Crawling with given credentials.",
							Optional: true,
						},
					},
					Blocks: map[string]schema.Block{
						"simple_login": schema.SingleNestedBlock{
							MarkdownDescription: "Simple Login.",
							Attributes: map[string]schema.Attribute{
								"user": schema.StringAttribute{
									MarkdownDescription: "User. Enter the username to assign credentials for the selected domain to crawl",
									Optional: true,
								},
							},
							Blocks: map[string]schema.Block{
								"password": schema.SingleNestedBlock{
									MarkdownDescription: "Secret. SecretType is used in an object to indicate a sensitive/confidential field",
									Attributes: map[string]schema.Attribute{
									},
									Blocks: map[string]schema.Block{
										"blindfold_secret_info": schema.SingleNestedBlock{
											MarkdownDescription: "Blindfold Secret. BlindfoldSecretInfoType specifies information about the Secret managed by F5XC Secret Management",
										},
										"clear_secret_info": schema.SingleNestedBlock{
											MarkdownDescription: "In-Clear Secret. ClearSecretInfoType specifies information about the Secret that is not encrypted.",
										},
									},
								},
							},
						},
					},

				},
			},
		},
	}
}

func (r *APICrawlerResource) Configure(ctx context.Context, req resource.ConfigureRequest, resp *resource.ConfigureResponse) {
	if req.ProviderData == nil {
		return
	}
	client, ok := req.ProviderData.(*client.Client)
	if !ok {
		resp.Diagnostics.AddError(
			"Unexpected Resource Configure Type",
			fmt.Sprintf("Expected *client.Client, got: %T", req.ProviderData),
		)
		return
	}
	r.client = client
}

func (r *APICrawlerResource) Create(ctx context.Context, req resource.CreateRequest, resp *resource.CreateResponse) {
	var data APICrawlerResourceModel
	resp.Diagnostics.Append(req.Plan.Get(ctx, &data)...)
	if resp.Diagnostics.HasError() {
		return
	}

	apiResource := &client.APICrawler{
		Metadata: client.Metadata{
			Name:      data.Name.ValueString(),
			Namespace: data.Namespace.ValueString(),
		},
		Spec: client.APICrawlerSpec{},
	}

	if !data.Labels.IsNull() {
		labels := make(map[string]string)
		resp.Diagnostics.Append(data.Labels.ElementsAs(ctx, &labels, false)...)
		if resp.Diagnostics.HasError() {
			return
		}
		apiResource.Metadata.Labels = labels
	}

	if !data.Annotations.IsNull() {
		annotations := make(map[string]string)
		resp.Diagnostics.Append(data.Annotations.ElementsAs(ctx, &annotations, false)...)
		if resp.Diagnostics.HasError() {
			return
		}
		apiResource.Metadata.Annotations = annotations
	}

	created, err := r.client.CreateAPICrawler(ctx, apiResource)
	if err != nil {
		resp.Diagnostics.AddError("Client Error", fmt.Sprintf("Unable to create APICrawler: %s", err))
		return
	}

	data.ID = types.StringValue(created.Metadata.Name)
	tflog.Trace(ctx, "created APICrawler resource")
	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}

func (r *APICrawlerResource) Read(ctx context.Context, req resource.ReadRequest, resp *resource.ReadResponse) {
	var data APICrawlerResourceModel
	resp.Diagnostics.Append(req.State.Get(ctx, &data)...)
	if resp.Diagnostics.HasError() {
		return
	}

	apiResource, err := r.client.GetAPICrawler(ctx, data.Namespace.ValueString(), data.Name.ValueString())
	if err != nil {
		resp.Diagnostics.AddError("Client Error", fmt.Sprintf("Unable to read APICrawler: %s", err))
		return
	}

	data.ID = types.StringValue(apiResource.Metadata.Name)
	data.Name = types.StringValue(apiResource.Metadata.Name)
	data.Namespace = types.StringValue(apiResource.Metadata.Namespace)

	if len(apiResource.Metadata.Labels) > 0 {
		labels, diags := types.MapValueFrom(ctx, types.StringType, apiResource.Metadata.Labels)
		resp.Diagnostics.Append(diags...)
		if !resp.Diagnostics.HasError() {
			data.Labels = labels
		}
	} else {
		data.Labels = types.MapNull(types.StringType)
	}

	if len(apiResource.Metadata.Annotations) > 0 {
		annotations, diags := types.MapValueFrom(ctx, types.StringType, apiResource.Metadata.Annotations)
		resp.Diagnostics.Append(diags...)
		if !resp.Diagnostics.HasError() {
			data.Annotations = annotations
		}
	} else {
		data.Annotations = types.MapNull(types.StringType)
	}

	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}

func (r *APICrawlerResource) Update(ctx context.Context, req resource.UpdateRequest, resp *resource.UpdateResponse) {
	var data APICrawlerResourceModel
	resp.Diagnostics.Append(req.Plan.Get(ctx, &data)...)
	if resp.Diagnostics.HasError() {
		return
	}

	apiResource := &client.APICrawler{
		Metadata: client.Metadata{
			Name:      data.Name.ValueString(),
			Namespace: data.Namespace.ValueString(),
		},
		Spec: client.APICrawlerSpec{},
	}

	if !data.Labels.IsNull() {
		labels := make(map[string]string)
		resp.Diagnostics.Append(data.Labels.ElementsAs(ctx, &labels, false)...)
		if resp.Diagnostics.HasError() {
			return
		}
		apiResource.Metadata.Labels = labels
	}

	if !data.Annotations.IsNull() {
		annotations := make(map[string]string)
		resp.Diagnostics.Append(data.Annotations.ElementsAs(ctx, &annotations, false)...)
		if resp.Diagnostics.HasError() {
			return
		}
		apiResource.Metadata.Annotations = annotations
	}

	updated, err := r.client.UpdateAPICrawler(ctx, apiResource)
	if err != nil {
		resp.Diagnostics.AddError("Client Error", fmt.Sprintf("Unable to update APICrawler: %s", err))
		return
	}

	data.ID = types.StringValue(updated.Metadata.Name)
	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}

func (r *APICrawlerResource) Delete(ctx context.Context, req resource.DeleteRequest, resp *resource.DeleteResponse) {
	var data APICrawlerResourceModel
	resp.Diagnostics.Append(req.State.Get(ctx, &data)...)
	if resp.Diagnostics.HasError() {
		return
	}

	err := r.client.DeleteAPICrawler(ctx, data.Namespace.ValueString(), data.Name.ValueString())
	if err != nil {
		resp.Diagnostics.AddError("Client Error", fmt.Sprintf("Unable to delete APICrawler: %s", err))
		return
	}
}

func (r *APICrawlerResource) ImportState(ctx context.Context, req resource.ImportStateRequest, resp *resource.ImportStateResponse) {
	resource.ImportStatePassthroughID(ctx, path.Root("id"), req, resp)
}
