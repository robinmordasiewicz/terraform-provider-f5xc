// Code generated by generate-all-schemas.go. DO NOT EDIT.
// Source: F5 XC OpenAPI specification

package provider

import (
	"context"
	"fmt"

	"github.com/hashicorp/terraform-plugin-framework-timeouts/resource/timeouts"
	"github.com/hashicorp/terraform-plugin-framework/path"
	"github.com/hashicorp/terraform-plugin-framework/resource"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/planmodifier"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/stringplanmodifier"
	"github.com/hashicorp/terraform-plugin-framework/schema/validator"
	"github.com/hashicorp/terraform-plugin-framework/types"
	"github.com/hashicorp/terraform-plugin-log/tflog"

	"github.com/f5xc/terraform-provider-f5xc/internal/client"
	"github.com/f5xc/terraform-provider-f5xc/internal/privatestate"
	inttimeouts "github.com/f5xc/terraform-provider-f5xc/internal/timeouts"
	"github.com/f5xc/terraform-provider-f5xc/internal/validators"
)

// Ensure provider defined types fully satisfy framework interfaces.
var (
	_ resource.Resource                   = &ClusterResource{}
	_ resource.ResourceWithConfigure      = &ClusterResource{}
	_ resource.ResourceWithImportState    = &ClusterResource{}
	_ resource.ResourceWithModifyPlan     = &ClusterResource{}
	_ resource.ResourceWithUpgradeState   = &ClusterResource{}
	_ resource.ResourceWithValidateConfig = &ClusterResource{}
)

// clusterSchemaVersion is the schema version for state upgrades
const clusterSchemaVersion int64 = 1

func NewClusterResource() resource.Resource {
	return &ClusterResource{}
}

type ClusterResource struct {
	client *client.Client
}

type ClusterResourceModel struct {
	Name types.String `tfsdk:"name"`
	Namespace types.String `tfsdk:"namespace"`
	Annotations types.Map `tfsdk:"annotations"`
	ConnectionTimeout types.Int64 `tfsdk:"connection_timeout"`
	EndpointSelection types.String `tfsdk:"endpoint_selection"`
	FallbackPolicy types.String `tfsdk:"fallback_policy"`
	HTTPIdleTimeout types.Int64 `tfsdk:"http_idle_timeout"`
	Labels types.Map `tfsdk:"labels"`
	LoadBalancerAlgorithm types.String `tfsdk:"loadbalancer_algorithm"`
	PanicThreshold types.Int64 `tfsdk:"panic_threshold"`
	ID types.String `tfsdk:"id"`
	Timeouts timeouts.Value `tfsdk:"timeouts"`
}

func (r *ClusterResource) Metadata(ctx context.Context, req resource.MetadataRequest, resp *resource.MetadataResponse) {
	resp.TypeName = req.ProviderTypeName + "_cluster"
}

func (r *ClusterResource) Schema(ctx context.Context, req resource.SchemaRequest, resp *resource.SchemaResponse) {
	resp.Schema = schema.Schema{
		Version:             clusterSchemaVersion,
		MarkdownDescription: "Manages cluster will create the object in the storage backend for namespace metadata.namespace in F5 Distributed Cloud.",
		Attributes: map[string]schema.Attribute{
			"name": schema.StringAttribute{
				MarkdownDescription: "Name of the Cluster. Must be unique within the namespace.",
				Required: true,
				PlanModifiers: []planmodifier.String{
					stringplanmodifier.RequiresReplace(),
				},
				Validators: []validator.String{
					validators.NameValidator(),
				},
			},
			"namespace": schema.StringAttribute{
				MarkdownDescription: "Namespace where the Cluster will be created.",
				Required: true,
				PlanModifiers: []planmodifier.String{
					stringplanmodifier.RequiresReplace(),
				},
				Validators: []validator.String{
					validators.NamespaceValidator(),
				},
			},
			"annotations": schema.MapAttribute{
				MarkdownDescription: "Annotations to apply to this resource.",
				Optional: true,
				ElementType: types.StringType,
			},
			"connection_timeout": schema.Int64Attribute{
				MarkdownDescription: "Connection Timeout. The timeout for new network connections to endpoints in the cluster. This is specified in milliseconds. The default value is 2 seconds",
				Optional: true,
			},
			"endpoint_selection": schema.StringAttribute{
				MarkdownDescription: "Endpoint Selection Policy. Policy for selection of endpoints from local site/remote site/both Consider both remote and local endpoints for load balancing LOCAL_ONLY: Consider only local endpoints for load balancing Enable this policy to load balance ONLY among locally discovered endpoints Prefer the local endpoints for load balancing. If local endpoints are not present remote endpoints will be considered. Possible values are `DISTRIBUTED`, `LOCAL_ONLY`, `LOCAL_PREFERRED`. Defaults to `DISTRIBUTED`.",
				Optional: true,
			},
			"fallback_policy": schema.StringAttribute{
				MarkdownDescription: "Subset Fallback Policy. Enumeration for SubsetFallbackPolicy if subset match is not found. The request fails as if the cluster had no endpoint matching the subset policy Any cluster endpoint may be selected if the cluster had no endpoint matching the subset policy Load balancing is done over endpoints matching default_subset if the cluster had no endpoint matching the subset policy. Possible values are `NO_FALLBACK`, `ANY_ENDPOINT`, `DEFAULT_SUBSET`. Defaults to `NO_FALLBACK`.",
				Optional: true,
			},
			"http_idle_timeout": schema.Int64Attribute{
				MarkdownDescription: "HTTP Idle Timeout. The idle timeout for upstream connection pool connections. The idle timeout is defined as the period in which there are no active requests. When the idle timeout is reached the connection will be closed. Note that request based timeouts mean that HTTP/2 PINGs will not keep the connection alive. This is specified in milliseconds. The default value is 5 minutes.",
				Optional: true,
			},
			"labels": schema.MapAttribute{
				MarkdownDescription: "Labels to apply to this resource.",
				Optional: true,
				ElementType: types.StringType,
			},
			"loadbalancer_algorithm": schema.StringAttribute{
				MarkdownDescription: "Load Balancer Algorithm. Different load balancing algorithms supported When a connection to a endpoint in an upstream cluster is required, the load balancer uses loadbalancer_algorithm to determine which host is selected. - ROUND_ROBIN: ROUND_ROBIN Policy in which each healthy/available upstream endpoint is selected in round robin order. - LEAST_REQUEST: LEAST_REQUEST Policy in which loadbalancer picks the upstream endpoint which has the fewest active requests - RING_HASH: RING_HASH Policy im... Possible values are `ROUND_ROBIN`, `LEAST_REQUEST`, `RING_HASH`, `RANDOM`, `LB_OVERRIDE`. Defaults to `ROUND_ROBIN`.",
				Optional: true,
			},
			"panic_threshold": schema.Int64Attribute{
				MarkdownDescription: "Panic threshold. Configure a threshold (percentage of unhealthy endpoints) below which all endpoints will be considered for loadbalancing ignoring its health status.",
				Optional: true,
			},
			"id": schema.StringAttribute{
				MarkdownDescription: "Unique identifier for the resource.",
				Computed: true,
				PlanModifiers: []planmodifier.String{
					stringplanmodifier.UseStateForUnknown(),
				},
			},
		},
		Blocks: map[string]schema.Block{
			"timeouts": timeouts.Block(ctx, timeouts.Opts{
				Create: true,
				Read:   true,
				Update: true,
				Delete: true,
			}),
			"auto_http_config": schema.SingleNestedBlock{
				MarkdownDescription: "[OneOf: auto_http_config, http1_config, http2_options] Empty. This can be used for messages where no values are needed",
			},
			"circuit_breaker": schema.SingleNestedBlock{
				MarkdownDescription: "Circuit Breaker. CircuitBreaker provides a mechanism for watching failures in upstream connections or requests and if the failures reach a certain threshold, automatically fail subsequent requests which allows to apply back pressure on downstream quickly.",
				Attributes: map[string]schema.Attribute{
					"connection_limit": schema.Int64Attribute{
						MarkdownDescription: "Connection Limit. The maximum number of connections that loadbalancer will establish to all hosts in an upstream cluster. In practice this is only applicable to TCP and HTTP/1.1 clusters since HTTP/2 uses a single connection to each host. Remove endpoint out of load balancing decision, if number of connections reach connection limit.",
						Optional: true,
					},
					"max_requests": schema.Int64Attribute{
						MarkdownDescription: "Maximum Request Count. The maximum number of requests that can be outstanding to all hosts in a cluster at any given time. In practice this is applicable to HTTP/2 clusters since HTTP/1.1 clusters are governed by the maximum connections (connection_limit). Remove endpoint out of load balancing decision, if requests exceed this count.",
						Optional: true,
					},
					"pending_requests": schema.Int64Attribute{
						MarkdownDescription: "Pending Requests. The maximum number of requests that will be queued while waiting for a ready connection pool connection. Since HTTP/2 requests are sent over a single connection, this circuit breaker only comes into play as the initial connection is created, as requests will be multiplexed immediately afterwards. For HTTP/1.1, requests are added to the list of pending requests whenever there aren’t enough upstream connections available to immediately dispatch the request, so this circuit b...",
						Optional: true,
					},
					"priority": schema.StringAttribute{
						MarkdownDescription: "Routing Priority. Priority routing for each request. Different connection pools are used based on the priority selected for the request. Also, circuit-breaker configuration at destination cluster is chosen based on selected priority. Default routing mechanism High-Priority routing mechanism. Possible values are `DEFAULT`, `HIGH`. Defaults to `DEFAULT`.",
						Optional: true,
					},
					"retries": schema.Int64Attribute{
						MarkdownDescription: "Retry Count. The maximum number of retries that can be outstanding to all hosts in a cluster at any given time. Remove endpoint out of load balancing decision, if retries for request exceed this count.",
						Optional: true,
					},
				},

			},
			"default_subset": schema.SingleNestedBlock{
				MarkdownDescription: "Default Subset. List of key-value pairs that define default subset. This subset can be referred in fallback_policy which gets used when route specifies no metadata or no subset matching the metadata exists.",
			},
			"disable_proxy_protocol": schema.SingleNestedBlock{
				MarkdownDescription: "[OneOf: disable_proxy_protocol, proxy_protocol_v1, proxy_protocol_v2] Empty. This can be used for messages where no values are needed",
			},
			"endpoint_subsets": schema.ListNestedBlock{
				MarkdownDescription: "Endpoint Subsets. Cluster may be configured to divide its endpoints into subsets based on metadata attached to the endpoints. Routes may then specify the metadata that a endpoint must match in order to be selected by the load balancer. endpoint_subsets is list of subsets for this cluster. Each entry in this list has definition for a subset (which is collection of keys) During routing, the route’s metadata match configuration is used to find a specific subset. If there is a subset with the e...",
				NestedObject: schema.NestedBlockObject{
					Attributes: map[string]schema.Attribute{
						"keys": schema.ListAttribute{
							MarkdownDescription: "Keys. List of keys that define a cluster subset class.",
							Optional: true,
							ElementType: types.StringType,
						},
					},

				},
			},
			"endpoints": schema.ListNestedBlock{
				MarkdownDescription: "Endpoints. List of references to all endpoint objects that belong to this cluster.",
				NestedObject: schema.NestedBlockObject{
					Attributes: map[string]schema.Attribute{
						"kind": schema.StringAttribute{
							MarkdownDescription: "Kind. When a configuration object(e.g. virtual_host) refers to another(e.g route) then kind will hold the referred object's kind (e.g. 'route')",
							Optional: true,
						},
						"name": schema.StringAttribute{
							MarkdownDescription: "Name. When a configuration object(e.g. virtual_host) refers to another(e.g route) then name will hold the referred object's(e.g. route's) name.",
							Optional: true,
						},
						"namespace": schema.StringAttribute{
							MarkdownDescription: "Namespace. When a configuration object(e.g. virtual_host) refers to another(e.g route) then namespace will hold the referred object's(e.g. route's) namespace.",
							Optional: true,
						},
						"tenant": schema.StringAttribute{
							MarkdownDescription: "Tenant. When a configuration object(e.g. virtual_host) refers to another(e.g route) then tenant will hold the referred object's(e.g. route's) tenant.",
							Optional: true,
						},
						"uid": schema.StringAttribute{
							MarkdownDescription: "UID. When a configuration object(e.g. virtual_host) refers to another(e.g route) then uid will hold the referred object's(e.g. route's) uid.",
							Optional: true,
						},
					},

				},
			},
			"health_checks": schema.ListNestedBlock{
				MarkdownDescription: "Health Checks. List of references to healthcheck object for this cluster.",
				NestedObject: schema.NestedBlockObject{
					Attributes: map[string]schema.Attribute{
						"kind": schema.StringAttribute{
							MarkdownDescription: "Kind. When a configuration object(e.g. virtual_host) refers to another(e.g route) then kind will hold the referred object's kind (e.g. 'route')",
							Optional: true,
						},
						"name": schema.StringAttribute{
							MarkdownDescription: "Name. When a configuration object(e.g. virtual_host) refers to another(e.g route) then name will hold the referred object's(e.g. route's) name.",
							Optional: true,
						},
						"namespace": schema.StringAttribute{
							MarkdownDescription: "Namespace. When a configuration object(e.g. virtual_host) refers to another(e.g route) then namespace will hold the referred object's(e.g. route's) namespace.",
							Optional: true,
						},
						"tenant": schema.StringAttribute{
							MarkdownDescription: "Tenant. When a configuration object(e.g. virtual_host) refers to another(e.g route) then tenant will hold the referred object's(e.g. route's) tenant.",
							Optional: true,
						},
						"uid": schema.StringAttribute{
							MarkdownDescription: "UID. When a configuration object(e.g. virtual_host) refers to another(e.g route) then uid will hold the referred object's(e.g. route's) uid.",
							Optional: true,
						},
					},

				},
			},
			"http1_config": schema.SingleNestedBlock{
				MarkdownDescription: "HTTP/1.1 Protocol Options. HTTP/1.1 Protocol options for upstream connections",
				Attributes: map[string]schema.Attribute{
				},
				Blocks: map[string]schema.Block{
					"header_transformation": schema.SingleNestedBlock{
						MarkdownDescription: "Header Transformation. Header Transformation options for HTTP/1.1 request/response headers",
						Attributes: map[string]schema.Attribute{
						},
						Blocks: map[string]schema.Block{
							"default_header_transformation": schema.SingleNestedBlock{
								MarkdownDescription: "Empty. This can be used for messages where no values are needed",
							},
							"legacy_header_transformation": schema.SingleNestedBlock{
								MarkdownDescription: "Empty. This can be used for messages where no values are needed",
							},
							"preserve_case_header_transformation": schema.SingleNestedBlock{
								MarkdownDescription: "Empty. This can be used for messages where no values are needed",
							},
							"proper_case_header_transformation": schema.SingleNestedBlock{
								MarkdownDescription: "Empty. This can be used for messages where no values are needed",
							},
						},
					},
				},

			},
			"http2_options": schema.SingleNestedBlock{
				MarkdownDescription: "Http2 Protocol Options. Http2 Protocol options for upstream connections",
				Attributes: map[string]schema.Attribute{
					"enabled": schema.BoolAttribute{
						MarkdownDescription: "HTTP2 Enabled. Enable/disable HTTP2 Protocol for upstream connections",
						Optional: true,
					},
				},

			},
			"no_panic_threshold": schema.SingleNestedBlock{
				MarkdownDescription: "[OneOf: no_panic_threshold, panic_threshold] Empty. This can be used for messages where no values are needed",
			},
			"outlier_detection": schema.SingleNestedBlock{
				MarkdownDescription: "Outlier Detection. Outlier detection and ejection is the process of dynamically determining whether some number of hosts in an upstream cluster are performing unlike the others and removing them from the healthy load balancing set. Outlier detection is a form of passive health checking. Algorithm 1. A endpoint is determined to be an outlier (based on configured number of consecutive_5xx or consecutive_gateway_failures) . 2. If no endpoints have been ejected, loadbalancer will eject the host i...",
				Attributes: map[string]schema.Attribute{
					"base_ejection_time": schema.Int64Attribute{
						MarkdownDescription: "Base Ejection Time. The base time that a host is ejected for. The real time is equal to the base time multiplied by the number of times the host has been ejected. This causes hosts to get ejected for longer periods if they continue to fail. Defaults to 30000ms or 30s. Specified in milliseconds.",
						Optional: true,
					},
					"consecutive_5xx": schema.Int64Attribute{
						MarkdownDescription: "Consecutive 5xx Count. If an upstream endpoint returns some number of consecutive 5xx, it will be ejected. Note that in this case a 5xx means an actual 5xx respond code, or an event that would cause the HTTP router to return one on the upstream’s behalf(reset, connection failure, etc.) consecutive_5xx indicates the number of consecutive 5xx responses required before a consecutive 5xx ejection occurs. Defaults to 5.",
						Optional: true,
					},
					"consecutive_gateway_failure": schema.Int64Attribute{
						MarkdownDescription: "Consecutive Gateway Failure. If an upstream endpoint returns some number of consecutive “gateway errors” (502, 503 or 504 status code), it will be ejected. Note that this includes events that would cause the HTTP router to return one of these status codes on the upstream’s behalf (reset, connection failure, etc.). consecutive_gateway_failure indicates the number of consecutive gateway failures before a consecutive gateway failure ejection occurs. Defaults to 5.",
						Optional: true,
					},
					"interval": schema.Int64Attribute{
						MarkdownDescription: "Interval. The time interval between ejection analysis sweeps. This can result in both new ejections as well as endpoints being returned to service. Defaults to 10000ms or 10s. Specified in milliseconds.",
						Optional: true,
					},
					"max_ejection_percent": schema.Int64Attribute{
						MarkdownDescription: "Max Ejection Percentage. The maximum % of an upstream cluster that can be ejected due to outlier detection. Defaults to 10% but will eject at least one host regardless of the value.",
						Optional: true,
					},
				},

			},
			"proxy_protocol_v1": schema.SingleNestedBlock{
				MarkdownDescription: "Empty. This can be used for messages where no values are needed",
			},
			"proxy_protocol_v2": schema.SingleNestedBlock{
				MarkdownDescription: "Empty. This can be used for messages where no values are needed",
			},
			"tls_parameters": schema.SingleNestedBlock{
				MarkdownDescription: "Upstream TLS Parameters. TLS configuration for upstream connections",
				Attributes: map[string]schema.Attribute{
					"max_session_keys": schema.Int64Attribute{
						MarkdownDescription: "Max Session Keys Cached. x-example:'25' Number of session keys that are cached.",
						Optional: true,
					},
					"sni": schema.StringAttribute{
						MarkdownDescription: "SNI Value. SNI value to be used.",
						Optional: true,
					},
				},
				Blocks: map[string]schema.Block{
					"cert_params": schema.SingleNestedBlock{
						MarkdownDescription: "Upstream Certificate Parameters. Certificate Parameters for authentication, TLS ciphers, and trust store",
						Attributes: map[string]schema.Attribute{
							"cipher_suites": schema.ListAttribute{
								MarkdownDescription: "Cipher Suites. The following list specifies the supported cipher suite TLS_AES_128_GCM_SHA256 TLS_AES_256_GCM_SHA384 TLS_CHACHA20_POLY1305_SHA256 TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256 TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384 TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256 TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256 TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA TLS_ECDHE_RSA_WITH_AES_128_CBC_...",
								Optional: true,
								ElementType: types.StringType,
							},
							"maximum_protocol_version": schema.StringAttribute{
								MarkdownDescription: "TLS Protocol. TlsProtocol is enumeration of supported TLS versions F5 Distributed Cloud will choose the optimal TLS version. Possible values are `TLS_AUTO`, `TLSv1_0`, `TLSv1_1`, `TLSv1_2`, `TLSv1_3`. Defaults to `TLS_AUTO`.",
								Optional: true,
							},
							"minimum_protocol_version": schema.StringAttribute{
								MarkdownDescription: "TLS Protocol. TlsProtocol is enumeration of supported TLS versions F5 Distributed Cloud will choose the optimal TLS version. Possible values are `TLS_AUTO`, `TLSv1_0`, `TLSv1_1`, `TLSv1_2`, `TLSv1_3`. Defaults to `TLS_AUTO`.",
								Optional: true,
							},
						},
						Blocks: map[string]schema.Block{
							"certificates": schema.ListNestedBlock{
								MarkdownDescription: "Client Certificate. Client TLS Certificate required for mTLS authentication",
								NestedObject: schema.NestedBlockObject{
									Attributes: map[string]schema.Attribute{
										"kind": schema.StringAttribute{
											MarkdownDescription: "Kind. When a configuration object(e.g. virtual_host) refers to another(e.g route) then kind will hold the referred object's kind (e.g. 'route')",
											Optional: true,
										},
										"name": schema.StringAttribute{
											MarkdownDescription: "Name. When a configuration object(e.g. virtual_host) refers to another(e.g route) then name will hold the referred object's(e.g. route's) name.",
											Optional: true,
										},
										"namespace": schema.StringAttribute{
											MarkdownDescription: "Namespace. When a configuration object(e.g. virtual_host) refers to another(e.g route) then namespace will hold the referred object's(e.g. route's) namespace.",
											Optional: true,
										},
										"tenant": schema.StringAttribute{
											MarkdownDescription: "Tenant. When a configuration object(e.g. virtual_host) refers to another(e.g route) then tenant will hold the referred object's(e.g. route's) tenant.",
											Optional: true,
										},
										"uid": schema.StringAttribute{
											MarkdownDescription: "UID. When a configuration object(e.g. virtual_host) refers to another(e.g route) then uid will hold the referred object's(e.g. route's) uid.",
											Optional: true,
										},
									},
								},
							},
							"validation_params": schema.SingleNestedBlock{
								MarkdownDescription: "TLS Certificate Validation Parameters. This includes URL for a trust store, whether SAN verification is required and list of Subject Alt Names for verification",
								Attributes: map[string]schema.Attribute{
									"skip_hostname_verification": schema.BoolAttribute{
										MarkdownDescription: "Skip verification of hostname. When True, skip verification of hostname i.e. CN/Subject Alt Name of certificate is not matched to the connecting hostname",
										Optional: true,
									},
									"trusted_ca_url": schema.StringAttribute{
										MarkdownDescription: "Inline Root CA Certificate (legacy). Inline Root CA Certificate",
										Optional: true,
									},
									"verify_subject_alt_names": schema.ListAttribute{
										MarkdownDescription: "List of SANs for matching. List of acceptable Subject Alt Names/CN in the peer's certificate. When skip_hostname_verification is false and verify_subject_alt_names is empty, the hostname of the peer will be used for matching against SAN/CN of peer's certificate",
										Optional: true,
										ElementType: types.StringType,
									},
								},
								Blocks: map[string]schema.Block{
									"trusted_ca": schema.SingleNestedBlock{
										MarkdownDescription: "Root CA Certificate Reference. Reference to Root CA Certificate",
									},
								},
							},
						},
					},
					"common_params": schema.SingleNestedBlock{
						MarkdownDescription: "TLS Parameters. Information of different aspects for TLS authentication related to ciphers, certificates and trust store",
						Attributes: map[string]schema.Attribute{
							"cipher_suites": schema.ListAttribute{
								MarkdownDescription: "Cipher Suites. The following list specifies the supported cipher suite TLS_AES_128_GCM_SHA256 TLS_AES_256_GCM_SHA384 TLS_CHACHA20_POLY1305_SHA256 TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256 TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384 TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256 TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256 TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA TLS_ECDHE_RSA_WITH_AES_128_CBC_...",
								Optional: true,
								ElementType: types.StringType,
							},
							"maximum_protocol_version": schema.StringAttribute{
								MarkdownDescription: "TLS Protocol. TlsProtocol is enumeration of supported TLS versions F5 Distributed Cloud will choose the optimal TLS version. Possible values are `TLS_AUTO`, `TLSv1_0`, `TLSv1_1`, `TLSv1_2`, `TLSv1_3`. Defaults to `TLS_AUTO`.",
								Optional: true,
							},
							"minimum_protocol_version": schema.StringAttribute{
								MarkdownDescription: "TLS Protocol. TlsProtocol is enumeration of supported TLS versions F5 Distributed Cloud will choose the optimal TLS version. Possible values are `TLS_AUTO`, `TLSv1_0`, `TLSv1_1`, `TLSv1_2`, `TLSv1_3`. Defaults to `TLS_AUTO`.",
								Optional: true,
							},
						},
						Blocks: map[string]schema.Block{
							"tls_certificates": schema.ListNestedBlock{
								MarkdownDescription: "TLS Certificates. Set of TLS certificates",
								NestedObject: schema.NestedBlockObject{
									Attributes: map[string]schema.Attribute{
										"certificate_url": schema.StringAttribute{
											MarkdownDescription: "Certificate. TLS certificate. Certificate or certificate chain in PEM format including the PEM headers.",
											Optional: true,
										},
										"description": schema.StringAttribute{
											MarkdownDescription: "Description. Description for the certificate",
											Optional: true,
										},
									},
									Blocks: map[string]schema.Block{
										"custom_hash_algorithms": schema.SingleNestedBlock{
											MarkdownDescription: "Hash Algorithms. Specifies the hash algorithms to be used",
										},
										"disable_ocsp_stapling": schema.SingleNestedBlock{
											MarkdownDescription: "Empty. This can be used for messages where no values are needed",
										},
										"private_key": schema.SingleNestedBlock{
											MarkdownDescription: "Secret. SecretType is used in an object to indicate a sensitive/confidential field",
										},
										"use_system_defaults": schema.SingleNestedBlock{
											MarkdownDescription: "Empty. This can be used for messages where no values are needed",
										},
									},
								},
							},
							"validation_params": schema.SingleNestedBlock{
								MarkdownDescription: "TLS Certificate Validation Parameters. This includes URL for a trust store, whether SAN verification is required and list of Subject Alt Names for verification",
								Attributes: map[string]schema.Attribute{
									"skip_hostname_verification": schema.BoolAttribute{
										MarkdownDescription: "Skip verification of hostname. When True, skip verification of hostname i.e. CN/Subject Alt Name of certificate is not matched to the connecting hostname",
										Optional: true,
									},
									"trusted_ca_url": schema.StringAttribute{
										MarkdownDescription: "Inline Root CA Certificate (legacy). Inline Root CA Certificate",
										Optional: true,
									},
									"verify_subject_alt_names": schema.ListAttribute{
										MarkdownDescription: "List of SANs for matching. List of acceptable Subject Alt Names/CN in the peer's certificate. When skip_hostname_verification is false and verify_subject_alt_names is empty, the hostname of the peer will be used for matching against SAN/CN of peer's certificate",
										Optional: true,
										ElementType: types.StringType,
									},
								},
								Blocks: map[string]schema.Block{
									"trusted_ca": schema.SingleNestedBlock{
										MarkdownDescription: "Root CA Certificate Reference. Reference to Root CA Certificate",
									},
								},
							},
						},
					},
					"default_session_key_caching": schema.SingleNestedBlock{
						MarkdownDescription: "Empty. This can be used for messages where no values are needed",
					},
					"disable_session_key_caching": schema.SingleNestedBlock{
						MarkdownDescription: "Empty. This can be used for messages where no values are needed",
					},
					"disable_sni": schema.SingleNestedBlock{
						MarkdownDescription: "Empty. This can be used for messages where no values are needed",
					},
					"use_host_header_as_sni": schema.SingleNestedBlock{
						MarkdownDescription: "Empty. This can be used for messages where no values are needed",
					},
				},

			},
			"upstream_conn_pool_reuse_type": schema.SingleNestedBlock{
				MarkdownDescription: "Select upstream connection pool reuse state. Select upstream connection pool reuse state for every downstream connection. This configuration choice is for HTTP(S) LB only.",
				Attributes: map[string]schema.Attribute{
				},
				Blocks: map[string]schema.Block{
					"disable_conn_pool_reuse": schema.SingleNestedBlock{
						MarkdownDescription: "Empty. This can be used for messages where no values are needed",
					},
					"enable_conn_pool_reuse": schema.SingleNestedBlock{
						MarkdownDescription: "Empty. This can be used for messages where no values are needed",
					},
				},

			},
		},
	}
}

func (r *ClusterResource) Configure(ctx context.Context, req resource.ConfigureRequest, resp *resource.ConfigureResponse) {
	if req.ProviderData == nil {
		return
	}
	client, ok := req.ProviderData.(*client.Client)
	if !ok {
		resp.Diagnostics.AddError(
			"Unexpected Resource Configure Type",
			fmt.Sprintf("Expected *client.Client, got: %T. Please report this issue to the provider developers.", req.ProviderData),
		)
		return
	}
	r.client = client
}

// ValidateConfig implements resource.ResourceWithValidateConfig
func (r *ClusterResource) ValidateConfig(ctx context.Context, req resource.ValidateConfigRequest, resp *resource.ValidateConfigResponse) {
	var data ClusterResourceModel
	resp.Diagnostics.Append(req.Config.Get(ctx, &data)...)
	if resp.Diagnostics.HasError() {
		return
	}
}

// ModifyPlan implements resource.ResourceWithModifyPlan
func (r *ClusterResource) ModifyPlan(ctx context.Context, req resource.ModifyPlanRequest, resp *resource.ModifyPlanResponse) {
	if req.Plan.Raw.IsNull() {
		resp.Diagnostics.AddWarning(
			"Resource Destruction",
			"This will permanently delete the cluster from F5 Distributed Cloud.",
		)
		return
	}

	if req.State.Raw.IsNull() {
		var plan ClusterResourceModel
		resp.Diagnostics.Append(req.Plan.Get(ctx, &plan)...)
		if resp.Diagnostics.HasError() {
			return
		}

		if plan.Name.IsUnknown() {
			resp.Diagnostics.AddWarning(
				"Unknown Resource Name",
				"The resource name is not yet known. This may affect planning for dependent resources.",
			)
		}
	}
}

// UpgradeState implements resource.ResourceWithUpgradeState
func (r *ClusterResource) UpgradeState(ctx context.Context) map[int64]resource.StateUpgrader {
	return map[int64]resource.StateUpgrader{
		0: {
			PriorSchema: &schema.Schema{
				Attributes: map[string]schema.Attribute{
					"name":        schema.StringAttribute{Required: true},
					"namespace":   schema.StringAttribute{Required: true},
					"annotations": schema.MapAttribute{Optional: true, ElementType: types.StringType},
					"labels":      schema.MapAttribute{Optional: true, ElementType: types.StringType},
					"id":          schema.StringAttribute{Computed: true},
				},
			},
			StateUpgrader: func(ctx context.Context, req resource.UpgradeStateRequest, resp *resource.UpgradeStateResponse) {
				var priorState struct {
					Name        types.String `tfsdk:"name"`
					Namespace   types.String `tfsdk:"namespace"`
					Annotations types.Map    `tfsdk:"annotations"`
					Labels      types.Map    `tfsdk:"labels"`
					ID          types.String `tfsdk:"id"`
				}

				resp.Diagnostics.Append(req.State.Get(ctx, &priorState)...)
				if resp.Diagnostics.HasError() {
					return
				}

				upgradedState := ClusterResourceModel{
					Name:        priorState.Name,
					Namespace:   priorState.Namespace,
					Annotations: priorState.Annotations,
					Labels:      priorState.Labels,
					ID:          priorState.ID,
					Timeouts:    timeouts.Value{},
				}

				resp.Diagnostics.Append(resp.State.Set(ctx, upgradedState)...)
			},
		},
	}
}

func (r *ClusterResource) Create(ctx context.Context, req resource.CreateRequest, resp *resource.CreateResponse) {
	var data ClusterResourceModel
	resp.Diagnostics.Append(req.Plan.Get(ctx, &data)...)
	if resp.Diagnostics.HasError() {
		return
	}

	createTimeout, diags := data.Timeouts.Create(ctx, inttimeouts.DefaultCreate)
	resp.Diagnostics.Append(diags...)
	if resp.Diagnostics.HasError() {
		return
	}

	ctx, cancel := context.WithTimeout(ctx, createTimeout)
	defer cancel()

	tflog.Debug(ctx, "Creating cluster", map[string]interface{}{
		"name":      data.Name.ValueString(),
		"namespace": data.Namespace.ValueString(),
	})

	apiResource := &client.Cluster{
		Metadata: client.Metadata{
			Name:      data.Name.ValueString(),
			Namespace: data.Namespace.ValueString(),
		},
		Spec: client.ClusterSpec{},
	}

	if !data.Labels.IsNull() {
		labels := make(map[string]string)
		resp.Diagnostics.Append(data.Labels.ElementsAs(ctx, &labels, false)...)
		if resp.Diagnostics.HasError() {
			return
		}
		apiResource.Metadata.Labels = labels
	}

	if !data.Annotations.IsNull() {
		annotations := make(map[string]string)
		resp.Diagnostics.Append(data.Annotations.ElementsAs(ctx, &annotations, false)...)
		if resp.Diagnostics.HasError() {
			return
		}
		apiResource.Metadata.Annotations = annotations
	}

	created, err := r.client.CreateCluster(ctx, apiResource)
	if err != nil {
		resp.Diagnostics.AddError("Client Error", fmt.Sprintf("Unable to create Cluster: %s", err))
		return
	}

	data.ID = types.StringValue(created.Metadata.Name)

	psd := privatestate.NewPrivateStateData()
	psd.SetUID(created.Metadata.UID)
	resp.Diagnostics.Append(psd.SaveToPrivateState(ctx, resp)...)

	tflog.Trace(ctx, "created Cluster resource")
	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}

func (r *ClusterResource) Read(ctx context.Context, req resource.ReadRequest, resp *resource.ReadResponse) {
	var data ClusterResourceModel
	resp.Diagnostics.Append(req.State.Get(ctx, &data)...)
	if resp.Diagnostics.HasError() {
		return
	}

	readTimeout, diags := data.Timeouts.Read(ctx, inttimeouts.DefaultRead)
	resp.Diagnostics.Append(diags...)
	if resp.Diagnostics.HasError() {
		return
	}

	ctx, cancel := context.WithTimeout(ctx, readTimeout)
	defer cancel()

	psd, psDiags := privatestate.LoadFromPrivateState(ctx, &req)
	resp.Diagnostics.Append(psDiags...)

	apiResource, err := r.client.GetCluster(ctx, data.Namespace.ValueString(), data.Name.ValueString())
	if err != nil {
		resp.Diagnostics.AddError("Client Error", fmt.Sprintf("Unable to read Cluster: %s", err))
		return
	}

	if psd != nil && psd.Metadata.UID != "" && apiResource.Metadata.UID != psd.Metadata.UID {
		resp.Diagnostics.AddWarning(
			"Resource Drift Detected",
			"The cluster may have been recreated outside of Terraform.",
		)
	}

	data.ID = types.StringValue(apiResource.Metadata.Name)
	data.Name = types.StringValue(apiResource.Metadata.Name)
	data.Namespace = types.StringValue(apiResource.Metadata.Namespace)

	if len(apiResource.Metadata.Labels) > 0 {
		labels, diags := types.MapValueFrom(ctx, types.StringType, apiResource.Metadata.Labels)
		resp.Diagnostics.Append(diags...)
		if !resp.Diagnostics.HasError() {
			data.Labels = labels
		}
	} else {
		data.Labels = types.MapNull(types.StringType)
	}

	if len(apiResource.Metadata.Annotations) > 0 {
		annotations, diags := types.MapValueFrom(ctx, types.StringType, apiResource.Metadata.Annotations)
		resp.Diagnostics.Append(diags...)
		if !resp.Diagnostics.HasError() {
			data.Annotations = annotations
		}
	} else {
		data.Annotations = types.MapNull(types.StringType)
	}

	psd = privatestate.NewPrivateStateData()
	psd.SetUID(apiResource.Metadata.UID)
	resp.Diagnostics.Append(psd.SaveToPrivateState(ctx, resp)...)

	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}

func (r *ClusterResource) Update(ctx context.Context, req resource.UpdateRequest, resp *resource.UpdateResponse) {
	var data ClusterResourceModel
	resp.Diagnostics.Append(req.Plan.Get(ctx, &data)...)
	if resp.Diagnostics.HasError() {
		return
	}

	updateTimeout, diags := data.Timeouts.Update(ctx, inttimeouts.DefaultUpdate)
	resp.Diagnostics.Append(diags...)
	if resp.Diagnostics.HasError() {
		return
	}

	ctx, cancel := context.WithTimeout(ctx, updateTimeout)
	defer cancel()

	apiResource := &client.Cluster{
		Metadata: client.Metadata{
			Name:      data.Name.ValueString(),
			Namespace: data.Namespace.ValueString(),
		},
		Spec: client.ClusterSpec{},
	}

	if !data.Labels.IsNull() {
		labels := make(map[string]string)
		resp.Diagnostics.Append(data.Labels.ElementsAs(ctx, &labels, false)...)
		if resp.Diagnostics.HasError() {
			return
		}
		apiResource.Metadata.Labels = labels
	}

	if !data.Annotations.IsNull() {
		annotations := make(map[string]string)
		resp.Diagnostics.Append(data.Annotations.ElementsAs(ctx, &annotations, false)...)
		if resp.Diagnostics.HasError() {
			return
		}
		apiResource.Metadata.Annotations = annotations
	}

	updated, err := r.client.UpdateCluster(ctx, apiResource)
	if err != nil {
		resp.Diagnostics.AddError("Client Error", fmt.Sprintf("Unable to update Cluster: %s", err))
		return
	}

	data.ID = types.StringValue(updated.Metadata.Name)

	psd := privatestate.NewPrivateStateData()
	psd.SetUID(updated.Metadata.UID)
	resp.Diagnostics.Append(psd.SaveToPrivateState(ctx, resp)...)

	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}

func (r *ClusterResource) Delete(ctx context.Context, req resource.DeleteRequest, resp *resource.DeleteResponse) {
	var data ClusterResourceModel
	resp.Diagnostics.Append(req.State.Get(ctx, &data)...)
	if resp.Diagnostics.HasError() {
		return
	}

	deleteTimeout, diags := data.Timeouts.Delete(ctx, inttimeouts.DefaultDelete)
	resp.Diagnostics.Append(diags...)
	if resp.Diagnostics.HasError() {
		return
	}

	ctx, cancel := context.WithTimeout(ctx, deleteTimeout)
	defer cancel()

	err := r.client.DeleteCluster(ctx, data.Namespace.ValueString(), data.Name.ValueString())
	if err != nil {
		resp.Diagnostics.AddError("Client Error", fmt.Sprintf("Unable to delete Cluster: %s", err))
		return
	}
}

func (r *ClusterResource) ImportState(ctx context.Context, req resource.ImportStateRequest, resp *resource.ImportStateResponse) {
	resource.ImportStatePassthroughID(ctx, path.Root("id"), req, resp)
}
