// Code generated by generate-all-schemas.go. DO NOT EDIT.
// Source: F5 XC OpenAPI specification

package provider

import (
	"context"
	"fmt"
	"strings"

	"github.com/hashicorp/terraform-plugin-framework-timeouts/resource/timeouts"
	"github.com/hashicorp/terraform-plugin-framework/path"
	"github.com/hashicorp/terraform-plugin-framework/resource"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/int64planmodifier"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/planmodifier"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/stringplanmodifier"
	"github.com/hashicorp/terraform-plugin-framework/schema/validator"
	"github.com/hashicorp/terraform-plugin-framework/types"
	"github.com/hashicorp/terraform-plugin-log/tflog"

	"github.com/f5xc/terraform-provider-f5xc/internal/client"
	"github.com/f5xc/terraform-provider-f5xc/internal/privatestate"
	inttimeouts "github.com/f5xc/terraform-provider-f5xc/internal/timeouts"
	"github.com/f5xc/terraform-provider-f5xc/internal/validators"
)

// Ensure provider defined types fully satisfy framework interfaces.
var (
	_ resource.Resource                   = &ClusterResource{}
	_ resource.ResourceWithConfigure      = &ClusterResource{}
	_ resource.ResourceWithImportState    = &ClusterResource{}
	_ resource.ResourceWithModifyPlan     = &ClusterResource{}
	_ resource.ResourceWithUpgradeState   = &ClusterResource{}
	_ resource.ResourceWithValidateConfig = &ClusterResource{}
)

// clusterSchemaVersion is the schema version for state upgrades
const clusterSchemaVersion int64 = 1

func NewClusterResource() resource.Resource {
	return &ClusterResource{}
}

type ClusterResource struct {
	client *client.Client
}

// ClusterEmptyModel represents empty nested blocks
type ClusterEmptyModel struct {
}

// ClusterCircuitBreakerModel represents circuit_breaker block
type ClusterCircuitBreakerModel struct {
	ConnectionLimit types.Int64  `tfsdk:"connection_limit"`
	MaxRequests     types.Int64  `tfsdk:"max_requests"`
	PendingRequests types.Int64  `tfsdk:"pending_requests"`
	Priority        types.String `tfsdk:"priority"`
	Retries         types.Int64  `tfsdk:"retries"`
}

// ClusterEndpointSubsetsModel represents endpoint_subsets block
type ClusterEndpointSubsetsModel struct {
	Keys types.List `tfsdk:"keys"`
}

// ClusterEndpointsModel represents endpoints block
type ClusterEndpointsModel struct {
	Kind      types.String `tfsdk:"kind"`
	Name      types.String `tfsdk:"name"`
	Namespace types.String `tfsdk:"namespace"`
	Tenant    types.String `tfsdk:"tenant"`
	Uid       types.String `tfsdk:"uid"`
}

// ClusterHealthChecksModel represents health_checks block
type ClusterHealthChecksModel struct {
	Kind      types.String `tfsdk:"kind"`
	Name      types.String `tfsdk:"name"`
	Namespace types.String `tfsdk:"namespace"`
	Tenant    types.String `tfsdk:"tenant"`
	Uid       types.String `tfsdk:"uid"`
}

// ClusterHttp1ConfigModel represents http1_config block
type ClusterHttp1ConfigModel struct {
	HeaderTransformation *ClusterHttp1ConfigHeaderTransformationModel `tfsdk:"header_transformation"`
}

// ClusterHttp1ConfigHeaderTransformationModel represents header_transformation block
type ClusterHttp1ConfigHeaderTransformationModel struct {
	DefaultHeaderTransformation      *ClusterEmptyModel `tfsdk:"default_header_transformation"`
	LegacyHeaderTransformation       *ClusterEmptyModel `tfsdk:"legacy_header_transformation"`
	PreserveCaseHeaderTransformation *ClusterEmptyModel `tfsdk:"preserve_case_header_transformation"`
	ProperCaseHeaderTransformation   *ClusterEmptyModel `tfsdk:"proper_case_header_transformation"`
}

// ClusterHttp2OptionsModel represents http2_options block
type ClusterHttp2OptionsModel struct {
	Enabled types.Bool `tfsdk:"enabled"`
}

// ClusterOutlierDetectionModel represents outlier_detection block
type ClusterOutlierDetectionModel struct {
	BaseEjectionTime          types.Int64 `tfsdk:"base_ejection_time"`
	Consecutive5xx            types.Int64 `tfsdk:"consecutive_5xx"`
	ConsecutiveGatewayFailure types.Int64 `tfsdk:"consecutive_gateway_failure"`
	Interval                  types.Int64 `tfsdk:"interval"`
	MaxEjectionPercent        types.Int64 `tfsdk:"max_ejection_percent"`
}

// ClusterTLSParametersModel represents tls_parameters block
type ClusterTLSParametersModel struct {
	MaxSessionKeys           types.Int64                            `tfsdk:"max_session_keys"`
	Sni                      types.String                           `tfsdk:"sni"`
	CertParams               *ClusterTLSParametersCertParamsModel   `tfsdk:"cert_params"`
	CommonParams             *ClusterTLSParametersCommonParamsModel `tfsdk:"common_params"`
	DefaultSessionKeyCaching *ClusterEmptyModel                     `tfsdk:"default_session_key_caching"`
	DisableSessionKeyCaching *ClusterEmptyModel                     `tfsdk:"disable_session_key_caching"`
	DisableSni               *ClusterEmptyModel                     `tfsdk:"disable_sni"`
	UseHostHeaderAsSni       *ClusterEmptyModel                     `tfsdk:"use_host_header_as_sni"`
}

// ClusterTLSParametersCertParamsModel represents cert_params block
type ClusterTLSParametersCertParamsModel struct {
	CipherSuites           types.List                                           `tfsdk:"cipher_suites"`
	MaximumProtocolVersion types.String                                         `tfsdk:"maximum_protocol_version"`
	MinimumProtocolVersion types.String                                         `tfsdk:"minimum_protocol_version"`
	Certificates           []ClusterTLSParametersCertParamsCertificatesModel    `tfsdk:"certificates"`
	ValidationParams       *ClusterTLSParametersCertParamsValidationParamsModel `tfsdk:"validation_params"`
}

// ClusterTLSParametersCertParamsCertificatesModel represents certificates block
type ClusterTLSParametersCertParamsCertificatesModel struct {
	Kind      types.String `tfsdk:"kind"`
	Name      types.String `tfsdk:"name"`
	Namespace types.String `tfsdk:"namespace"`
	Tenant    types.String `tfsdk:"tenant"`
	Uid       types.String `tfsdk:"uid"`
}

// ClusterTLSParametersCertParamsValidationParamsModel represents validation_params block
type ClusterTLSParametersCertParamsValidationParamsModel struct {
	SkipHostnameVerification types.Bool                                                    `tfsdk:"skip_hostname_verification"`
	TrustedCAURL             types.String                                                  `tfsdk:"trusted_ca_url"`
	VerifySubjectAltNames    types.List                                                    `tfsdk:"verify_subject_alt_names"`
	TrustedCA                *ClusterTLSParametersCertParamsValidationParamsTrustedCAModel `tfsdk:"trusted_ca"`
}

// ClusterTLSParametersCertParamsValidationParamsTrustedCAModel represents trusted_ca block
type ClusterTLSParametersCertParamsValidationParamsTrustedCAModel struct {
	TrustedCAList []ClusterTLSParametersCertParamsValidationParamsTrustedCATrustedCAListModel `tfsdk:"trusted_ca_list"`
}

// ClusterTLSParametersCertParamsValidationParamsTrustedCATrustedCAListModel represents trusted_ca_list block
type ClusterTLSParametersCertParamsValidationParamsTrustedCATrustedCAListModel struct {
	Kind      types.String `tfsdk:"kind"`
	Name      types.String `tfsdk:"name"`
	Namespace types.String `tfsdk:"namespace"`
	Tenant    types.String `tfsdk:"tenant"`
	Uid       types.String `tfsdk:"uid"`
}

// ClusterTLSParametersCommonParamsModel represents common_params block
type ClusterTLSParametersCommonParamsModel struct {
	CipherSuites           types.List                                             `tfsdk:"cipher_suites"`
	MaximumProtocolVersion types.String                                           `tfsdk:"maximum_protocol_version"`
	MinimumProtocolVersion types.String                                           `tfsdk:"minimum_protocol_version"`
	TLSCertificates        []ClusterTLSParametersCommonParamsTLSCertificatesModel `tfsdk:"tls_certificates"`
	ValidationParams       *ClusterTLSParametersCommonParamsValidationParamsModel `tfsdk:"validation_params"`
}

// ClusterTLSParametersCommonParamsTLSCertificatesModel represents tls_certificates block
type ClusterTLSParametersCommonParamsTLSCertificatesModel struct {
	CertificateURL       types.String                                                              `tfsdk:"certificate_url"`
	DescriptionSpec      types.String                                                              `tfsdk:"description_spec"`
	CustomHashAlgorithms *ClusterTLSParametersCommonParamsTLSCertificatesCustomHashAlgorithmsModel `tfsdk:"custom_hash_algorithms"`
	DisableOCSPStapling  *ClusterEmptyModel                                                        `tfsdk:"disable_ocsp_stapling"`
	PrivateKey           *ClusterTLSParametersCommonParamsTLSCertificatesPrivateKeyModel           `tfsdk:"private_key"`
	UseSystemDefaults    *ClusterEmptyModel                                                        `tfsdk:"use_system_defaults"`
}

// ClusterTLSParametersCommonParamsTLSCertificatesCustomHashAlgorithmsModel represents custom_hash_algorithms block
type ClusterTLSParametersCommonParamsTLSCertificatesCustomHashAlgorithmsModel struct {
	HashAlgorithms types.List `tfsdk:"hash_algorithms"`
}

// ClusterTLSParametersCommonParamsTLSCertificatesPrivateKeyModel represents private_key block
type ClusterTLSParametersCommonParamsTLSCertificatesPrivateKeyModel struct {
	BlindfoldSecretInfo *ClusterTLSParametersCommonParamsTLSCertificatesPrivateKeyBlindfoldSecretInfoModel `tfsdk:"blindfold_secret_info"`
	ClearSecretInfo     *ClusterTLSParametersCommonParamsTLSCertificatesPrivateKeyClearSecretInfoModel     `tfsdk:"clear_secret_info"`
}

// ClusterTLSParametersCommonParamsTLSCertificatesPrivateKeyBlindfoldSecretInfoModel represents blindfold_secret_info block
type ClusterTLSParametersCommonParamsTLSCertificatesPrivateKeyBlindfoldSecretInfoModel struct {
	DecryptionProvider types.String `tfsdk:"decryption_provider"`
	Location           types.String `tfsdk:"location"`
	StoreProvider      types.String `tfsdk:"store_provider"`
}

// ClusterTLSParametersCommonParamsTLSCertificatesPrivateKeyClearSecretInfoModel represents clear_secret_info block
type ClusterTLSParametersCommonParamsTLSCertificatesPrivateKeyClearSecretInfoModel struct {
	Provider types.String `tfsdk:"provider_ref"`
	URL      types.String `tfsdk:"url"`
}

// ClusterTLSParametersCommonParamsValidationParamsModel represents validation_params block
type ClusterTLSParametersCommonParamsValidationParamsModel struct {
	SkipHostnameVerification types.Bool                                                      `tfsdk:"skip_hostname_verification"`
	TrustedCAURL             types.String                                                    `tfsdk:"trusted_ca_url"`
	VerifySubjectAltNames    types.List                                                      `tfsdk:"verify_subject_alt_names"`
	TrustedCA                *ClusterTLSParametersCommonParamsValidationParamsTrustedCAModel `tfsdk:"trusted_ca"`
}

// ClusterTLSParametersCommonParamsValidationParamsTrustedCAModel represents trusted_ca block
type ClusterTLSParametersCommonParamsValidationParamsTrustedCAModel struct {
	TrustedCAList []ClusterTLSParametersCommonParamsValidationParamsTrustedCATrustedCAListModel `tfsdk:"trusted_ca_list"`
}

// ClusterTLSParametersCommonParamsValidationParamsTrustedCATrustedCAListModel represents trusted_ca_list block
type ClusterTLSParametersCommonParamsValidationParamsTrustedCATrustedCAListModel struct {
	Kind      types.String `tfsdk:"kind"`
	Name      types.String `tfsdk:"name"`
	Namespace types.String `tfsdk:"namespace"`
	Tenant    types.String `tfsdk:"tenant"`
	Uid       types.String `tfsdk:"uid"`
}

// ClusterUpstreamConnPoolReuseTypeModel represents upstream_conn_pool_reuse_type block
type ClusterUpstreamConnPoolReuseTypeModel struct {
	DisableConnPoolReuse *ClusterEmptyModel `tfsdk:"disable_conn_pool_reuse"`
	EnableConnPoolReuse  *ClusterEmptyModel `tfsdk:"enable_conn_pool_reuse"`
}

type ClusterResourceModel struct {
	Name                      types.String                           `tfsdk:"name"`
	Namespace                 types.String                           `tfsdk:"namespace"`
	Annotations               types.Map                              `tfsdk:"annotations"`
	Description               types.String                           `tfsdk:"description"`
	Disable                   types.Bool                             `tfsdk:"disable"`
	Labels                    types.Map                              `tfsdk:"labels"`
	ID                        types.String                           `tfsdk:"id"`
	ConnectionTimeout         types.Int64                            `tfsdk:"connection_timeout"`
	EndpointSelection         types.String                           `tfsdk:"endpoint_selection"`
	FallbackPolicy            types.String                           `tfsdk:"fallback_policy"`
	HTTPIdleTimeout           types.Int64                            `tfsdk:"http_idle_timeout"`
	LoadBalancerAlgorithm     types.String                           `tfsdk:"loadbalancer_algorithm"`
	PanicThreshold            types.Int64                            `tfsdk:"panic_threshold"`
	Timeouts                  timeouts.Value                         `tfsdk:"timeouts"`
	AutoHTTPConfig            *ClusterEmptyModel                     `tfsdk:"auto_http_config"`
	CircuitBreaker            *ClusterCircuitBreakerModel            `tfsdk:"circuit_breaker"`
	DefaultSubset             *ClusterEmptyModel                     `tfsdk:"default_subset"`
	DisableProxyProtocol      *ClusterEmptyModel                     `tfsdk:"disable_proxy_protocol"`
	EndpointSubsets           []ClusterEndpointSubsetsModel          `tfsdk:"endpoint_subsets"`
	Endpoints                 []ClusterEndpointsModel                `tfsdk:"endpoints"`
	HealthChecks              []ClusterHealthChecksModel             `tfsdk:"health_checks"`
	Http1Config               *ClusterHttp1ConfigModel               `tfsdk:"http1_config"`
	Http2Options              *ClusterHttp2OptionsModel              `tfsdk:"http2_options"`
	NoPanicThreshold          *ClusterEmptyModel                     `tfsdk:"no_panic_threshold"`
	OutlierDetection          *ClusterOutlierDetectionModel          `tfsdk:"outlier_detection"`
	ProxyProtocolV1           *ClusterEmptyModel                     `tfsdk:"proxy_protocol_v1"`
	ProxyProtocolV2           *ClusterEmptyModel                     `tfsdk:"proxy_protocol_v2"`
	TLSParameters             *ClusterTLSParametersModel             `tfsdk:"tls_parameters"`
	UpstreamConnPoolReuseType *ClusterUpstreamConnPoolReuseTypeModel `tfsdk:"upstream_conn_pool_reuse_type"`
}

func (r *ClusterResource) Metadata(ctx context.Context, req resource.MetadataRequest, resp *resource.MetadataResponse) {
	resp.TypeName = req.ProviderTypeName + "_cluster"
}

func (r *ClusterResource) Schema(ctx context.Context, req resource.SchemaRequest, resp *resource.SchemaResponse) {
	resp.Schema = schema.Schema{
		Version:             clusterSchemaVersion,
		MarkdownDescription: "[Namespace: required] Manages cluster will create the object in the storage backend for namespace metadata.namespace in F5 Distributed Cloud.",
		Attributes: map[string]schema.Attribute{
			"name": schema.StringAttribute{
				MarkdownDescription: "Name of the Cluster. Must be unique within the namespace.",
				Required:            true,
				PlanModifiers: []planmodifier.String{
					stringplanmodifier.RequiresReplace(),
				},
				Validators: []validator.String{
					validators.NameValidator(),
				},
			},
			"namespace": schema.StringAttribute{
				MarkdownDescription: "Namespace where the Cluster will be created.",
				Required:            true,
				PlanModifiers: []planmodifier.String{
					stringplanmodifier.RequiresReplace(),
				},
				Validators: []validator.String{
					validators.NamespaceValidator(),
				},
			},
			"annotations": schema.MapAttribute{
				MarkdownDescription: "Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata.",
				Optional:            true,
				ElementType:         types.StringType,
			},
			"description": schema.StringAttribute{
				MarkdownDescription: "Human readable description for the object.",
				Optional:            true,
			},
			"disable": schema.BoolAttribute{
				MarkdownDescription: "A value of true will administratively disable the object.",
				Optional:            true,
			},
			"labels": schema.MapAttribute{
				MarkdownDescription: "Labels is a user defined key value map that can be attached to resources for organization and filtering.",
				Optional:            true,
				ElementType:         types.StringType,
			},
			"id": schema.StringAttribute{
				MarkdownDescription: "Unique identifier for the resource.",
				Computed:            true,
				PlanModifiers: []planmodifier.String{
					stringplanmodifier.UseStateForUnknown(),
				},
			},
			"connection_timeout": schema.Int64Attribute{
				MarkdownDescription: "Connection Timeout. The timeout for new network connections to endpoints in the cluster. This is specified in milliseconds. The  seconds. Defaults to `2`.",
				Optional:            true,
				Computed:            true,
				PlanModifiers: []planmodifier.Int64{
					int64planmodifier.UseStateForUnknown(),
				},
			},
			"endpoint_selection": schema.StringAttribute{
				MarkdownDescription: "[Enum: DISTRIBUTED|LOCAL_ONLY|LOCAL_PREFERRED] Endpoint Selection Policy. Policy for selection of endpoints from local site/remote site/both Consider both remote and local endpoints for load balancing LOCAL_ONLY: Consider only local endpoints for load balancing Enable this policy to load balance ONLY among locally discovered endpoints Prefer the local endpoints for load balancing. If local endpoints are not present remote endpoints will be considered. Possible values are `DISTRIBUTED`, `LOCAL_ONLY`, `LOCAL_PREFERRED`. Defaults to `DISTRIBUTED`.",
				Optional:            true,
				Computed:            true,
				PlanModifiers: []planmodifier.String{
					stringplanmodifier.UseStateForUnknown(),
				},
			},
			"fallback_policy": schema.StringAttribute{
				MarkdownDescription: "[Enum: NO_FALLBACK|ANY_ENDPOINT|DEFAULT_SUBSET] Subset Fallback Policy. Enumeration for SubsetFallbackPolicy if subset match is not found. The request fails as if the cluster had no endpoint matching the subset policy Any cluster endpoint may be selected if the cluster had no endpoint matching the subset policy Load balancing is done over endpoints matching default_subset if the cluster had no endpoint matching the subset policy. Possible values are `NO_FALLBACK`, `ANY_ENDPOINT`, `DEFAULT_SUBSET`. Defaults to `NO_FALLBACK`.",
				Optional:            true,
				Computed:            true,
				PlanModifiers: []planmodifier.String{
					stringplanmodifier.UseStateForUnknown(),
				},
			},
			"http_idle_timeout": schema.Int64Attribute{
				MarkdownDescription: "HTTP Idle Timeout. The idle timeout for upstream connection pool connections. The idle timeout is defined as the period in which there are no active requests. When the idle timeout is reached the connection will be closed. Note that request based timeouts mean that HTTP/2 PINGs will not keep the connection alive. This is specified in milliseconds. The  minutes. Defaults to `5`.",
				Optional:            true,
				Computed:            true,
				PlanModifiers: []planmodifier.Int64{
					int64planmodifier.UseStateForUnknown(),
				},
			},
			"loadbalancer_algorithm": schema.StringAttribute{
				MarkdownDescription: "[Enum: ROUND_ROBIN|LEAST_REQUEST|RING_HASH|RANDOM|LB_OVERRIDE] Load Balancer Algorithm. Different load balancing algorithms supported When a connection to a endpoint in an upstream cluster is required, the load balancer uses loadbalancer_algorithm to determine which host is selected. - ROUND_ROBIN: ROUND_ROBIN Policy in which each healthy/available upstream endpoint is selected in round robin order. - LEAST_REQUEST: LEAST_REQUEST Policy in which loadbalancer picks the upstream endpoint which has the fewest active requests - RING_HASH: RING_HASH Policy implements consistent hashing to upstream endpoints using ring hash of endpoint names Hash of the incoming request is calculated using request hash policy. The ring/modulo hash load balancer implements consistent hashing to upstream hosts. The algorithm is based on mapping all hosts onto a circle such that the addition or removal of a host from the host set changes only affect 1/N requests. This technique is also commonly known as “ketama” hashing. A consistent hashing load balancer is only effective when protocol routing is used that specifies a value to hash on. The minimum ring size governs the replication factor for each host in the ring. For example, if the minimum ring size is 1024 and there are 16 hosts, each host will be replicated 64 times. - RANDOM: RANDOM Policy in which each available upstream endpoint is selected in random order. The random load balancer selects a random healthy host. The random load balancer generally performs better than round robin if no health checking policy is configured. Random selection avoids bias towards the host in the set that comes after a failed host. - LB_OVERRIDE: Load Balancer Override Hash policy is taken from from the load balancer which is using this origin pool. Possible values are `ROUND_ROBIN`, `LEAST_REQUEST`, `RING_HASH`, `RANDOM`, `LB_OVERRIDE`. Defaults to `ROUND_ROBIN`.",
				Optional:            true,
				Computed:            true,
				PlanModifiers: []planmodifier.String{
					stringplanmodifier.UseStateForUnknown(),
				},
			},
			"panic_threshold": schema.Int64Attribute{
				MarkdownDescription: "Panic threshold. Configure a threshold (percentage of unhealthy endpoints) below which all endpoints will be considered for loadbalancing ignoring its health status.",
				Optional:            true,
				Computed:            true,
				PlanModifiers: []planmodifier.Int64{
					int64planmodifier.UseStateForUnknown(),
				},
			},
		},
		Blocks: map[string]schema.Block{
			"timeouts": timeouts.Block(ctx, timeouts.Opts{
				Create: true,
				Read:   true,
				Update: true,
				Delete: true,
			}),
			"auto_http_config": schema.SingleNestedBlock{
				MarkdownDescription: "[OneOf: auto_http_config, http1_config, http2_options] Enable this option",
			},
			"circuit_breaker": schema.SingleNestedBlock{
				MarkdownDescription: "Circuit Breaker. CircuitBreaker provides a mechanism for watching failures in upstream connections or requests and if the failures reach a certain threshold, automatically fail subsequent requests which allows to apply back pressure on downstream quickly.",
				Attributes: map[string]schema.Attribute{
					"connection_limit": schema.Int64Attribute{
						MarkdownDescription: "Connection Limit. The maximum number of connections that loadbalancer will establish to all hosts in an upstream cluster. In practice this is only applicable to TCP and HTTP/1.1 clusters since HTTP/2 uses a single connection to each host. Remove endpoint out of load balancing decision, if number of connections reach connection limit.",
						Optional:            true,
					},
					"max_requests": schema.Int64Attribute{
						MarkdownDescription: "Maximum Request Count. The maximum number of requests that can be outstanding to all hosts in a cluster at any given time. In practice this is applicable to HTTP/2 clusters since HTTP/1.1 clusters are governed by the maximum connections (connection_limit). Remove endpoint out of load balancing decision, if requests exceed this count.",
						Optional:            true,
					},
					"pending_requests": schema.Int64Attribute{
						MarkdownDescription: "Pending Requests. The maximum number of requests that will be queued while waiting for a ready connection pool connection. Since HTTP/2 requests are sent over a single connection, this circuit breaker only comes into play as the initial connection is created, as requests will be multiplexed immediately afterwards. For HTTP/1.1, requests are added to the list of pending requests whenever there aren’t enough upstream connections available to immediately dispatch the request, so this circuit breaker will remain in play for the lifetime of the process. Remove endpoint out of load balancing decision, if pending request reach pending_request.",
						Optional:            true,
					},
					"priority": schema.StringAttribute{
						MarkdownDescription: "[Enum: DEFAULT|HIGH] Routing Priority. Priority routing for each request. Different connection pools are used based on the priority selected for the request. Also, circuit-breaker configuration at destination cluster is chosen based on selected priority. Default routing mechanism High-Priority routing mechanism. Possible values are `DEFAULT`, `HIGH`. Defaults to `DEFAULT`.",
						Optional:            true,
					},
					"retries": schema.Int64Attribute{
						MarkdownDescription: "Retry Count. The maximum number of retries that can be outstanding to all hosts in a cluster at any given time. Remove endpoint out of load balancing decision, if retries for request exceed this count.",
						Optional:            true,
					},
				},
			},
			"default_subset": schema.SingleNestedBlock{
				MarkdownDescription: "Default Subset. List of key-value pairs that define default subset. This subset can be referred in fallback_policy which gets used when route specifies no metadata or no subset matching the metadata exists.",
			},
			"disable_proxy_protocol": schema.SingleNestedBlock{
				MarkdownDescription: "[OneOf: disable_proxy_protocol, proxy_protocol_v1, proxy_protocol_v2; Default: disable_proxy_protocol] Enable this option",
			},
			"endpoint_subsets": schema.ListNestedBlock{
				MarkdownDescription: "Endpoint Subsets. Cluster may be configured to divide its endpoints into subsets based on metadata attached to the endpoints. Routes may then specify the metadata that a endpoint must match in order to be selected by the load balancer. endpoint_subsets is list of subsets for this cluster. Each entry in this list has definition for a subset (which is collection of keys) During routing, the route’s metadata match configuration is used to find a specific subset. If there is a subset with the exact keys and values specified by the route, the subset is used for load balancing. Otherwise, the fallback policy is used. The cluster’s subset configuration must, therefore, contain a definition that has the same keys as a given route in order for subset load balancing to occur. RouteConfig routes: - match: - headers: [] path: path: /1.log query_params: [] routeDestination: destinations: - cluster: - kind: cluster.Object uid: 00000000-0000-0000-0001-000000000005 endpointSubsets: site: india EndpointConfig metadata: labels: deployment: debug site: india name: end-1 uid: end-1 ClusterConfig gcSpec: defaultSubset: stage: production fallbackPolicy: DEFAULT_SUBSET endpointSubsets: - keys: - site - keys: - stage - app Assume the below endpoints are defined and associated with the cluster. Endpoint Labels -------- ------ ep1 stage: production, site: india ep2 stage: deployment, site: us ep3 stage: production, app: hr ep4 site: india The following table describes some routes and the result of their application to the cluster. The subset definition for cluster is assumed to be same as given above in the ClusterConfig section RouteMatch Criteria Subset Reason ------------------- ------ ------ site: india ep1, ep4 Subset of endpoints selected site: us ep2 Subset of endpoints selected app: hr ep1, ep3 Fallback: No subset selector for 'app' alone stage: production, app: hr ep3 Subset of endpoints selected other: x ep1, ep3 Fallback: No subset selector for “other” (none) ep1, ep3 Fallback: No subset requested",
				NestedObject: schema.NestedBlockObject{
					Attributes: map[string]schema.Attribute{
						"keys": schema.ListAttribute{
							MarkdownDescription: "Keys. List of keys that define a cluster subset class.",
							Optional:            true,
							ElementType:         types.StringType,
						},
					},
				},
			},
			"endpoints": schema.ListNestedBlock{
				MarkdownDescription: "Endpoints. List of references to all endpoint objects that belong to this cluster.",
				NestedObject: schema.NestedBlockObject{
					Attributes: map[string]schema.Attribute{
						"kind": schema.StringAttribute{
							MarkdownDescription: "Kind. When a configuration object(e.g. virtual_host) refers to another(e.g route) then kind will hold the referred object's kind (e.g. 'route')",
							Optional:            true,
							Computed:            true,
						},
						"name": schema.StringAttribute{
							MarkdownDescription: "Name. When a configuration object(e.g. virtual_host) refers to another(e.g route) then name will hold the referred object's(e.g. route's) name.",
							Optional:            true,
						},
						"namespace": schema.StringAttribute{
							MarkdownDescription: "Namespace. When a configuration object(e.g. virtual_host) refers to another(e.g route) then namespace will hold the referred object's(e.g. route's) namespace.",
							Optional:            true,
						},
						"tenant": schema.StringAttribute{
							MarkdownDescription: "Tenant. When a configuration object(e.g. virtual_host) refers to another(e.g route) then tenant will hold the referred object's(e.g. route's) tenant.",
							Optional:            true,
							Computed:            true,
						},
						"uid": schema.StringAttribute{
							MarkdownDescription: "UID. When a configuration object(e.g. virtual_host) refers to another(e.g route) then uid will hold the referred object's(e.g. route's) uid.",
							Optional:            true,
							Computed:            true,
						},
					},
				},
			},
			"health_checks": schema.ListNestedBlock{
				MarkdownDescription: "Health Checks. List of references to healthcheck object for this cluster.",
				NestedObject: schema.NestedBlockObject{
					Attributes: map[string]schema.Attribute{
						"kind": schema.StringAttribute{
							MarkdownDescription: "Kind. When a configuration object(e.g. virtual_host) refers to another(e.g route) then kind will hold the referred object's kind (e.g. 'route')",
							Optional:            true,
							Computed:            true,
						},
						"name": schema.StringAttribute{
							MarkdownDescription: "Name. When a configuration object(e.g. virtual_host) refers to another(e.g route) then name will hold the referred object's(e.g. route's) name.",
							Optional:            true,
						},
						"namespace": schema.StringAttribute{
							MarkdownDescription: "Namespace. When a configuration object(e.g. virtual_host) refers to another(e.g route) then namespace will hold the referred object's(e.g. route's) namespace.",
							Optional:            true,
						},
						"tenant": schema.StringAttribute{
							MarkdownDescription: "Tenant. When a configuration object(e.g. virtual_host) refers to another(e.g route) then tenant will hold the referred object's(e.g. route's) tenant.",
							Optional:            true,
							Computed:            true,
						},
						"uid": schema.StringAttribute{
							MarkdownDescription: "UID. When a configuration object(e.g. virtual_host) refers to another(e.g route) then uid will hold the referred object's(e.g. route's) uid.",
							Optional:            true,
							Computed:            true,
						},
					},
				},
			},
			"http1_config": schema.SingleNestedBlock{
				MarkdownDescription: "HTTP/1.1 Protocol Options. HTTP/1.1 Protocol options for upstream connections",
				Attributes:          map[string]schema.Attribute{},
				Blocks: map[string]schema.Block{
					"header_transformation": schema.SingleNestedBlock{
						MarkdownDescription: "Header Transformation. Header Transformation options for HTTP/1.1 request/response headers",
						Attributes:          map[string]schema.Attribute{},
						Blocks: map[string]schema.Block{
							"default_header_transformation": schema.SingleNestedBlock{
								MarkdownDescription: "Enable this option",
							},
							"legacy_header_transformation": schema.SingleNestedBlock{
								MarkdownDescription: "Enable this option",
							},
							"preserve_case_header_transformation": schema.SingleNestedBlock{
								MarkdownDescription: "Enable this option",
							},
							"proper_case_header_transformation": schema.SingleNestedBlock{
								MarkdownDescription: "Enable this option",
							},
						},
					},
				},
			},
			"http2_options": schema.SingleNestedBlock{
				MarkdownDescription: "Http2 Protocol Options. Http2 Protocol options for upstream connections",
				Attributes: map[string]schema.Attribute{
					"enabled": schema.BoolAttribute{
						MarkdownDescription: "HTTP2 Enabled. Enable/disable HTTP2 Protocol for upstream connections",
						Optional:            true,
					},
				},
			},
			"no_panic_threshold": schema.SingleNestedBlock{
				MarkdownDescription: "[OneOf: no_panic_threshold, panic_threshold; Default: no_panic_threshold] Enable this option",
			},
			"outlier_detection": schema.SingleNestedBlock{
				MarkdownDescription: "Outlier Detection. Outlier detection and ejection is the process of dynamically determining whether some number of hosts in an upstream cluster are performing unlike the others and removing them from the healthy load balancing set. Outlier detection is a form of passive health checking. Algorithm 1. A endpoint is determined to be an outlier (based on configured number of consecutive_5xx or consecutive_gateway_failures) . 2. If no endpoints have been ejected, loadbalancer will eject the host immediately. Otherwise, it checks to make sure the number of ejected hosts is below the allowed threshold (specified via max_ejection_percent setting). If the number of ejected hosts is above the threshold, the host is not ejected. 3. The endpoint is ejected for some number of milliseconds. Ejection means that the endpoint is marked unhealthy and will not be used during load balancing. The number of milliseconds is equal to the base_ejection_time value multiplied by the number of times the host has been ejected. 4. An ejected endpoint will automatically be brought back into service after the ejection time has been satisfied",
				Attributes: map[string]schema.Attribute{
					"base_ejection_time": schema.Int64Attribute{
						MarkdownDescription: "Base Ejection Time. The base time that a host is ejected for. The real time is equal to the base time multiplied by the number of times the host has been ejected. This causes hosts to get ejected for longer periods if they continue to fail. Specified in milliseconds. Defaults to `30000ms`.",
						Optional:            true,
					},
					"consecutive_5xx": schema.Int64Attribute{
						MarkdownDescription: "Consecutive 5xx Count. If an upstream endpoint returns some number of consecutive 5xx, it will be ejected. Note that in this case a 5xx means an actual 5xx respond code, or an event that would cause the HTTP router to return one on the upstream’s behalf(reset, connection failure, etc.) consecutive_5xx indicates the number of consecutive 5xx responses required before a consecutive 5xx ejection occurs. Defaults to `5`.",
						Optional:            true,
					},
					"consecutive_gateway_failure": schema.Int64Attribute{
						MarkdownDescription: "Consecutive Gateway Failure. If an upstream endpoint returns some number of consecutive “gateway errors” (502, 503 or 504 status code), it will be ejected. Note that this includes events that would cause the HTTP router to return one of these status codes on the upstream’s behalf (reset, connection failure, etc.). consecutive_gateway_failure indicates the number of consecutive gateway failures before a consecutive gateway failure ejection occurs. Defaults to `5`.",
						Optional:            true,
					},
					"interval": schema.Int64Attribute{
						MarkdownDescription: "Interval. The time interval between ejection analysis sweeps. This can result in both new ejections as well as endpoints being returned to service. Specified in milliseconds. Defaults to `10000ms`.",
						Optional:            true,
					},
					"max_ejection_percent": schema.Int64Attribute{
						MarkdownDescription: "Max Ejection Percentage. The maximum % of an upstream cluster that can be ejected due to outlier detection.  but will eject at least one host regardless of the value. Defaults to `10%`.",
						Optional:            true,
					},
				},
			},
			"proxy_protocol_v1": schema.SingleNestedBlock{
				MarkdownDescription: "Enable this option",
			},
			"proxy_protocol_v2": schema.SingleNestedBlock{
				MarkdownDescription: "Enable this option",
			},
			"tls_parameters": schema.SingleNestedBlock{
				MarkdownDescription: "Upstream TLS Parameters. TLS configuration for upstream connections",
				Attributes: map[string]schema.Attribute{
					"max_session_keys": schema.Int64Attribute{
						MarkdownDescription: "Max Session Keys Cached. Number of session keys that are cached.",
						Optional:            true,
					},
					"sni": schema.StringAttribute{
						MarkdownDescription: "SNI Value. SNI value to be used.",
						Optional:            true,
					},
				},
				Blocks: map[string]schema.Block{
					"cert_params": schema.SingleNestedBlock{
						MarkdownDescription: "Upstream Certificate Parameters. Certificate Parameters for authentication, TLS ciphers, and trust store",
						Attributes: map[string]schema.Attribute{
							"cipher_suites": schema.ListAttribute{
								MarkdownDescription: "Cipher Suites. The following list specifies the supported cipher suite TLS_AES_128_GCM_SHA256 TLS_AES_256_GCM_SHA384 TLS_CHACHA20_POLY1305_SHA256 TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256 TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384 TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256 TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256 TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA TLS_RSA_WITH_AES_128_CBC_SHA TLS_RSA_WITH_AES_128_GCM_SHA256 TLS_RSA_WITH_AES_256_CBC_SHA TLS_RSA_WITH_AES_256_GCM_SHA384 If not specified, the default list: TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256 TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256 TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256 TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384 TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 will be used.",
								Optional:            true,
								ElementType:         types.StringType,
							},
							"maximum_protocol_version": schema.StringAttribute{
								MarkdownDescription: "[Enum: TLS_AUTO|TLSv1_0|TLSv1_1|TLSv1_2|TLSv1_3] TLS Protocol. TlsProtocol is enumeration of supported TLS versions F5 Distributed Cloud will choose the optimal TLS version. Possible values are `TLS_AUTO`, `TLSv1_0`, `TLSv1_1`, `TLSv1_2`, `TLSv1_3`. Defaults to `TLS_AUTO`.",
								Optional:            true,
							},
							"minimum_protocol_version": schema.StringAttribute{
								MarkdownDescription: "[Enum: TLS_AUTO|TLSv1_0|TLSv1_1|TLSv1_2|TLSv1_3] TLS Protocol. TlsProtocol is enumeration of supported TLS versions F5 Distributed Cloud will choose the optimal TLS version. Possible values are `TLS_AUTO`, `TLSv1_0`, `TLSv1_1`, `TLSv1_2`, `TLSv1_3`. Defaults to `TLS_AUTO`.",
								Optional:            true,
							},
						},
						Blocks: map[string]schema.Block{
							"certificates": schema.ListNestedBlock{
								MarkdownDescription: "Client Certificate. Client TLS Certificate required for mTLS authentication",
								NestedObject: schema.NestedBlockObject{
									Attributes: map[string]schema.Attribute{
										"kind": schema.StringAttribute{
											MarkdownDescription: "Kind. When a configuration object(e.g. virtual_host) refers to another(e.g route) then kind will hold the referred object's kind (e.g. 'route')",
											Optional:            true,
											Computed:            true,
										},
										"name": schema.StringAttribute{
											MarkdownDescription: "Name. When a configuration object(e.g. virtual_host) refers to another(e.g route) then name will hold the referred object's(e.g. route's) name.",
											Optional:            true,
										},
										"namespace": schema.StringAttribute{
											MarkdownDescription: "Namespace. When a configuration object(e.g. virtual_host) refers to another(e.g route) then namespace will hold the referred object's(e.g. route's) namespace.",
											Optional:            true,
										},
										"tenant": schema.StringAttribute{
											MarkdownDescription: "Tenant. When a configuration object(e.g. virtual_host) refers to another(e.g route) then tenant will hold the referred object's(e.g. route's) tenant.",
											Optional:            true,
											Computed:            true,
										},
										"uid": schema.StringAttribute{
											MarkdownDescription: "UID. When a configuration object(e.g. virtual_host) refers to another(e.g route) then uid will hold the referred object's(e.g. route's) uid.",
											Optional:            true,
											Computed:            true,
										},
									},
								},
							},
							"validation_params": schema.SingleNestedBlock{
								MarkdownDescription: "TLS Certificate Validation Parameters. This includes URL for a trust store, whether SAN verification is required and list of Subject Alt Names for verification",
								Attributes: map[string]schema.Attribute{
									"skip_hostname_verification": schema.BoolAttribute{
										MarkdownDescription: "Skip verification of hostname. When True, skip verification of hostname i.e. CN/Subject Alt Name of certificate is not matched to the connecting hostname",
										Optional:            true,
									},
									"trusted_ca_url": schema.StringAttribute{
										MarkdownDescription: "Inline Root CA Certificate (legacy). Inline Root CA Certificate",
										Optional:            true,
									},
									"verify_subject_alt_names": schema.ListAttribute{
										MarkdownDescription: "List of SANs for matching. List of acceptable Subject Alt Names/CN in the peer's certificate. When skip_hostname_verification is false and verify_subject_alt_names is empty, the hostname of the peer will be used for matching against SAN/CN of peer's certificate",
										Optional:            true,
										ElementType:         types.StringType,
									},
								},
								Blocks: map[string]schema.Block{
									"trusted_ca": schema.SingleNestedBlock{
										MarkdownDescription: "Root CA Certificate Reference. Reference to Root CA Certificate",
										Attributes:          map[string]schema.Attribute{},
										Blocks: map[string]schema.Block{
											"trusted_ca_list": schema.ListNestedBlock{
												MarkdownDescription: "Root CA Certificate Reference. Reference to Root CA Certificate",
												NestedObject: schema.NestedBlockObject{
													Attributes: map[string]schema.Attribute{
														"kind": schema.StringAttribute{
															MarkdownDescription: "Kind. When a configuration object(e.g. virtual_host) refers to another(e.g route) then kind will hold the referred object's kind (e.g. 'route')",
															Optional:            true,
															Computed:            true,
														},
														"name": schema.StringAttribute{
															MarkdownDescription: "Name. When a configuration object(e.g. virtual_host) refers to another(e.g route) then name will hold the referred object's(e.g. route's) name.",
															Optional:            true,
														},
														"namespace": schema.StringAttribute{
															MarkdownDescription: "Namespace. When a configuration object(e.g. virtual_host) refers to another(e.g route) then namespace will hold the referred object's(e.g. route's) namespace.",
															Optional:            true,
														},
														"tenant": schema.StringAttribute{
															MarkdownDescription: "Tenant. When a configuration object(e.g. virtual_host) refers to another(e.g route) then tenant will hold the referred object's(e.g. route's) tenant.",
															Optional:            true,
															Computed:            true,
														},
														"uid": schema.StringAttribute{
															MarkdownDescription: "UID. When a configuration object(e.g. virtual_host) refers to another(e.g route) then uid will hold the referred object's(e.g. route's) uid.",
															Optional:            true,
															Computed:            true,
														},
													},
												},
											},
										},
									},
								},
							},
						},
					},
					"common_params": schema.SingleNestedBlock{
						MarkdownDescription: "TLS Parameters. Information of different aspects for TLS authentication related to ciphers, certificates and trust store",
						Attributes: map[string]schema.Attribute{
							"cipher_suites": schema.ListAttribute{
								MarkdownDescription: "Cipher Suites. The following list specifies the supported cipher suite TLS_AES_128_GCM_SHA256 TLS_AES_256_GCM_SHA384 TLS_CHACHA20_POLY1305_SHA256 TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256 TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384 TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256 TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256 TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA TLS_RSA_WITH_AES_128_CBC_SHA TLS_RSA_WITH_AES_128_GCM_SHA256 TLS_RSA_WITH_AES_256_CBC_SHA TLS_RSA_WITH_AES_256_GCM_SHA384 If not specified, the default list: TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256 TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256 TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256 TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384 TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 will be used.",
								Optional:            true,
								ElementType:         types.StringType,
							},
							"maximum_protocol_version": schema.StringAttribute{
								MarkdownDescription: "[Enum: TLS_AUTO|TLSv1_0|TLSv1_1|TLSv1_2|TLSv1_3] TLS Protocol. TlsProtocol is enumeration of supported TLS versions F5 Distributed Cloud will choose the optimal TLS version. Possible values are `TLS_AUTO`, `TLSv1_0`, `TLSv1_1`, `TLSv1_2`, `TLSv1_3`. Defaults to `TLS_AUTO`.",
								Optional:            true,
							},
							"minimum_protocol_version": schema.StringAttribute{
								MarkdownDescription: "[Enum: TLS_AUTO|TLSv1_0|TLSv1_1|TLSv1_2|TLSv1_3] TLS Protocol. TlsProtocol is enumeration of supported TLS versions F5 Distributed Cloud will choose the optimal TLS version. Possible values are `TLS_AUTO`, `TLSv1_0`, `TLSv1_1`, `TLSv1_2`, `TLSv1_3`. Defaults to `TLS_AUTO`.",
								Optional:            true,
							},
						},
						Blocks: map[string]schema.Block{
							"tls_certificates": schema.ListNestedBlock{
								MarkdownDescription: "TLS Certificates. Set of TLS certificates",
								NestedObject: schema.NestedBlockObject{
									Attributes: map[string]schema.Attribute{
										"certificate_url": schema.StringAttribute{
											MarkdownDescription: "Certificate. TLS certificate. Certificate or certificate chain in PEM format including the PEM headers.",
											Optional:            true,
										},
										"description_spec": schema.StringAttribute{
											MarkdownDescription: "Description. Description for the certificate",
											Optional:            true,
										},
									},
									Blocks: map[string]schema.Block{
										"custom_hash_algorithms": schema.SingleNestedBlock{
											MarkdownDescription: "Hash Algorithms. Specifies the hash algorithms to be used",
											Attributes: map[string]schema.Attribute{
												"hash_algorithms": schema.ListAttribute{
													MarkdownDescription: "[Enum: INVALID_HASH_ALGORITHM|SHA256|SHA1] Hash Algorithms. Ordered list of hash algorithms to be used. Possible values are `INVALID_HASH_ALGORITHM`, `SHA256`, `SHA1`. Defaults to `INVALID_HASH_ALGORITHM`.",
													Optional:            true,
													ElementType:         types.StringType,
												},
											},
										},
										"disable_ocsp_stapling": schema.SingleNestedBlock{
											MarkdownDescription: "Enable this option",
										},
										"private_key": schema.SingleNestedBlock{
											MarkdownDescription: "Secret. SecretType is used in an object to indicate a sensitive/confidential field",
											Attributes:          map[string]schema.Attribute{},
											Blocks: map[string]schema.Block{
												"blindfold_secret_info": schema.SingleNestedBlock{
													MarkdownDescription: "Blindfold Secret. BlindfoldSecretInfoType specifies information about the Secret managed by F5XC Secret Management",
													Attributes: map[string]schema.Attribute{
														"decryption_provider": schema.StringAttribute{
															MarkdownDescription: "Decryption Provider. Name of the Secret Management Access object that contains information about the backend Secret Management service.",
															Optional:            true,
														},
														"location": schema.StringAttribute{
															MarkdownDescription: "Location. Location is the uri_ref. It could be in url format for string:/// Or it could be a path if the store provider is an http/https location",
															Optional:            true,
														},
														"store_provider": schema.StringAttribute{
															MarkdownDescription: "Store Provider. Name of the Secret Management Access object that contains information about the store to get encrypted bytes This field needs to be provided only if the url scheme is not string:///",
															Optional:            true,
														},
													},
												},
												"clear_secret_info": schema.SingleNestedBlock{
													MarkdownDescription: "In-Clear Secret. ClearSecretInfoType specifies information about the Secret that is not encrypted.",
													Attributes: map[string]schema.Attribute{
														"provider_ref": schema.StringAttribute{
															MarkdownDescription: "Provider. Name of the Secret Management Access object that contains information about the store to get encrypted bytes This field needs to be provided only if the url scheme is not string:///",
															Optional:            true,
														},
														"url": schema.StringAttribute{
															MarkdownDescription: "URL. URL of the secret. Currently supported URL schemes is string:///. For string:/// scheme, Secret needs to be encoded Base64 format. When asked for this secret, caller will get Secret bytes after Base64 decoding.",
															Optional:            true,
														},
													},
												},
											},
										},
										"use_system_defaults": schema.SingleNestedBlock{
											MarkdownDescription: "Enable this option",
										},
									},
								},
							},
							"validation_params": schema.SingleNestedBlock{
								MarkdownDescription: "TLS Certificate Validation Parameters. This includes URL for a trust store, whether SAN verification is required and list of Subject Alt Names for verification",
								Attributes: map[string]schema.Attribute{
									"skip_hostname_verification": schema.BoolAttribute{
										MarkdownDescription: "Skip verification of hostname. When True, skip verification of hostname i.e. CN/Subject Alt Name of certificate is not matched to the connecting hostname",
										Optional:            true,
									},
									"trusted_ca_url": schema.StringAttribute{
										MarkdownDescription: "Inline Root CA Certificate (legacy). Inline Root CA Certificate",
										Optional:            true,
									},
									"verify_subject_alt_names": schema.ListAttribute{
										MarkdownDescription: "List of SANs for matching. List of acceptable Subject Alt Names/CN in the peer's certificate. When skip_hostname_verification is false and verify_subject_alt_names is empty, the hostname of the peer will be used for matching against SAN/CN of peer's certificate",
										Optional:            true,
										ElementType:         types.StringType,
									},
								},
								Blocks: map[string]schema.Block{
									"trusted_ca": schema.SingleNestedBlock{
										MarkdownDescription: "Root CA Certificate Reference. Reference to Root CA Certificate",
										Attributes:          map[string]schema.Attribute{},
										Blocks: map[string]schema.Block{
											"trusted_ca_list": schema.ListNestedBlock{
												MarkdownDescription: "Root CA Certificate Reference. Reference to Root CA Certificate",
												NestedObject: schema.NestedBlockObject{
													Attributes: map[string]schema.Attribute{
														"kind": schema.StringAttribute{
															MarkdownDescription: "Kind. When a configuration object(e.g. virtual_host) refers to another(e.g route) then kind will hold the referred object's kind (e.g. 'route')",
															Optional:            true,
															Computed:            true,
														},
														"name": schema.StringAttribute{
															MarkdownDescription: "Name. When a configuration object(e.g. virtual_host) refers to another(e.g route) then name will hold the referred object's(e.g. route's) name.",
															Optional:            true,
														},
														"namespace": schema.StringAttribute{
															MarkdownDescription: "Namespace. When a configuration object(e.g. virtual_host) refers to another(e.g route) then namespace will hold the referred object's(e.g. route's) namespace.",
															Optional:            true,
														},
														"tenant": schema.StringAttribute{
															MarkdownDescription: "Tenant. When a configuration object(e.g. virtual_host) refers to another(e.g route) then tenant will hold the referred object's(e.g. route's) tenant.",
															Optional:            true,
															Computed:            true,
														},
														"uid": schema.StringAttribute{
															MarkdownDescription: "UID. When a configuration object(e.g. virtual_host) refers to another(e.g route) then uid will hold the referred object's(e.g. route's) uid.",
															Optional:            true,
															Computed:            true,
														},
													},
												},
											},
										},
									},
								},
							},
						},
					},
					"default_session_key_caching": schema.SingleNestedBlock{
						MarkdownDescription: "Enable this option",
					},
					"disable_session_key_caching": schema.SingleNestedBlock{
						MarkdownDescription: "Enable this option",
					},
					"disable_sni": schema.SingleNestedBlock{
						MarkdownDescription: "Enable this option",
					},
					"use_host_header_as_sni": schema.SingleNestedBlock{
						MarkdownDescription: "Enable this option",
					},
				},
			},
			"upstream_conn_pool_reuse_type": schema.SingleNestedBlock{
				MarkdownDescription: "Select upstream connection pool reuse state. Select upstream connection pool reuse state for every downstream connection. This configuration choice is for HTTP(S) LB only.",
				Attributes:          map[string]schema.Attribute{},
				Blocks: map[string]schema.Block{
					"disable_conn_pool_reuse": schema.SingleNestedBlock{
						MarkdownDescription: "Enable this option",
					},
					"enable_conn_pool_reuse": schema.SingleNestedBlock{
						MarkdownDescription: "Enable this option",
					},
				},
			},
		},
	}
}

func (r *ClusterResource) Configure(ctx context.Context, req resource.ConfigureRequest, resp *resource.ConfigureResponse) {
	if req.ProviderData == nil {
		return
	}
	client, ok := req.ProviderData.(*client.Client)
	if !ok {
		resp.Diagnostics.AddError(
			"Unexpected Resource Configure Type",
			fmt.Sprintf("Expected *client.Client, got: %T. Please report this issue to the provider developers.", req.ProviderData),
		)
		return
	}
	r.client = client
}

// ValidateConfig implements resource.ResourceWithValidateConfig
func (r *ClusterResource) ValidateConfig(ctx context.Context, req resource.ValidateConfigRequest, resp *resource.ValidateConfigResponse) {
	var data ClusterResourceModel
	resp.Diagnostics.Append(req.Config.Get(ctx, &data)...)
	if resp.Diagnostics.HasError() {
		return
	}
}

// ModifyPlan implements resource.ResourceWithModifyPlan
func (r *ClusterResource) ModifyPlan(ctx context.Context, req resource.ModifyPlanRequest, resp *resource.ModifyPlanResponse) {
	if req.Plan.Raw.IsNull() {
		resp.Diagnostics.AddWarning(
			"Resource Destruction",
			"This will permanently delete the cluster from F5 Distributed Cloud.",
		)
		return
	}

	if req.State.Raw.IsNull() {
		var plan ClusterResourceModel
		resp.Diagnostics.Append(req.Plan.Get(ctx, &plan)...)
		if resp.Diagnostics.HasError() {
			return
		}

		if plan.Name.IsUnknown() {
			resp.Diagnostics.AddWarning(
				"Unknown Resource Name",
				"The resource name is not yet known. This may affect planning for dependent resources.",
			)
		}
	}
}

// UpgradeState implements resource.ResourceWithUpgradeState
func (r *ClusterResource) UpgradeState(ctx context.Context) map[int64]resource.StateUpgrader {
	return map[int64]resource.StateUpgrader{
		0: {
			PriorSchema: &schema.Schema{
				Attributes: map[string]schema.Attribute{
					"name":        schema.StringAttribute{Required: true},
					"namespace":   schema.StringAttribute{Required: true},
					"annotations": schema.MapAttribute{Optional: true, ElementType: types.StringType},
					"labels":      schema.MapAttribute{Optional: true, ElementType: types.StringType},
					"id":          schema.StringAttribute{Computed: true},
				},
			},
			StateUpgrader: func(ctx context.Context, req resource.UpgradeStateRequest, resp *resource.UpgradeStateResponse) {
				var priorState struct {
					Name        types.String `tfsdk:"name"`
					Namespace   types.String `tfsdk:"namespace"`
					Annotations types.Map    `tfsdk:"annotations"`
					Labels      types.Map    `tfsdk:"labels"`
					ID          types.String `tfsdk:"id"`
				}

				resp.Diagnostics.Append(req.State.Get(ctx, &priorState)...)
				if resp.Diagnostics.HasError() {
					return
				}

				upgradedState := ClusterResourceModel{
					Name:        priorState.Name,
					Namespace:   priorState.Namespace,
					Annotations: priorState.Annotations,
					Labels:      priorState.Labels,
					ID:          priorState.ID,
					Timeouts:    timeouts.Value{},
				}

				resp.Diagnostics.Append(resp.State.Set(ctx, upgradedState)...)
			},
		},
	}
}

func (r *ClusterResource) Create(ctx context.Context, req resource.CreateRequest, resp *resource.CreateResponse) {
	var data ClusterResourceModel
	resp.Diagnostics.Append(req.Plan.Get(ctx, &data)...)
	if resp.Diagnostics.HasError() {
		return
	}

	createTimeout, diags := data.Timeouts.Create(ctx, inttimeouts.DefaultCreate)
	resp.Diagnostics.Append(diags...)
	if resp.Diagnostics.HasError() {
		return
	}

	ctx, cancel := context.WithTimeout(ctx, createTimeout)
	defer cancel()

	tflog.Debug(ctx, "Creating cluster", map[string]interface{}{
		"name":      data.Name.ValueString(),
		"namespace": data.Namespace.ValueString(),
	})

	createReq := &client.Cluster{
		Metadata: client.Metadata{
			Name:      data.Name.ValueString(),
			Namespace: data.Namespace.ValueString(),
		},
		Spec: make(map[string]interface{}),
	}

	if !data.Description.IsNull() {
		createReq.Metadata.Description = data.Description.ValueString()
	}

	if !data.Labels.IsNull() {
		labels := make(map[string]string)
		resp.Diagnostics.Append(data.Labels.ElementsAs(ctx, &labels, false)...)
		if resp.Diagnostics.HasError() {
			return
		}
		createReq.Metadata.Labels = labels
	}

	if !data.Annotations.IsNull() {
		annotations := make(map[string]string)
		resp.Diagnostics.Append(data.Annotations.ElementsAs(ctx, &annotations, false)...)
		if resp.Diagnostics.HasError() {
			return
		}
		createReq.Metadata.Annotations = annotations
	}

	// Marshal spec fields from Terraform state to API struct
	if data.AutoHTTPConfig != nil {
		auto_http_configMap := make(map[string]interface{})
		createReq.Spec["auto_http_config"] = auto_http_configMap
	}
	if data.CircuitBreaker != nil {
		circuit_breakerMap := make(map[string]interface{})
		if !data.CircuitBreaker.ConnectionLimit.IsNull() && !data.CircuitBreaker.ConnectionLimit.IsUnknown() {
			circuit_breakerMap["connection_limit"] = data.CircuitBreaker.ConnectionLimit.ValueInt64()
		}
		if !data.CircuitBreaker.MaxRequests.IsNull() && !data.CircuitBreaker.MaxRequests.IsUnknown() {
			circuit_breakerMap["max_requests"] = data.CircuitBreaker.MaxRequests.ValueInt64()
		}
		if !data.CircuitBreaker.PendingRequests.IsNull() && !data.CircuitBreaker.PendingRequests.IsUnknown() {
			circuit_breakerMap["pending_requests"] = data.CircuitBreaker.PendingRequests.ValueInt64()
		}
		if !data.CircuitBreaker.Priority.IsNull() && !data.CircuitBreaker.Priority.IsUnknown() {
			circuit_breakerMap["priority"] = data.CircuitBreaker.Priority.ValueString()
		}
		if !data.CircuitBreaker.Retries.IsNull() && !data.CircuitBreaker.Retries.IsUnknown() {
			circuit_breakerMap["retries"] = data.CircuitBreaker.Retries.ValueInt64()
		}
		createReq.Spec["circuit_breaker"] = circuit_breakerMap
	}
	if data.DefaultSubset != nil {
		default_subsetMap := make(map[string]interface{})
		createReq.Spec["default_subset"] = default_subsetMap
	}
	if data.DisableProxyProtocol != nil {
		disable_proxy_protocolMap := make(map[string]interface{})
		createReq.Spec["disable_proxy_protocol"] = disable_proxy_protocolMap
	}
	if len(data.EndpointSubsets) > 0 {
		var endpoint_subsetsList []map[string]interface{}
		for range data.EndpointSubsets {
			itemMap := make(map[string]interface{})
			endpoint_subsetsList = append(endpoint_subsetsList, itemMap)
		}
		createReq.Spec["endpoint_subsets"] = endpoint_subsetsList
	}
	if len(data.Endpoints) > 0 {
		var endpointsList []map[string]interface{}
		for _, item := range data.Endpoints {
			itemMap := make(map[string]interface{})
			if !item.Kind.IsNull() && !item.Kind.IsUnknown() {
				itemMap["kind"] = item.Kind.ValueString()
			}
			if !item.Name.IsNull() && !item.Name.IsUnknown() {
				itemMap["name"] = item.Name.ValueString()
			}
			if !item.Namespace.IsNull() && !item.Namespace.IsUnknown() {
				itemMap["namespace"] = item.Namespace.ValueString()
			}
			if !item.Tenant.IsNull() && !item.Tenant.IsUnknown() {
				itemMap["tenant"] = item.Tenant.ValueString()
			}
			if !item.Uid.IsNull() && !item.Uid.IsUnknown() {
				itemMap["uid"] = item.Uid.ValueString()
			}
			endpointsList = append(endpointsList, itemMap)
		}
		createReq.Spec["endpoints"] = endpointsList
	}
	if len(data.HealthChecks) > 0 {
		var health_checksList []map[string]interface{}
		for _, item := range data.HealthChecks {
			itemMap := make(map[string]interface{})
			if !item.Kind.IsNull() && !item.Kind.IsUnknown() {
				itemMap["kind"] = item.Kind.ValueString()
			}
			if !item.Name.IsNull() && !item.Name.IsUnknown() {
				itemMap["name"] = item.Name.ValueString()
			}
			if !item.Namespace.IsNull() && !item.Namespace.IsUnknown() {
				itemMap["namespace"] = item.Namespace.ValueString()
			}
			if !item.Tenant.IsNull() && !item.Tenant.IsUnknown() {
				itemMap["tenant"] = item.Tenant.ValueString()
			}
			if !item.Uid.IsNull() && !item.Uid.IsUnknown() {
				itemMap["uid"] = item.Uid.ValueString()
			}
			health_checksList = append(health_checksList, itemMap)
		}
		createReq.Spec["health_checks"] = health_checksList
	}
	if data.Http1Config != nil {
		http1_configMap := make(map[string]interface{})
		if data.Http1Config.HeaderTransformation != nil {
			header_transformationNestedMap := make(map[string]interface{})
			http1_configMap["header_transformation"] = header_transformationNestedMap
		}
		createReq.Spec["http1_config"] = http1_configMap
	}
	if data.Http2Options != nil {
		http2_optionsMap := make(map[string]interface{})
		if !data.Http2Options.Enabled.IsNull() && !data.Http2Options.Enabled.IsUnknown() {
			http2_optionsMap["enabled"] = data.Http2Options.Enabled.ValueBool()
		}
		createReq.Spec["http2_options"] = http2_optionsMap
	}
	if data.NoPanicThreshold != nil {
		no_panic_thresholdMap := make(map[string]interface{})
		createReq.Spec["no_panic_threshold"] = no_panic_thresholdMap
	}
	if data.OutlierDetection != nil {
		outlier_detectionMap := make(map[string]interface{})
		if !data.OutlierDetection.BaseEjectionTime.IsNull() && !data.OutlierDetection.BaseEjectionTime.IsUnknown() {
			outlier_detectionMap["base_ejection_time"] = data.OutlierDetection.BaseEjectionTime.ValueInt64()
		}
		if !data.OutlierDetection.Consecutive5xx.IsNull() && !data.OutlierDetection.Consecutive5xx.IsUnknown() {
			outlier_detectionMap["consecutive_5xx"] = data.OutlierDetection.Consecutive5xx.ValueInt64()
		}
		if !data.OutlierDetection.ConsecutiveGatewayFailure.IsNull() && !data.OutlierDetection.ConsecutiveGatewayFailure.IsUnknown() {
			outlier_detectionMap["consecutive_gateway_failure"] = data.OutlierDetection.ConsecutiveGatewayFailure.ValueInt64()
		}
		if !data.OutlierDetection.Interval.IsNull() && !data.OutlierDetection.Interval.IsUnknown() {
			outlier_detectionMap["interval"] = data.OutlierDetection.Interval.ValueInt64()
		}
		if !data.OutlierDetection.MaxEjectionPercent.IsNull() && !data.OutlierDetection.MaxEjectionPercent.IsUnknown() {
			outlier_detectionMap["max_ejection_percent"] = data.OutlierDetection.MaxEjectionPercent.ValueInt64()
		}
		createReq.Spec["outlier_detection"] = outlier_detectionMap
	}
	if data.ProxyProtocolV1 != nil {
		proxy_protocol_v1Map := make(map[string]interface{})
		createReq.Spec["proxy_protocol_v1"] = proxy_protocol_v1Map
	}
	if data.ProxyProtocolV2 != nil {
		proxy_protocol_v2Map := make(map[string]interface{})
		createReq.Spec["proxy_protocol_v2"] = proxy_protocol_v2Map
	}
	if data.TLSParameters != nil {
		tls_parametersMap := make(map[string]interface{})
		if data.TLSParameters.CertParams != nil {
			cert_paramsNestedMap := make(map[string]interface{})
			if !data.TLSParameters.CertParams.MaximumProtocolVersion.IsNull() && !data.TLSParameters.CertParams.MaximumProtocolVersion.IsUnknown() {
				cert_paramsNestedMap["maximum_protocol_version"] = data.TLSParameters.CertParams.MaximumProtocolVersion.ValueString()
			}
			if !data.TLSParameters.CertParams.MinimumProtocolVersion.IsNull() && !data.TLSParameters.CertParams.MinimumProtocolVersion.IsUnknown() {
				cert_paramsNestedMap["minimum_protocol_version"] = data.TLSParameters.CertParams.MinimumProtocolVersion.ValueString()
			}
			tls_parametersMap["cert_params"] = cert_paramsNestedMap
		}
		if data.TLSParameters.CommonParams != nil {
			common_paramsNestedMap := make(map[string]interface{})
			if !data.TLSParameters.CommonParams.MaximumProtocolVersion.IsNull() && !data.TLSParameters.CommonParams.MaximumProtocolVersion.IsUnknown() {
				common_paramsNestedMap["maximum_protocol_version"] = data.TLSParameters.CommonParams.MaximumProtocolVersion.ValueString()
			}
			if !data.TLSParameters.CommonParams.MinimumProtocolVersion.IsNull() && !data.TLSParameters.CommonParams.MinimumProtocolVersion.IsUnknown() {
				common_paramsNestedMap["minimum_protocol_version"] = data.TLSParameters.CommonParams.MinimumProtocolVersion.ValueString()
			}
			tls_parametersMap["common_params"] = common_paramsNestedMap
		}
		if data.TLSParameters.DefaultSessionKeyCaching != nil {
			tls_parametersMap["default_session_key_caching"] = map[string]interface{}{}
		}
		if data.TLSParameters.DisableSessionKeyCaching != nil {
			tls_parametersMap["disable_session_key_caching"] = map[string]interface{}{}
		}
		if data.TLSParameters.DisableSni != nil {
			tls_parametersMap["disable_sni"] = map[string]interface{}{}
		}
		if !data.TLSParameters.MaxSessionKeys.IsNull() && !data.TLSParameters.MaxSessionKeys.IsUnknown() {
			tls_parametersMap["max_session_keys"] = data.TLSParameters.MaxSessionKeys.ValueInt64()
		}
		if !data.TLSParameters.Sni.IsNull() && !data.TLSParameters.Sni.IsUnknown() {
			tls_parametersMap["sni"] = data.TLSParameters.Sni.ValueString()
		}
		if data.TLSParameters.UseHostHeaderAsSni != nil {
			tls_parametersMap["use_host_header_as_sni"] = map[string]interface{}{}
		}
		createReq.Spec["tls_parameters"] = tls_parametersMap
	}
	if data.UpstreamConnPoolReuseType != nil {
		upstream_conn_pool_reuse_typeMap := make(map[string]interface{})
		if data.UpstreamConnPoolReuseType.DisableConnPoolReuse != nil {
			upstream_conn_pool_reuse_typeMap["disable_conn_pool_reuse"] = map[string]interface{}{}
		}
		if data.UpstreamConnPoolReuseType.EnableConnPoolReuse != nil {
			upstream_conn_pool_reuse_typeMap["enable_conn_pool_reuse"] = map[string]interface{}{}
		}
		createReq.Spec["upstream_conn_pool_reuse_type"] = upstream_conn_pool_reuse_typeMap
	}
	if !data.ConnectionTimeout.IsNull() && !data.ConnectionTimeout.IsUnknown() {
		createReq.Spec["connection_timeout"] = data.ConnectionTimeout.ValueInt64()
	}
	if !data.EndpointSelection.IsNull() && !data.EndpointSelection.IsUnknown() {
		createReq.Spec["endpoint_selection"] = data.EndpointSelection.ValueString()
	}
	if !data.FallbackPolicy.IsNull() && !data.FallbackPolicy.IsUnknown() {
		createReq.Spec["fallback_policy"] = data.FallbackPolicy.ValueString()
	}
	if !data.HTTPIdleTimeout.IsNull() && !data.HTTPIdleTimeout.IsUnknown() {
		createReq.Spec["http_idle_timeout"] = data.HTTPIdleTimeout.ValueInt64()
	}
	if !data.LoadBalancerAlgorithm.IsNull() && !data.LoadBalancerAlgorithm.IsUnknown() {
		createReq.Spec["loadbalancer_algorithm"] = data.LoadBalancerAlgorithm.ValueString()
	}
	if !data.PanicThreshold.IsNull() && !data.PanicThreshold.IsUnknown() {
		createReq.Spec["panic_threshold"] = data.PanicThreshold.ValueInt64()
	}

	apiResource, err := r.client.CreateCluster(ctx, createReq)
	if err != nil {
		resp.Diagnostics.AddError("Client Error", fmt.Sprintf("Unable to create Cluster: %s", err))
		return
	}

	data.ID = types.StringValue(apiResource.Metadata.Name)

	// Unmarshal spec fields from API response to Terraform state
	// This ensures computed nested fields (like tenant in Object Reference blocks) have known values
	isImport := false // Create is never an import
	_ = isImport      // May be unused if resource has no blocks needing import detection
	if _, ok := apiResource.Spec["auto_http_config"].(map[string]interface{}); ok && isImport && data.AutoHTTPConfig == nil {
		// Import case: populate from API since state is nil and psd is empty
		data.AutoHTTPConfig = &ClusterEmptyModel{}
	}
	// Normal Read: preserve existing state value
	if blockData, ok := apiResource.Spec["circuit_breaker"].(map[string]interface{}); ok && (isImport || data.CircuitBreaker != nil) {
		data.CircuitBreaker = &ClusterCircuitBreakerModel{
			ConnectionLimit: func() types.Int64 {
				if v, ok := blockData["connection_limit"].(float64); ok {
					return types.Int64Value(int64(v))
				}
				return types.Int64Null()
			}(),
			MaxRequests: func() types.Int64 {
				if v, ok := blockData["max_requests"].(float64); ok {
					return types.Int64Value(int64(v))
				}
				return types.Int64Null()
			}(),
			PendingRequests: func() types.Int64 {
				if v, ok := blockData["pending_requests"].(float64); ok {
					return types.Int64Value(int64(v))
				}
				return types.Int64Null()
			}(),
			Priority: func() types.String {
				if v, ok := blockData["priority"].(string); ok && v != "" {
					return types.StringValue(v)
				}
				return types.StringNull()
			}(),
			Retries: func() types.Int64 {
				if v, ok := blockData["retries"].(float64); ok {
					return types.Int64Value(int64(v))
				}
				return types.Int64Null()
			}(),
		}
	}
	if _, ok := apiResource.Spec["default_subset"].(map[string]interface{}); ok && isImport && data.DefaultSubset == nil {
		// Import case: populate from API since state is nil and psd is empty
		data.DefaultSubset = &ClusterEmptyModel{}
	}
	// Normal Read: preserve existing state value
	if _, ok := apiResource.Spec["disable_proxy_protocol"].(map[string]interface{}); ok && isImport && data.DisableProxyProtocol == nil {
		// Import case: populate from API since state is nil and psd is empty
		data.DisableProxyProtocol = &ClusterEmptyModel{}
	}
	// Normal Read: preserve existing state value
	if listData, ok := apiResource.Spec["endpoint_subsets"].([]interface{}); ok && len(listData) > 0 {
		var endpoint_subsetsList []ClusterEndpointSubsetsModel
		for listIdx, item := range listData {
			_ = listIdx // May be unused if no empty marker blocks in list item
			if itemMap, ok := item.(map[string]interface{}); ok {
				endpoint_subsetsList = append(endpoint_subsetsList, ClusterEndpointSubsetsModel{
					Keys: func() types.List {
						if v, ok := itemMap["keys"].([]interface{}); ok && len(v) > 0 {
							var items []string
							for _, item := range v {
								if s, ok := item.(string); ok {
									items = append(items, s)
								}
							}
							listVal, _ := types.ListValueFrom(ctx, types.StringType, items)
							return listVal
						}
						return types.ListNull(types.StringType)
					}(),
				})
			}
		}
		data.EndpointSubsets = endpoint_subsetsList
	}
	if listData, ok := apiResource.Spec["endpoints"].([]interface{}); ok && len(listData) > 0 {
		var endpointsList []ClusterEndpointsModel
		for listIdx, item := range listData {
			_ = listIdx // May be unused if no empty marker blocks in list item
			if itemMap, ok := item.(map[string]interface{}); ok {
				endpointsList = append(endpointsList, ClusterEndpointsModel{
					Kind: func() types.String {
						if v, ok := itemMap["kind"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
					Name: func() types.String {
						if v, ok := itemMap["name"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
					Namespace: func() types.String {
						if v, ok := itemMap["namespace"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
					Tenant: func() types.String {
						if v, ok := itemMap["tenant"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
					Uid: func() types.String {
						if v, ok := itemMap["uid"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
				})
			}
		}
		data.Endpoints = endpointsList
	}
	if listData, ok := apiResource.Spec["health_checks"].([]interface{}); ok && len(listData) > 0 {
		var health_checksList []ClusterHealthChecksModel
		for listIdx, item := range listData {
			_ = listIdx // May be unused if no empty marker blocks in list item
			if itemMap, ok := item.(map[string]interface{}); ok {
				health_checksList = append(health_checksList, ClusterHealthChecksModel{
					Kind: func() types.String {
						if v, ok := itemMap["kind"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
					Name: func() types.String {
						if v, ok := itemMap["name"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
					Namespace: func() types.String {
						if v, ok := itemMap["namespace"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
					Tenant: func() types.String {
						if v, ok := itemMap["tenant"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
					Uid: func() types.String {
						if v, ok := itemMap["uid"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
				})
			}
		}
		data.HealthChecks = health_checksList
	}
	if _, ok := apiResource.Spec["http1_config"].(map[string]interface{}); ok && isImport && data.Http1Config == nil {
		// Import case: populate from API since state is nil and psd is empty
		data.Http1Config = &ClusterHttp1ConfigModel{}
	}
	// Normal Read: preserve existing state value
	if blockData, ok := apiResource.Spec["http2_options"].(map[string]interface{}); ok && (isImport || data.Http2Options != nil) {
		data.Http2Options = &ClusterHttp2OptionsModel{
			Enabled: func() types.Bool {
				if !isImport && data.Http2Options != nil {
					// Normal Read: preserve existing state value to avoid API default drift
					return data.Http2Options.Enabled
				}
				// Import case: read from API
				if v, ok := blockData["enabled"].(bool); ok {
					return types.BoolValue(v)
				}
				return types.BoolNull()
			}(),
		}
	}
	if _, ok := apiResource.Spec["no_panic_threshold"].(map[string]interface{}); ok && isImport && data.NoPanicThreshold == nil {
		// Import case: populate from API since state is nil and psd is empty
		data.NoPanicThreshold = &ClusterEmptyModel{}
	}
	// Normal Read: preserve existing state value
	if blockData, ok := apiResource.Spec["outlier_detection"].(map[string]interface{}); ok && (isImport || data.OutlierDetection != nil) {
		data.OutlierDetection = &ClusterOutlierDetectionModel{
			BaseEjectionTime: func() types.Int64 {
				if v, ok := blockData["base_ejection_time"].(float64); ok {
					return types.Int64Value(int64(v))
				}
				return types.Int64Null()
			}(),
			Consecutive5xx: func() types.Int64 {
				if v, ok := blockData["consecutive_5xx"].(float64); ok {
					return types.Int64Value(int64(v))
				}
				return types.Int64Null()
			}(),
			ConsecutiveGatewayFailure: func() types.Int64 {
				if v, ok := blockData["consecutive_gateway_failure"].(float64); ok {
					return types.Int64Value(int64(v))
				}
				return types.Int64Null()
			}(),
			Interval: func() types.Int64 {
				if v, ok := blockData["interval"].(float64); ok {
					return types.Int64Value(int64(v))
				}
				return types.Int64Null()
			}(),
			MaxEjectionPercent: func() types.Int64 {
				if v, ok := blockData["max_ejection_percent"].(float64); ok {
					return types.Int64Value(int64(v))
				}
				return types.Int64Null()
			}(),
		}
	}
	if _, ok := apiResource.Spec["proxy_protocol_v1"].(map[string]interface{}); ok && isImport && data.ProxyProtocolV1 == nil {
		// Import case: populate from API since state is nil and psd is empty
		data.ProxyProtocolV1 = &ClusterEmptyModel{}
	}
	// Normal Read: preserve existing state value
	if _, ok := apiResource.Spec["proxy_protocol_v2"].(map[string]interface{}); ok && isImport && data.ProxyProtocolV2 == nil {
		// Import case: populate from API since state is nil and psd is empty
		data.ProxyProtocolV2 = &ClusterEmptyModel{}
	}
	// Normal Read: preserve existing state value
	if blockData, ok := apiResource.Spec["tls_parameters"].(map[string]interface{}); ok && (isImport || data.TLSParameters != nil) {
		data.TLSParameters = &ClusterTLSParametersModel{
			CertParams: func() *ClusterTLSParametersCertParamsModel {
				if !isImport && data.TLSParameters != nil && data.TLSParameters.CertParams != nil {
					// Normal Read: preserve existing state value
					return data.TLSParameters.CertParams
				}
				// Import case: read from API
				if nestedBlockData, ok := blockData["cert_params"].(map[string]interface{}); ok {
					return &ClusterTLSParametersCertParamsModel{
						CipherSuites: func() types.List {
							if v, ok := nestedBlockData["cipher_suites"].([]interface{}); ok && len(v) > 0 {
								var items []string
								for _, item := range v {
									if s, ok := item.(string); ok {
										items = append(items, s)
									}
								}
								listVal, _ := types.ListValueFrom(ctx, types.StringType, items)
								return listVal
							}
							return types.ListNull(types.StringType)
						}(),
						MaximumProtocolVersion: func() types.String {
							if v, ok := nestedBlockData["maximum_protocol_version"].(string); ok && v != "" {
								return types.StringValue(v)
							}
							return types.StringNull()
						}(),
						MinimumProtocolVersion: func() types.String {
							if v, ok := nestedBlockData["minimum_protocol_version"].(string); ok && v != "" {
								return types.StringValue(v)
							}
							return types.StringNull()
						}(),
					}
				}
				return nil
			}(),
			CommonParams: func() *ClusterTLSParametersCommonParamsModel {
				if !isImport && data.TLSParameters != nil && data.TLSParameters.CommonParams != nil {
					// Normal Read: preserve existing state value
					return data.TLSParameters.CommonParams
				}
				// Import case: read from API
				if nestedBlockData, ok := blockData["common_params"].(map[string]interface{}); ok {
					return &ClusterTLSParametersCommonParamsModel{
						CipherSuites: func() types.List {
							if v, ok := nestedBlockData["cipher_suites"].([]interface{}); ok && len(v) > 0 {
								var items []string
								for _, item := range v {
									if s, ok := item.(string); ok {
										items = append(items, s)
									}
								}
								listVal, _ := types.ListValueFrom(ctx, types.StringType, items)
								return listVal
							}
							return types.ListNull(types.StringType)
						}(),
						MaximumProtocolVersion: func() types.String {
							if v, ok := nestedBlockData["maximum_protocol_version"].(string); ok && v != "" {
								return types.StringValue(v)
							}
							return types.StringNull()
						}(),
						MinimumProtocolVersion: func() types.String {
							if v, ok := nestedBlockData["minimum_protocol_version"].(string); ok && v != "" {
								return types.StringValue(v)
							}
							return types.StringNull()
						}(),
					}
				}
				return nil
			}(),
			DefaultSessionKeyCaching: func() *ClusterEmptyModel {
				if !isImport && data.TLSParameters != nil {
					// Normal Read: preserve existing state value (even if nil)
					// This prevents API returning empty objects from overwriting user's 'not configured' intent
					return data.TLSParameters.DefaultSessionKeyCaching
				}
				// Import case: read from API
				if _, ok := blockData["default_session_key_caching"].(map[string]interface{}); ok {
					return &ClusterEmptyModel{}
				}
				return nil
			}(),
			DisableSessionKeyCaching: func() *ClusterEmptyModel {
				if !isImport && data.TLSParameters != nil {
					// Normal Read: preserve existing state value (even if nil)
					// This prevents API returning empty objects from overwriting user's 'not configured' intent
					return data.TLSParameters.DisableSessionKeyCaching
				}
				// Import case: read from API
				if _, ok := blockData["disable_session_key_caching"].(map[string]interface{}); ok {
					return &ClusterEmptyModel{}
				}
				return nil
			}(),
			DisableSni: func() *ClusterEmptyModel {
				if !isImport && data.TLSParameters != nil {
					// Normal Read: preserve existing state value (even if nil)
					// This prevents API returning empty objects from overwriting user's 'not configured' intent
					return data.TLSParameters.DisableSni
				}
				// Import case: read from API
				if _, ok := blockData["disable_sni"].(map[string]interface{}); ok {
					return &ClusterEmptyModel{}
				}
				return nil
			}(),
			MaxSessionKeys: func() types.Int64 {
				if v, ok := blockData["max_session_keys"].(float64); ok {
					return types.Int64Value(int64(v))
				}
				return types.Int64Null()
			}(),
			Sni: func() types.String {
				if v, ok := blockData["sni"].(string); ok && v != "" {
					return types.StringValue(v)
				}
				return types.StringNull()
			}(),
			UseHostHeaderAsSni: func() *ClusterEmptyModel {
				if !isImport && data.TLSParameters != nil {
					// Normal Read: preserve existing state value (even if nil)
					// This prevents API returning empty objects from overwriting user's 'not configured' intent
					return data.TLSParameters.UseHostHeaderAsSni
				}
				// Import case: read from API
				if _, ok := blockData["use_host_header_as_sni"].(map[string]interface{}); ok {
					return &ClusterEmptyModel{}
				}
				return nil
			}(),
		}
	}
	if _, ok := apiResource.Spec["upstream_conn_pool_reuse_type"].(map[string]interface{}); ok && isImport && data.UpstreamConnPoolReuseType == nil {
		// Import case: populate from API since state is nil and psd is empty
		data.UpstreamConnPoolReuseType = &ClusterUpstreamConnPoolReuseTypeModel{}
	}
	// Normal Read: preserve existing state value
	if v, ok := apiResource.Spec["connection_timeout"].(float64); ok {
		data.ConnectionTimeout = types.Int64Value(int64(v))
	} else {
		data.ConnectionTimeout = types.Int64Null()
	}
	if v, ok := apiResource.Spec["endpoint_selection"].(string); ok && v != "" {
		data.EndpointSelection = types.StringValue(v)
	} else {
		data.EndpointSelection = types.StringNull()
	}
	if v, ok := apiResource.Spec["fallback_policy"].(string); ok && v != "" {
		data.FallbackPolicy = types.StringValue(v)
	} else {
		data.FallbackPolicy = types.StringNull()
	}
	if v, ok := apiResource.Spec["http_idle_timeout"].(float64); ok {
		data.HTTPIdleTimeout = types.Int64Value(int64(v))
	} else {
		data.HTTPIdleTimeout = types.Int64Null()
	}
	if v, ok := apiResource.Spec["loadbalancer_algorithm"].(string); ok && v != "" {
		data.LoadBalancerAlgorithm = types.StringValue(v)
	} else {
		data.LoadBalancerAlgorithm = types.StringNull()
	}
	if v, ok := apiResource.Spec["panic_threshold"].(float64); ok {
		data.PanicThreshold = types.Int64Value(int64(v))
	} else {
		data.PanicThreshold = types.Int64Null()
	}

	psd := privatestate.NewPrivateStateData()
	psd.SetCustom("managed", "true")
	tflog.Debug(ctx, "Create: saving private state with managed marker", map[string]interface{}{
		"name": apiResource.Metadata.Name,
	})
	resp.Diagnostics.Append(psd.SaveToPrivateState(ctx, resp)...)

	tflog.Trace(ctx, "created Cluster resource")
	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}

func (r *ClusterResource) Read(ctx context.Context, req resource.ReadRequest, resp *resource.ReadResponse) {
	var data ClusterResourceModel
	resp.Diagnostics.Append(req.State.Get(ctx, &data)...)
	if resp.Diagnostics.HasError() {
		return
	}

	readTimeout, diags := data.Timeouts.Read(ctx, inttimeouts.DefaultRead)
	resp.Diagnostics.Append(diags...)
	if resp.Diagnostics.HasError() {
		return
	}

	ctx, cancel := context.WithTimeout(ctx, readTimeout)
	defer cancel()

	psd, psDiags := privatestate.LoadFromPrivateState(ctx, &req)
	resp.Diagnostics.Append(psDiags...)

	apiResource, err := r.client.GetCluster(ctx, data.Namespace.ValueString(), data.Name.ValueString())
	if err != nil {
		// Check if the resource was deleted outside Terraform
		if strings.Contains(err.Error(), "NOT_FOUND") || strings.Contains(err.Error(), "404") {
			tflog.Warn(ctx, "Cluster not found, removing from state", map[string]interface{}{
				"name":      data.Name.ValueString(),
				"namespace": data.Namespace.ValueString(),
			})
			resp.State.RemoveResource(ctx)
			return
		}
		resp.Diagnostics.AddError("Client Error", fmt.Sprintf("Unable to read Cluster: %s", err))
		return
	}

	if psd != nil && psd.Metadata.UID != "" && apiResource.Metadata.UID != psd.Metadata.UID {
		resp.Diagnostics.AddWarning(
			"Resource Drift Detected",
			"The cluster may have been recreated outside of Terraform.",
		)
	}

	data.ID = types.StringValue(apiResource.Metadata.Name)
	data.Name = types.StringValue(apiResource.Metadata.Name)
	data.Namespace = types.StringValue(apiResource.Metadata.Namespace)

	// Read description from metadata
	if apiResource.Metadata.Description != "" {
		data.Description = types.StringValue(apiResource.Metadata.Description)
	} else {
		data.Description = types.StringNull()
	}

	if len(apiResource.Metadata.Labels) > 0 {
		labels, diags := types.MapValueFrom(ctx, types.StringType, apiResource.Metadata.Labels)
		resp.Diagnostics.Append(diags...)
		if !resp.Diagnostics.HasError() {
			data.Labels = labels
		}
	} else {
		data.Labels = types.MapNull(types.StringType)
	}

	if len(apiResource.Metadata.Annotations) > 0 {
		annotations, diags := types.MapValueFrom(ctx, types.StringType, apiResource.Metadata.Annotations)
		resp.Diagnostics.Append(diags...)
		if !resp.Diagnostics.HasError() {
			data.Annotations = annotations
		}
	} else {
		data.Annotations = types.MapNull(types.StringType)
	}

	// Unmarshal spec fields from API response to Terraform state
	// isImport is true when private state has no "managed" marker (Import case - never went through Create)
	isImport := psd == nil || psd.Metadata.Custom == nil || psd.Metadata.Custom["managed"] != "true"
	_ = isImport // May be unused if resource has no blocks needing import detection
	tflog.Debug(ctx, "Read: checking isImport status", map[string]interface{}{
		"isImport":   isImport,
		"psd_is_nil": psd == nil,
		"managed":    psd.Metadata.Custom["managed"],
	})
	if _, ok := apiResource.Spec["auto_http_config"].(map[string]interface{}); ok && isImport && data.AutoHTTPConfig == nil {
		// Import case: populate from API since state is nil and psd is empty
		data.AutoHTTPConfig = &ClusterEmptyModel{}
	}
	// Normal Read: preserve existing state value
	if blockData, ok := apiResource.Spec["circuit_breaker"].(map[string]interface{}); ok && (isImport || data.CircuitBreaker != nil) {
		data.CircuitBreaker = &ClusterCircuitBreakerModel{
			ConnectionLimit: func() types.Int64 {
				if v, ok := blockData["connection_limit"].(float64); ok {
					return types.Int64Value(int64(v))
				}
				return types.Int64Null()
			}(),
			MaxRequests: func() types.Int64 {
				if v, ok := blockData["max_requests"].(float64); ok {
					return types.Int64Value(int64(v))
				}
				return types.Int64Null()
			}(),
			PendingRequests: func() types.Int64 {
				if v, ok := blockData["pending_requests"].(float64); ok {
					return types.Int64Value(int64(v))
				}
				return types.Int64Null()
			}(),
			Priority: func() types.String {
				if v, ok := blockData["priority"].(string); ok && v != "" {
					return types.StringValue(v)
				}
				return types.StringNull()
			}(),
			Retries: func() types.Int64 {
				if v, ok := blockData["retries"].(float64); ok {
					return types.Int64Value(int64(v))
				}
				return types.Int64Null()
			}(),
		}
	}
	if _, ok := apiResource.Spec["default_subset"].(map[string]interface{}); ok && isImport && data.DefaultSubset == nil {
		// Import case: populate from API since state is nil and psd is empty
		data.DefaultSubset = &ClusterEmptyModel{}
	}
	// Normal Read: preserve existing state value
	if _, ok := apiResource.Spec["disable_proxy_protocol"].(map[string]interface{}); ok && isImport && data.DisableProxyProtocol == nil {
		// Import case: populate from API since state is nil and psd is empty
		data.DisableProxyProtocol = &ClusterEmptyModel{}
	}
	// Normal Read: preserve existing state value
	if listData, ok := apiResource.Spec["endpoint_subsets"].([]interface{}); ok && len(listData) > 0 {
		var endpoint_subsetsList []ClusterEndpointSubsetsModel
		for listIdx, item := range listData {
			_ = listIdx // May be unused if no empty marker blocks in list item
			if itemMap, ok := item.(map[string]interface{}); ok {
				endpoint_subsetsList = append(endpoint_subsetsList, ClusterEndpointSubsetsModel{
					Keys: func() types.List {
						if v, ok := itemMap["keys"].([]interface{}); ok && len(v) > 0 {
							var items []string
							for _, item := range v {
								if s, ok := item.(string); ok {
									items = append(items, s)
								}
							}
							listVal, _ := types.ListValueFrom(ctx, types.StringType, items)
							return listVal
						}
						return types.ListNull(types.StringType)
					}(),
				})
			}
		}
		data.EndpointSubsets = endpoint_subsetsList
	}
	if listData, ok := apiResource.Spec["endpoints"].([]interface{}); ok && len(listData) > 0 {
		var endpointsList []ClusterEndpointsModel
		for listIdx, item := range listData {
			_ = listIdx // May be unused if no empty marker blocks in list item
			if itemMap, ok := item.(map[string]interface{}); ok {
				endpointsList = append(endpointsList, ClusterEndpointsModel{
					Kind: func() types.String {
						if v, ok := itemMap["kind"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
					Name: func() types.String {
						if v, ok := itemMap["name"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
					Namespace: func() types.String {
						if v, ok := itemMap["namespace"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
					Tenant: func() types.String {
						if v, ok := itemMap["tenant"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
					Uid: func() types.String {
						if v, ok := itemMap["uid"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
				})
			}
		}
		data.Endpoints = endpointsList
	}
	if listData, ok := apiResource.Spec["health_checks"].([]interface{}); ok && len(listData) > 0 {
		var health_checksList []ClusterHealthChecksModel
		for listIdx, item := range listData {
			_ = listIdx // May be unused if no empty marker blocks in list item
			if itemMap, ok := item.(map[string]interface{}); ok {
				health_checksList = append(health_checksList, ClusterHealthChecksModel{
					Kind: func() types.String {
						if v, ok := itemMap["kind"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
					Name: func() types.String {
						if v, ok := itemMap["name"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
					Namespace: func() types.String {
						if v, ok := itemMap["namespace"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
					Tenant: func() types.String {
						if v, ok := itemMap["tenant"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
					Uid: func() types.String {
						if v, ok := itemMap["uid"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
				})
			}
		}
		data.HealthChecks = health_checksList
	}
	if _, ok := apiResource.Spec["http1_config"].(map[string]interface{}); ok && isImport && data.Http1Config == nil {
		// Import case: populate from API since state is nil and psd is empty
		data.Http1Config = &ClusterHttp1ConfigModel{}
	}
	// Normal Read: preserve existing state value
	if blockData, ok := apiResource.Spec["http2_options"].(map[string]interface{}); ok && (isImport || data.Http2Options != nil) {
		data.Http2Options = &ClusterHttp2OptionsModel{
			Enabled: func() types.Bool {
				if !isImport && data.Http2Options != nil {
					// Normal Read: preserve existing state value to avoid API default drift
					return data.Http2Options.Enabled
				}
				// Import case: read from API
				if v, ok := blockData["enabled"].(bool); ok {
					return types.BoolValue(v)
				}
				return types.BoolNull()
			}(),
		}
	}
	if _, ok := apiResource.Spec["no_panic_threshold"].(map[string]interface{}); ok && isImport && data.NoPanicThreshold == nil {
		// Import case: populate from API since state is nil and psd is empty
		data.NoPanicThreshold = &ClusterEmptyModel{}
	}
	// Normal Read: preserve existing state value
	if blockData, ok := apiResource.Spec["outlier_detection"].(map[string]interface{}); ok && (isImport || data.OutlierDetection != nil) {
		data.OutlierDetection = &ClusterOutlierDetectionModel{
			BaseEjectionTime: func() types.Int64 {
				if v, ok := blockData["base_ejection_time"].(float64); ok {
					return types.Int64Value(int64(v))
				}
				return types.Int64Null()
			}(),
			Consecutive5xx: func() types.Int64 {
				if v, ok := blockData["consecutive_5xx"].(float64); ok {
					return types.Int64Value(int64(v))
				}
				return types.Int64Null()
			}(),
			ConsecutiveGatewayFailure: func() types.Int64 {
				if v, ok := blockData["consecutive_gateway_failure"].(float64); ok {
					return types.Int64Value(int64(v))
				}
				return types.Int64Null()
			}(),
			Interval: func() types.Int64 {
				if v, ok := blockData["interval"].(float64); ok {
					return types.Int64Value(int64(v))
				}
				return types.Int64Null()
			}(),
			MaxEjectionPercent: func() types.Int64 {
				if v, ok := blockData["max_ejection_percent"].(float64); ok {
					return types.Int64Value(int64(v))
				}
				return types.Int64Null()
			}(),
		}
	}
	if _, ok := apiResource.Spec["proxy_protocol_v1"].(map[string]interface{}); ok && isImport && data.ProxyProtocolV1 == nil {
		// Import case: populate from API since state is nil and psd is empty
		data.ProxyProtocolV1 = &ClusterEmptyModel{}
	}
	// Normal Read: preserve existing state value
	if _, ok := apiResource.Spec["proxy_protocol_v2"].(map[string]interface{}); ok && isImport && data.ProxyProtocolV2 == nil {
		// Import case: populate from API since state is nil and psd is empty
		data.ProxyProtocolV2 = &ClusterEmptyModel{}
	}
	// Normal Read: preserve existing state value
	if blockData, ok := apiResource.Spec["tls_parameters"].(map[string]interface{}); ok && (isImport || data.TLSParameters != nil) {
		data.TLSParameters = &ClusterTLSParametersModel{
			CertParams: func() *ClusterTLSParametersCertParamsModel {
				if !isImport && data.TLSParameters != nil && data.TLSParameters.CertParams != nil {
					// Normal Read: preserve existing state value
					return data.TLSParameters.CertParams
				}
				// Import case: read from API
				if nestedBlockData, ok := blockData["cert_params"].(map[string]interface{}); ok {
					return &ClusterTLSParametersCertParamsModel{
						CipherSuites: func() types.List {
							if v, ok := nestedBlockData["cipher_suites"].([]interface{}); ok && len(v) > 0 {
								var items []string
								for _, item := range v {
									if s, ok := item.(string); ok {
										items = append(items, s)
									}
								}
								listVal, _ := types.ListValueFrom(ctx, types.StringType, items)
								return listVal
							}
							return types.ListNull(types.StringType)
						}(),
						MaximumProtocolVersion: func() types.String {
							if v, ok := nestedBlockData["maximum_protocol_version"].(string); ok && v != "" {
								return types.StringValue(v)
							}
							return types.StringNull()
						}(),
						MinimumProtocolVersion: func() types.String {
							if v, ok := nestedBlockData["minimum_protocol_version"].(string); ok && v != "" {
								return types.StringValue(v)
							}
							return types.StringNull()
						}(),
					}
				}
				return nil
			}(),
			CommonParams: func() *ClusterTLSParametersCommonParamsModel {
				if !isImport && data.TLSParameters != nil && data.TLSParameters.CommonParams != nil {
					// Normal Read: preserve existing state value
					return data.TLSParameters.CommonParams
				}
				// Import case: read from API
				if nestedBlockData, ok := blockData["common_params"].(map[string]interface{}); ok {
					return &ClusterTLSParametersCommonParamsModel{
						CipherSuites: func() types.List {
							if v, ok := nestedBlockData["cipher_suites"].([]interface{}); ok && len(v) > 0 {
								var items []string
								for _, item := range v {
									if s, ok := item.(string); ok {
										items = append(items, s)
									}
								}
								listVal, _ := types.ListValueFrom(ctx, types.StringType, items)
								return listVal
							}
							return types.ListNull(types.StringType)
						}(),
						MaximumProtocolVersion: func() types.String {
							if v, ok := nestedBlockData["maximum_protocol_version"].(string); ok && v != "" {
								return types.StringValue(v)
							}
							return types.StringNull()
						}(),
						MinimumProtocolVersion: func() types.String {
							if v, ok := nestedBlockData["minimum_protocol_version"].(string); ok && v != "" {
								return types.StringValue(v)
							}
							return types.StringNull()
						}(),
					}
				}
				return nil
			}(),
			DefaultSessionKeyCaching: func() *ClusterEmptyModel {
				if !isImport && data.TLSParameters != nil {
					// Normal Read: preserve existing state value (even if nil)
					// This prevents API returning empty objects from overwriting user's 'not configured' intent
					return data.TLSParameters.DefaultSessionKeyCaching
				}
				// Import case: read from API
				if _, ok := blockData["default_session_key_caching"].(map[string]interface{}); ok {
					return &ClusterEmptyModel{}
				}
				return nil
			}(),
			DisableSessionKeyCaching: func() *ClusterEmptyModel {
				if !isImport && data.TLSParameters != nil {
					// Normal Read: preserve existing state value (even if nil)
					// This prevents API returning empty objects from overwriting user's 'not configured' intent
					return data.TLSParameters.DisableSessionKeyCaching
				}
				// Import case: read from API
				if _, ok := blockData["disable_session_key_caching"].(map[string]interface{}); ok {
					return &ClusterEmptyModel{}
				}
				return nil
			}(),
			DisableSni: func() *ClusterEmptyModel {
				if !isImport && data.TLSParameters != nil {
					// Normal Read: preserve existing state value (even if nil)
					// This prevents API returning empty objects from overwriting user's 'not configured' intent
					return data.TLSParameters.DisableSni
				}
				// Import case: read from API
				if _, ok := blockData["disable_sni"].(map[string]interface{}); ok {
					return &ClusterEmptyModel{}
				}
				return nil
			}(),
			MaxSessionKeys: func() types.Int64 {
				if v, ok := blockData["max_session_keys"].(float64); ok {
					return types.Int64Value(int64(v))
				}
				return types.Int64Null()
			}(),
			Sni: func() types.String {
				if v, ok := blockData["sni"].(string); ok && v != "" {
					return types.StringValue(v)
				}
				return types.StringNull()
			}(),
			UseHostHeaderAsSni: func() *ClusterEmptyModel {
				if !isImport && data.TLSParameters != nil {
					// Normal Read: preserve existing state value (even if nil)
					// This prevents API returning empty objects from overwriting user's 'not configured' intent
					return data.TLSParameters.UseHostHeaderAsSni
				}
				// Import case: read from API
				if _, ok := blockData["use_host_header_as_sni"].(map[string]interface{}); ok {
					return &ClusterEmptyModel{}
				}
				return nil
			}(),
		}
	}
	if _, ok := apiResource.Spec["upstream_conn_pool_reuse_type"].(map[string]interface{}); ok && isImport && data.UpstreamConnPoolReuseType == nil {
		// Import case: populate from API since state is nil and psd is empty
		data.UpstreamConnPoolReuseType = &ClusterUpstreamConnPoolReuseTypeModel{}
	}
	// Normal Read: preserve existing state value
	if v, ok := apiResource.Spec["connection_timeout"].(float64); ok {
		data.ConnectionTimeout = types.Int64Value(int64(v))
	} else {
		data.ConnectionTimeout = types.Int64Null()
	}
	if v, ok := apiResource.Spec["endpoint_selection"].(string); ok && v != "" {
		data.EndpointSelection = types.StringValue(v)
	} else {
		data.EndpointSelection = types.StringNull()
	}
	if v, ok := apiResource.Spec["fallback_policy"].(string); ok && v != "" {
		data.FallbackPolicy = types.StringValue(v)
	} else {
		data.FallbackPolicy = types.StringNull()
	}
	if v, ok := apiResource.Spec["http_idle_timeout"].(float64); ok {
		data.HTTPIdleTimeout = types.Int64Value(int64(v))
	} else {
		data.HTTPIdleTimeout = types.Int64Null()
	}
	if v, ok := apiResource.Spec["loadbalancer_algorithm"].(string); ok && v != "" {
		data.LoadBalancerAlgorithm = types.StringValue(v)
	} else {
		data.LoadBalancerAlgorithm = types.StringNull()
	}
	if v, ok := apiResource.Spec["panic_threshold"].(float64); ok {
		data.PanicThreshold = types.Int64Value(int64(v))
	} else {
		data.PanicThreshold = types.Int64Null()
	}

	// Preserve or set the managed marker for future Read operations
	newPsd := privatestate.NewPrivateStateData()
	newPsd.SetUID(apiResource.Metadata.UID)
	if !isImport {
		// Preserve the managed marker if we already had it
		newPsd.SetCustom("managed", "true")
	}
	resp.Diagnostics.Append(newPsd.SaveToPrivateState(ctx, resp)...)

	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}

func (r *ClusterResource) Update(ctx context.Context, req resource.UpdateRequest, resp *resource.UpdateResponse) {
	var data ClusterResourceModel
	resp.Diagnostics.Append(req.Plan.Get(ctx, &data)...)
	if resp.Diagnostics.HasError() {
		return
	}

	updateTimeout, diags := data.Timeouts.Update(ctx, inttimeouts.DefaultUpdate)
	resp.Diagnostics.Append(diags...)
	if resp.Diagnostics.HasError() {
		return
	}

	ctx, cancel := context.WithTimeout(ctx, updateTimeout)
	defer cancel()

	apiResource := &client.Cluster{
		Metadata: client.Metadata{
			Name:      data.Name.ValueString(),
			Namespace: data.Namespace.ValueString(),
		},
		Spec: make(map[string]interface{}),
	}

	if !data.Description.IsNull() {
		apiResource.Metadata.Description = data.Description.ValueString()
	}

	if !data.Labels.IsNull() {
		labels := make(map[string]string)
		resp.Diagnostics.Append(data.Labels.ElementsAs(ctx, &labels, false)...)
		if resp.Diagnostics.HasError() {
			return
		}
		apiResource.Metadata.Labels = labels
	}

	if !data.Annotations.IsNull() {
		annotations := make(map[string]string)
		resp.Diagnostics.Append(data.Annotations.ElementsAs(ctx, &annotations, false)...)
		if resp.Diagnostics.HasError() {
			return
		}
		apiResource.Metadata.Annotations = annotations
	}

	// Marshal spec fields from Terraform state to API struct
	if data.AutoHTTPConfig != nil {
		auto_http_configMap := make(map[string]interface{})
		apiResource.Spec["auto_http_config"] = auto_http_configMap
	}
	if data.CircuitBreaker != nil {
		circuit_breakerMap := make(map[string]interface{})
		if !data.CircuitBreaker.ConnectionLimit.IsNull() && !data.CircuitBreaker.ConnectionLimit.IsUnknown() {
			circuit_breakerMap["connection_limit"] = data.CircuitBreaker.ConnectionLimit.ValueInt64()
		}
		if !data.CircuitBreaker.MaxRequests.IsNull() && !data.CircuitBreaker.MaxRequests.IsUnknown() {
			circuit_breakerMap["max_requests"] = data.CircuitBreaker.MaxRequests.ValueInt64()
		}
		if !data.CircuitBreaker.PendingRequests.IsNull() && !data.CircuitBreaker.PendingRequests.IsUnknown() {
			circuit_breakerMap["pending_requests"] = data.CircuitBreaker.PendingRequests.ValueInt64()
		}
		if !data.CircuitBreaker.Priority.IsNull() && !data.CircuitBreaker.Priority.IsUnknown() {
			circuit_breakerMap["priority"] = data.CircuitBreaker.Priority.ValueString()
		}
		if !data.CircuitBreaker.Retries.IsNull() && !data.CircuitBreaker.Retries.IsUnknown() {
			circuit_breakerMap["retries"] = data.CircuitBreaker.Retries.ValueInt64()
		}
		apiResource.Spec["circuit_breaker"] = circuit_breakerMap
	}
	if data.DefaultSubset != nil {
		default_subsetMap := make(map[string]interface{})
		apiResource.Spec["default_subset"] = default_subsetMap
	}
	if data.DisableProxyProtocol != nil {
		disable_proxy_protocolMap := make(map[string]interface{})
		apiResource.Spec["disable_proxy_protocol"] = disable_proxy_protocolMap
	}
	if len(data.EndpointSubsets) > 0 {
		var endpoint_subsetsList []map[string]interface{}
		for range data.EndpointSubsets {
			itemMap := make(map[string]interface{})
			endpoint_subsetsList = append(endpoint_subsetsList, itemMap)
		}
		apiResource.Spec["endpoint_subsets"] = endpoint_subsetsList
	}
	if len(data.Endpoints) > 0 {
		var endpointsList []map[string]interface{}
		for _, item := range data.Endpoints {
			itemMap := make(map[string]interface{})
			if !item.Kind.IsNull() && !item.Kind.IsUnknown() {
				itemMap["kind"] = item.Kind.ValueString()
			}
			if !item.Name.IsNull() && !item.Name.IsUnknown() {
				itemMap["name"] = item.Name.ValueString()
			}
			if !item.Namespace.IsNull() && !item.Namespace.IsUnknown() {
				itemMap["namespace"] = item.Namespace.ValueString()
			}
			if !item.Tenant.IsNull() && !item.Tenant.IsUnknown() {
				itemMap["tenant"] = item.Tenant.ValueString()
			}
			if !item.Uid.IsNull() && !item.Uid.IsUnknown() {
				itemMap["uid"] = item.Uid.ValueString()
			}
			endpointsList = append(endpointsList, itemMap)
		}
		apiResource.Spec["endpoints"] = endpointsList
	}
	if len(data.HealthChecks) > 0 {
		var health_checksList []map[string]interface{}
		for _, item := range data.HealthChecks {
			itemMap := make(map[string]interface{})
			if !item.Kind.IsNull() && !item.Kind.IsUnknown() {
				itemMap["kind"] = item.Kind.ValueString()
			}
			if !item.Name.IsNull() && !item.Name.IsUnknown() {
				itemMap["name"] = item.Name.ValueString()
			}
			if !item.Namespace.IsNull() && !item.Namespace.IsUnknown() {
				itemMap["namespace"] = item.Namespace.ValueString()
			}
			if !item.Tenant.IsNull() && !item.Tenant.IsUnknown() {
				itemMap["tenant"] = item.Tenant.ValueString()
			}
			if !item.Uid.IsNull() && !item.Uid.IsUnknown() {
				itemMap["uid"] = item.Uid.ValueString()
			}
			health_checksList = append(health_checksList, itemMap)
		}
		apiResource.Spec["health_checks"] = health_checksList
	}
	if data.Http1Config != nil {
		http1_configMap := make(map[string]interface{})
		if data.Http1Config.HeaderTransformation != nil {
			header_transformationNestedMap := make(map[string]interface{})
			http1_configMap["header_transformation"] = header_transformationNestedMap
		}
		apiResource.Spec["http1_config"] = http1_configMap
	}
	if data.Http2Options != nil {
		http2_optionsMap := make(map[string]interface{})
		if !data.Http2Options.Enabled.IsNull() && !data.Http2Options.Enabled.IsUnknown() {
			http2_optionsMap["enabled"] = data.Http2Options.Enabled.ValueBool()
		}
		apiResource.Spec["http2_options"] = http2_optionsMap
	}
	if data.NoPanicThreshold != nil {
		no_panic_thresholdMap := make(map[string]interface{})
		apiResource.Spec["no_panic_threshold"] = no_panic_thresholdMap
	}
	if data.OutlierDetection != nil {
		outlier_detectionMap := make(map[string]interface{})
		if !data.OutlierDetection.BaseEjectionTime.IsNull() && !data.OutlierDetection.BaseEjectionTime.IsUnknown() {
			outlier_detectionMap["base_ejection_time"] = data.OutlierDetection.BaseEjectionTime.ValueInt64()
		}
		if !data.OutlierDetection.Consecutive5xx.IsNull() && !data.OutlierDetection.Consecutive5xx.IsUnknown() {
			outlier_detectionMap["consecutive_5xx"] = data.OutlierDetection.Consecutive5xx.ValueInt64()
		}
		if !data.OutlierDetection.ConsecutiveGatewayFailure.IsNull() && !data.OutlierDetection.ConsecutiveGatewayFailure.IsUnknown() {
			outlier_detectionMap["consecutive_gateway_failure"] = data.OutlierDetection.ConsecutiveGatewayFailure.ValueInt64()
		}
		if !data.OutlierDetection.Interval.IsNull() && !data.OutlierDetection.Interval.IsUnknown() {
			outlier_detectionMap["interval"] = data.OutlierDetection.Interval.ValueInt64()
		}
		if !data.OutlierDetection.MaxEjectionPercent.IsNull() && !data.OutlierDetection.MaxEjectionPercent.IsUnknown() {
			outlier_detectionMap["max_ejection_percent"] = data.OutlierDetection.MaxEjectionPercent.ValueInt64()
		}
		apiResource.Spec["outlier_detection"] = outlier_detectionMap
	}
	if data.ProxyProtocolV1 != nil {
		proxy_protocol_v1Map := make(map[string]interface{})
		apiResource.Spec["proxy_protocol_v1"] = proxy_protocol_v1Map
	}
	if data.ProxyProtocolV2 != nil {
		proxy_protocol_v2Map := make(map[string]interface{})
		apiResource.Spec["proxy_protocol_v2"] = proxy_protocol_v2Map
	}
	if data.TLSParameters != nil {
		tls_parametersMap := make(map[string]interface{})
		if data.TLSParameters.CertParams != nil {
			cert_paramsNestedMap := make(map[string]interface{})
			if !data.TLSParameters.CertParams.MaximumProtocolVersion.IsNull() && !data.TLSParameters.CertParams.MaximumProtocolVersion.IsUnknown() {
				cert_paramsNestedMap["maximum_protocol_version"] = data.TLSParameters.CertParams.MaximumProtocolVersion.ValueString()
			}
			if !data.TLSParameters.CertParams.MinimumProtocolVersion.IsNull() && !data.TLSParameters.CertParams.MinimumProtocolVersion.IsUnknown() {
				cert_paramsNestedMap["minimum_protocol_version"] = data.TLSParameters.CertParams.MinimumProtocolVersion.ValueString()
			}
			tls_parametersMap["cert_params"] = cert_paramsNestedMap
		}
		if data.TLSParameters.CommonParams != nil {
			common_paramsNestedMap := make(map[string]interface{})
			if !data.TLSParameters.CommonParams.MaximumProtocolVersion.IsNull() && !data.TLSParameters.CommonParams.MaximumProtocolVersion.IsUnknown() {
				common_paramsNestedMap["maximum_protocol_version"] = data.TLSParameters.CommonParams.MaximumProtocolVersion.ValueString()
			}
			if !data.TLSParameters.CommonParams.MinimumProtocolVersion.IsNull() && !data.TLSParameters.CommonParams.MinimumProtocolVersion.IsUnknown() {
				common_paramsNestedMap["minimum_protocol_version"] = data.TLSParameters.CommonParams.MinimumProtocolVersion.ValueString()
			}
			tls_parametersMap["common_params"] = common_paramsNestedMap
		}
		if data.TLSParameters.DefaultSessionKeyCaching != nil {
			tls_parametersMap["default_session_key_caching"] = map[string]interface{}{}
		}
		if data.TLSParameters.DisableSessionKeyCaching != nil {
			tls_parametersMap["disable_session_key_caching"] = map[string]interface{}{}
		}
		if data.TLSParameters.DisableSni != nil {
			tls_parametersMap["disable_sni"] = map[string]interface{}{}
		}
		if !data.TLSParameters.MaxSessionKeys.IsNull() && !data.TLSParameters.MaxSessionKeys.IsUnknown() {
			tls_parametersMap["max_session_keys"] = data.TLSParameters.MaxSessionKeys.ValueInt64()
		}
		if !data.TLSParameters.Sni.IsNull() && !data.TLSParameters.Sni.IsUnknown() {
			tls_parametersMap["sni"] = data.TLSParameters.Sni.ValueString()
		}
		if data.TLSParameters.UseHostHeaderAsSni != nil {
			tls_parametersMap["use_host_header_as_sni"] = map[string]interface{}{}
		}
		apiResource.Spec["tls_parameters"] = tls_parametersMap
	}
	if data.UpstreamConnPoolReuseType != nil {
		upstream_conn_pool_reuse_typeMap := make(map[string]interface{})
		if data.UpstreamConnPoolReuseType.DisableConnPoolReuse != nil {
			upstream_conn_pool_reuse_typeMap["disable_conn_pool_reuse"] = map[string]interface{}{}
		}
		if data.UpstreamConnPoolReuseType.EnableConnPoolReuse != nil {
			upstream_conn_pool_reuse_typeMap["enable_conn_pool_reuse"] = map[string]interface{}{}
		}
		apiResource.Spec["upstream_conn_pool_reuse_type"] = upstream_conn_pool_reuse_typeMap
	}
	if !data.ConnectionTimeout.IsNull() && !data.ConnectionTimeout.IsUnknown() {
		apiResource.Spec["connection_timeout"] = data.ConnectionTimeout.ValueInt64()
	}
	if !data.EndpointSelection.IsNull() && !data.EndpointSelection.IsUnknown() {
		apiResource.Spec["endpoint_selection"] = data.EndpointSelection.ValueString()
	}
	if !data.FallbackPolicy.IsNull() && !data.FallbackPolicy.IsUnknown() {
		apiResource.Spec["fallback_policy"] = data.FallbackPolicy.ValueString()
	}
	if !data.HTTPIdleTimeout.IsNull() && !data.HTTPIdleTimeout.IsUnknown() {
		apiResource.Spec["http_idle_timeout"] = data.HTTPIdleTimeout.ValueInt64()
	}
	if !data.LoadBalancerAlgorithm.IsNull() && !data.LoadBalancerAlgorithm.IsUnknown() {
		apiResource.Spec["loadbalancer_algorithm"] = data.LoadBalancerAlgorithm.ValueString()
	}
	if !data.PanicThreshold.IsNull() && !data.PanicThreshold.IsUnknown() {
		apiResource.Spec["panic_threshold"] = data.PanicThreshold.ValueInt64()
	}

	_, err := r.client.UpdateCluster(ctx, apiResource)
	if err != nil {
		resp.Diagnostics.AddError("Client Error", fmt.Sprintf("Unable to update Cluster: %s", err))
		return
	}

	// Use plan data for ID since API response may not include metadata.name
	data.ID = types.StringValue(data.Name.ValueString())

	// Fetch the resource to get complete state including computed fields
	// PUT responses may not include all computed nested fields (like tenant in Object Reference blocks)
	fetched, fetchErr := r.client.GetCluster(ctx, data.Namespace.ValueString(), data.Name.ValueString())
	if fetchErr != nil {
		resp.Diagnostics.AddError("Client Error", fmt.Sprintf("Unable to read Cluster after update: %s", fetchErr))
		return
	}

	// Set computed fields from API response
	if v, ok := fetched.Spec["connection_timeout"].(float64); ok {
		data.ConnectionTimeout = types.Int64Value(int64(v))
	} else if data.ConnectionTimeout.IsUnknown() {
		// API didn't return value and plan was unknown - set to null
		data.ConnectionTimeout = types.Int64Null()
	}
	// If plan had a value, preserve it
	if v, ok := fetched.Spec["endpoint_selection"].(string); ok && v != "" {
		data.EndpointSelection = types.StringValue(v)
	} else if data.EndpointSelection.IsUnknown() {
		// API didn't return value and plan was unknown - set to null
		data.EndpointSelection = types.StringNull()
	}
	// If plan had a value, preserve it
	if v, ok := fetched.Spec["fallback_policy"].(string); ok && v != "" {
		data.FallbackPolicy = types.StringValue(v)
	} else if data.FallbackPolicy.IsUnknown() {
		// API didn't return value and plan was unknown - set to null
		data.FallbackPolicy = types.StringNull()
	}
	// If plan had a value, preserve it
	if v, ok := fetched.Spec["http_idle_timeout"].(float64); ok {
		data.HTTPIdleTimeout = types.Int64Value(int64(v))
	} else if data.HTTPIdleTimeout.IsUnknown() {
		// API didn't return value and plan was unknown - set to null
		data.HTTPIdleTimeout = types.Int64Null()
	}
	// If plan had a value, preserve it
	if v, ok := fetched.Spec["loadbalancer_algorithm"].(string); ok && v != "" {
		data.LoadBalancerAlgorithm = types.StringValue(v)
	} else if data.LoadBalancerAlgorithm.IsUnknown() {
		// API didn't return value and plan was unknown - set to null
		data.LoadBalancerAlgorithm = types.StringNull()
	}
	// If plan had a value, preserve it
	if v, ok := fetched.Spec["panic_threshold"].(float64); ok {
		data.PanicThreshold = types.Int64Value(int64(v))
	} else if data.PanicThreshold.IsUnknown() {
		// API didn't return value and plan was unknown - set to null
		data.PanicThreshold = types.Int64Null()
	}
	// If plan had a value, preserve it

	// Unmarshal spec fields from fetched resource to Terraform state
	apiResource = fetched // Use GET response which includes all computed fields
	isImport := false     // Update is never an import
	_ = isImport          // May be unused if resource has no blocks needing import detection
	if _, ok := apiResource.Spec["auto_http_config"].(map[string]interface{}); ok && isImport && data.AutoHTTPConfig == nil {
		// Import case: populate from API since state is nil and psd is empty
		data.AutoHTTPConfig = &ClusterEmptyModel{}
	}
	// Normal Read: preserve existing state value
	if blockData, ok := apiResource.Spec["circuit_breaker"].(map[string]interface{}); ok && (isImport || data.CircuitBreaker != nil) {
		data.CircuitBreaker = &ClusterCircuitBreakerModel{
			ConnectionLimit: func() types.Int64 {
				if v, ok := blockData["connection_limit"].(float64); ok {
					return types.Int64Value(int64(v))
				}
				return types.Int64Null()
			}(),
			MaxRequests: func() types.Int64 {
				if v, ok := blockData["max_requests"].(float64); ok {
					return types.Int64Value(int64(v))
				}
				return types.Int64Null()
			}(),
			PendingRequests: func() types.Int64 {
				if v, ok := blockData["pending_requests"].(float64); ok {
					return types.Int64Value(int64(v))
				}
				return types.Int64Null()
			}(),
			Priority: func() types.String {
				if v, ok := blockData["priority"].(string); ok && v != "" {
					return types.StringValue(v)
				}
				return types.StringNull()
			}(),
			Retries: func() types.Int64 {
				if v, ok := blockData["retries"].(float64); ok {
					return types.Int64Value(int64(v))
				}
				return types.Int64Null()
			}(),
		}
	}
	if _, ok := apiResource.Spec["default_subset"].(map[string]interface{}); ok && isImport && data.DefaultSubset == nil {
		// Import case: populate from API since state is nil and psd is empty
		data.DefaultSubset = &ClusterEmptyModel{}
	}
	// Normal Read: preserve existing state value
	if _, ok := apiResource.Spec["disable_proxy_protocol"].(map[string]interface{}); ok && isImport && data.DisableProxyProtocol == nil {
		// Import case: populate from API since state is nil and psd is empty
		data.DisableProxyProtocol = &ClusterEmptyModel{}
	}
	// Normal Read: preserve existing state value
	if listData, ok := apiResource.Spec["endpoint_subsets"].([]interface{}); ok && len(listData) > 0 {
		var endpoint_subsetsList []ClusterEndpointSubsetsModel
		for listIdx, item := range listData {
			_ = listIdx // May be unused if no empty marker blocks in list item
			if itemMap, ok := item.(map[string]interface{}); ok {
				endpoint_subsetsList = append(endpoint_subsetsList, ClusterEndpointSubsetsModel{
					Keys: func() types.List {
						if v, ok := itemMap["keys"].([]interface{}); ok && len(v) > 0 {
							var items []string
							for _, item := range v {
								if s, ok := item.(string); ok {
									items = append(items, s)
								}
							}
							listVal, _ := types.ListValueFrom(ctx, types.StringType, items)
							return listVal
						}
						return types.ListNull(types.StringType)
					}(),
				})
			}
		}
		data.EndpointSubsets = endpoint_subsetsList
	}
	if listData, ok := apiResource.Spec["endpoints"].([]interface{}); ok && len(listData) > 0 {
		var endpointsList []ClusterEndpointsModel
		for listIdx, item := range listData {
			_ = listIdx // May be unused if no empty marker blocks in list item
			if itemMap, ok := item.(map[string]interface{}); ok {
				endpointsList = append(endpointsList, ClusterEndpointsModel{
					Kind: func() types.String {
						if v, ok := itemMap["kind"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
					Name: func() types.String {
						if v, ok := itemMap["name"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
					Namespace: func() types.String {
						if v, ok := itemMap["namespace"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
					Tenant: func() types.String {
						if v, ok := itemMap["tenant"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
					Uid: func() types.String {
						if v, ok := itemMap["uid"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
				})
			}
		}
		data.Endpoints = endpointsList
	}
	if listData, ok := apiResource.Spec["health_checks"].([]interface{}); ok && len(listData) > 0 {
		var health_checksList []ClusterHealthChecksModel
		for listIdx, item := range listData {
			_ = listIdx // May be unused if no empty marker blocks in list item
			if itemMap, ok := item.(map[string]interface{}); ok {
				health_checksList = append(health_checksList, ClusterHealthChecksModel{
					Kind: func() types.String {
						if v, ok := itemMap["kind"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
					Name: func() types.String {
						if v, ok := itemMap["name"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
					Namespace: func() types.String {
						if v, ok := itemMap["namespace"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
					Tenant: func() types.String {
						if v, ok := itemMap["tenant"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
					Uid: func() types.String {
						if v, ok := itemMap["uid"].(string); ok && v != "" {
							return types.StringValue(v)
						}
						return types.StringNull()
					}(),
				})
			}
		}
		data.HealthChecks = health_checksList
	}
	if _, ok := apiResource.Spec["http1_config"].(map[string]interface{}); ok && isImport && data.Http1Config == nil {
		// Import case: populate from API since state is nil and psd is empty
		data.Http1Config = &ClusterHttp1ConfigModel{}
	}
	// Normal Read: preserve existing state value
	if blockData, ok := apiResource.Spec["http2_options"].(map[string]interface{}); ok && (isImport || data.Http2Options != nil) {
		data.Http2Options = &ClusterHttp2OptionsModel{
			Enabled: func() types.Bool {
				if !isImport && data.Http2Options != nil {
					// Normal Read: preserve existing state value to avoid API default drift
					return data.Http2Options.Enabled
				}
				// Import case: read from API
				if v, ok := blockData["enabled"].(bool); ok {
					return types.BoolValue(v)
				}
				return types.BoolNull()
			}(),
		}
	}
	if _, ok := apiResource.Spec["no_panic_threshold"].(map[string]interface{}); ok && isImport && data.NoPanicThreshold == nil {
		// Import case: populate from API since state is nil and psd is empty
		data.NoPanicThreshold = &ClusterEmptyModel{}
	}
	// Normal Read: preserve existing state value
	if blockData, ok := apiResource.Spec["outlier_detection"].(map[string]interface{}); ok && (isImport || data.OutlierDetection != nil) {
		data.OutlierDetection = &ClusterOutlierDetectionModel{
			BaseEjectionTime: func() types.Int64 {
				if v, ok := blockData["base_ejection_time"].(float64); ok {
					return types.Int64Value(int64(v))
				}
				return types.Int64Null()
			}(),
			Consecutive5xx: func() types.Int64 {
				if v, ok := blockData["consecutive_5xx"].(float64); ok {
					return types.Int64Value(int64(v))
				}
				return types.Int64Null()
			}(),
			ConsecutiveGatewayFailure: func() types.Int64 {
				if v, ok := blockData["consecutive_gateway_failure"].(float64); ok {
					return types.Int64Value(int64(v))
				}
				return types.Int64Null()
			}(),
			Interval: func() types.Int64 {
				if v, ok := blockData["interval"].(float64); ok {
					return types.Int64Value(int64(v))
				}
				return types.Int64Null()
			}(),
			MaxEjectionPercent: func() types.Int64 {
				if v, ok := blockData["max_ejection_percent"].(float64); ok {
					return types.Int64Value(int64(v))
				}
				return types.Int64Null()
			}(),
		}
	}
	if _, ok := apiResource.Spec["proxy_protocol_v1"].(map[string]interface{}); ok && isImport && data.ProxyProtocolV1 == nil {
		// Import case: populate from API since state is nil and psd is empty
		data.ProxyProtocolV1 = &ClusterEmptyModel{}
	}
	// Normal Read: preserve existing state value
	if _, ok := apiResource.Spec["proxy_protocol_v2"].(map[string]interface{}); ok && isImport && data.ProxyProtocolV2 == nil {
		// Import case: populate from API since state is nil and psd is empty
		data.ProxyProtocolV2 = &ClusterEmptyModel{}
	}
	// Normal Read: preserve existing state value
	if blockData, ok := apiResource.Spec["tls_parameters"].(map[string]interface{}); ok && (isImport || data.TLSParameters != nil) {
		data.TLSParameters = &ClusterTLSParametersModel{
			CertParams: func() *ClusterTLSParametersCertParamsModel {
				if !isImport && data.TLSParameters != nil && data.TLSParameters.CertParams != nil {
					// Normal Read: preserve existing state value
					return data.TLSParameters.CertParams
				}
				// Import case: read from API
				if nestedBlockData, ok := blockData["cert_params"].(map[string]interface{}); ok {
					return &ClusterTLSParametersCertParamsModel{
						CipherSuites: func() types.List {
							if v, ok := nestedBlockData["cipher_suites"].([]interface{}); ok && len(v) > 0 {
								var items []string
								for _, item := range v {
									if s, ok := item.(string); ok {
										items = append(items, s)
									}
								}
								listVal, _ := types.ListValueFrom(ctx, types.StringType, items)
								return listVal
							}
							return types.ListNull(types.StringType)
						}(),
						MaximumProtocolVersion: func() types.String {
							if v, ok := nestedBlockData["maximum_protocol_version"].(string); ok && v != "" {
								return types.StringValue(v)
							}
							return types.StringNull()
						}(),
						MinimumProtocolVersion: func() types.String {
							if v, ok := nestedBlockData["minimum_protocol_version"].(string); ok && v != "" {
								return types.StringValue(v)
							}
							return types.StringNull()
						}(),
					}
				}
				return nil
			}(),
			CommonParams: func() *ClusterTLSParametersCommonParamsModel {
				if !isImport && data.TLSParameters != nil && data.TLSParameters.CommonParams != nil {
					// Normal Read: preserve existing state value
					return data.TLSParameters.CommonParams
				}
				// Import case: read from API
				if nestedBlockData, ok := blockData["common_params"].(map[string]interface{}); ok {
					return &ClusterTLSParametersCommonParamsModel{
						CipherSuites: func() types.List {
							if v, ok := nestedBlockData["cipher_suites"].([]interface{}); ok && len(v) > 0 {
								var items []string
								for _, item := range v {
									if s, ok := item.(string); ok {
										items = append(items, s)
									}
								}
								listVal, _ := types.ListValueFrom(ctx, types.StringType, items)
								return listVal
							}
							return types.ListNull(types.StringType)
						}(),
						MaximumProtocolVersion: func() types.String {
							if v, ok := nestedBlockData["maximum_protocol_version"].(string); ok && v != "" {
								return types.StringValue(v)
							}
							return types.StringNull()
						}(),
						MinimumProtocolVersion: func() types.String {
							if v, ok := nestedBlockData["minimum_protocol_version"].(string); ok && v != "" {
								return types.StringValue(v)
							}
							return types.StringNull()
						}(),
					}
				}
				return nil
			}(),
			DefaultSessionKeyCaching: func() *ClusterEmptyModel {
				if !isImport && data.TLSParameters != nil {
					// Normal Read: preserve existing state value (even if nil)
					// This prevents API returning empty objects from overwriting user's 'not configured' intent
					return data.TLSParameters.DefaultSessionKeyCaching
				}
				// Import case: read from API
				if _, ok := blockData["default_session_key_caching"].(map[string]interface{}); ok {
					return &ClusterEmptyModel{}
				}
				return nil
			}(),
			DisableSessionKeyCaching: func() *ClusterEmptyModel {
				if !isImport && data.TLSParameters != nil {
					// Normal Read: preserve existing state value (even if nil)
					// This prevents API returning empty objects from overwriting user's 'not configured' intent
					return data.TLSParameters.DisableSessionKeyCaching
				}
				// Import case: read from API
				if _, ok := blockData["disable_session_key_caching"].(map[string]interface{}); ok {
					return &ClusterEmptyModel{}
				}
				return nil
			}(),
			DisableSni: func() *ClusterEmptyModel {
				if !isImport && data.TLSParameters != nil {
					// Normal Read: preserve existing state value (even if nil)
					// This prevents API returning empty objects from overwriting user's 'not configured' intent
					return data.TLSParameters.DisableSni
				}
				// Import case: read from API
				if _, ok := blockData["disable_sni"].(map[string]interface{}); ok {
					return &ClusterEmptyModel{}
				}
				return nil
			}(),
			MaxSessionKeys: func() types.Int64 {
				if v, ok := blockData["max_session_keys"].(float64); ok {
					return types.Int64Value(int64(v))
				}
				return types.Int64Null()
			}(),
			Sni: func() types.String {
				if v, ok := blockData["sni"].(string); ok && v != "" {
					return types.StringValue(v)
				}
				return types.StringNull()
			}(),
			UseHostHeaderAsSni: func() *ClusterEmptyModel {
				if !isImport && data.TLSParameters != nil {
					// Normal Read: preserve existing state value (even if nil)
					// This prevents API returning empty objects from overwriting user's 'not configured' intent
					return data.TLSParameters.UseHostHeaderAsSni
				}
				// Import case: read from API
				if _, ok := blockData["use_host_header_as_sni"].(map[string]interface{}); ok {
					return &ClusterEmptyModel{}
				}
				return nil
			}(),
		}
	}
	if _, ok := apiResource.Spec["upstream_conn_pool_reuse_type"].(map[string]interface{}); ok && isImport && data.UpstreamConnPoolReuseType == nil {
		// Import case: populate from API since state is nil and psd is empty
		data.UpstreamConnPoolReuseType = &ClusterUpstreamConnPoolReuseTypeModel{}
	}
	// Normal Read: preserve existing state value
	if v, ok := apiResource.Spec["connection_timeout"].(float64); ok {
		data.ConnectionTimeout = types.Int64Value(int64(v))
	} else {
		data.ConnectionTimeout = types.Int64Null()
	}
	if v, ok := apiResource.Spec["endpoint_selection"].(string); ok && v != "" {
		data.EndpointSelection = types.StringValue(v)
	} else {
		data.EndpointSelection = types.StringNull()
	}
	if v, ok := apiResource.Spec["fallback_policy"].(string); ok && v != "" {
		data.FallbackPolicy = types.StringValue(v)
	} else {
		data.FallbackPolicy = types.StringNull()
	}
	if v, ok := apiResource.Spec["http_idle_timeout"].(float64); ok {
		data.HTTPIdleTimeout = types.Int64Value(int64(v))
	} else {
		data.HTTPIdleTimeout = types.Int64Null()
	}
	if v, ok := apiResource.Spec["loadbalancer_algorithm"].(string); ok && v != "" {
		data.LoadBalancerAlgorithm = types.StringValue(v)
	} else {
		data.LoadBalancerAlgorithm = types.StringNull()
	}
	if v, ok := apiResource.Spec["panic_threshold"].(float64); ok {
		data.PanicThreshold = types.Int64Value(int64(v))
	} else {
		data.PanicThreshold = types.Int64Null()
	}

	psd := privatestate.NewPrivateStateData()
	// Use UID from fetched resource
	uid := fetched.Metadata.UID
	psd.SetUID(uid)
	psd.SetCustom("managed", "true") // Preserve managed marker after Update
	resp.Diagnostics.Append(psd.SaveToPrivateState(ctx, resp)...)

	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}

func (r *ClusterResource) Delete(ctx context.Context, req resource.DeleteRequest, resp *resource.DeleteResponse) {
	var data ClusterResourceModel
	resp.Diagnostics.Append(req.State.Get(ctx, &data)...)
	if resp.Diagnostics.HasError() {
		return
	}

	deleteTimeout, diags := data.Timeouts.Delete(ctx, inttimeouts.DefaultDelete)
	resp.Diagnostics.Append(diags...)
	if resp.Diagnostics.HasError() {
		return
	}

	ctx, cancel := context.WithTimeout(ctx, deleteTimeout)
	defer cancel()
	err := r.client.DeleteCluster(ctx, data.Namespace.ValueString(), data.Name.ValueString())
	if err != nil {
		// If the resource is already gone, consider deletion successful (idempotent delete)
		if strings.Contains(err.Error(), "NOT_FOUND") || strings.Contains(err.Error(), "404") {
			tflog.Warn(ctx, "Cluster already deleted, removing from state", map[string]interface{}{
				"name":      data.Name.ValueString(),
				"namespace": data.Namespace.ValueString(),
			})
			return
		}
		// If delete is not implemented (501), warn and remove from state
		// Some F5 XC resources don't support deletion via API
		if strings.Contains(err.Error(), "501") {
			tflog.Warn(ctx, "Cluster delete not supported by API (501), removing from state only", map[string]interface{}{
				"name":      data.Name.ValueString(),
				"namespace": data.Namespace.ValueString(),
			})
			return
		}
		resp.Diagnostics.AddError("Client Error", fmt.Sprintf("Unable to delete Cluster: %s", err))
		return
	}
}

func (r *ClusterResource) ImportState(ctx context.Context, req resource.ImportStateRequest, resp *resource.ImportStateResponse) {
	// Import ID format: namespace/name
	parts := strings.Split(req.ID, "/")
	if len(parts) != 2 || parts[0] == "" || parts[1] == "" {
		resp.Diagnostics.AddError(
			"Invalid Import ID",
			fmt.Sprintf("Expected import ID format: namespace/name, got: %s", req.ID),
		)
		return
	}
	namespace := parts[0]
	name := parts[1]

	resp.Diagnostics.Append(resp.State.SetAttribute(ctx, path.Root("namespace"), namespace)...)
	resp.Diagnostics.Append(resp.State.SetAttribute(ctx, path.Root("name"), name)...)
	resp.Diagnostics.Append(resp.State.SetAttribute(ctx, path.Root("id"), name)...)
}
